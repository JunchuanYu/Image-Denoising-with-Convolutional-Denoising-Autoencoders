{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import skimage\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage import data, img_as_float\n",
    "from skimage.restoration import denoise_nl_means\n",
    "from skimage.measure import compare_ssim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "from random import shuffle\n",
    "import math\n",
    "from keras.models import model_from_json, load_model\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.core import Lambda\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pickle\n",
    "from random import randint\n",
    "from utilities import *\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,:,0], rgb[:,:,:,1], rgb[:,:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray\n",
    "\n",
    "def read_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path,filename),0)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_images(src_path,dest_path,sizeX,sizeY):\n",
    "    images = []\n",
    "    width,height = sizeX,sizeY\n",
    "    for filename in os.listdir(src_path):\n",
    "        img = cv2.imread(src_path + filename)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    cnt =1\n",
    "    for img in images:\n",
    "        im2 = cv2.resize(img,(width, height),interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        \n",
    "        ext = \".png\"\n",
    "        cv2.imwrite(dest_path + \"image\" +  str(cnt) + ext,im2)\n",
    "        cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_images = read_images_from_folder('./data/oct_gt/')\n",
    "raw_images = np.resize(raw_images,(raw_images.shape[0],448,900,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding noise to images\n",
    "def add_noise(images):\n",
    "    \n",
    "    noisy_set = []\n",
    "    for image in images:\n",
    "        print len(noisy_set)\n",
    "        for shape in xrange(2,9,1):\n",
    "            for scale in xrange(2,9,1):\n",
    "                noise = np.random.gamma(shape,scale,image.shape)\n",
    "                noisy_set.append((image,np.clip(noise + image,0.,255.)))\n",
    "    shuffle(noisy_set)\n",
    "    return np.array(noisy_set)\n",
    "   \n",
    "#Shuffle the noisy image ground truth pair to randomize the noise distribution in the dataset\n",
    "def expand_pair(noisy_set):   \n",
    "    ground_truth=[]\n",
    "    noisy_images = []\n",
    "    for i in range(noisy_set.shape[0]):\n",
    "        ground_truth.append(noisy_set[i][0].reshape((noisy_set[i][0].shape[0],noisy_set[i][0].shape[1],1)))\n",
    "        #print( str(noisy_set[i][0].shape[0]) +\" \"+ str(noisy_set[i][0].shape[1]))\n",
    "        noisy_images.append(noisy_set[i][1].reshape((noisy_set[i][1].shape[0],noisy_set[i][1].shape[1],1)))\n",
    "    return np.array(ground_truth), np.array(noisy_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "49\n",
      "98\n",
      "147\n",
      "196\n",
      "245\n",
      "294\n",
      "343\n",
      "392\n",
      "441\n",
      "490\n",
      "539\n",
      "588\n",
      "637\n",
      "686\n",
      "735\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "noisy_set = add_noise(raw_images)\n",
    "for i in range(noisy_set.shape[0]):\n",
    "    cv2.imwrite(\"./data/oct_noisy/\"+str(i)+\".tif\",noisy_set[i][1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((833, 448, 900, 1), (833, 448, 900, 1), (833, 2, 448, 900, 1))\n"
     ]
    }
   ],
   "source": [
    "#Shuffling and adding noise to the dataset\n",
    "ground_truth,noisy_images = expand_pair(noisy_set)\n",
    "print (ground_truth.shape, noisy_images.shape, noisy_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.std(ground_truth/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ground_truth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2c25719b28fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresized_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mground_truth_rs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mnoisy_images_rs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ground_truth' is not defined"
     ]
    }
   ],
   "source": [
    "def resize_images(images,size):\n",
    "    resized_images = []\n",
    "    \n",
    "    for img in images:\n",
    "        im2 = cv2.resize(img,size,interpolation = cv2.INTER_CUBIC)\n",
    "        resized_images.append(im2)\n",
    "    \n",
    "    resized_images = np.array(resized_images)\n",
    "    resized_images = np.reshape(resized_images,(resized_images.shape[0],resized_images.shape[1],resized_images.shape[2],1))\n",
    "    \n",
    "    return resized_images\n",
    "\n",
    "ground_truth_rs = resize_images(ground_truth,(256,128))\n",
    "noisy_images_rs = resize_images(noisy_images,(256,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(833, 128, 256, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_images_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(noisy_images_rs.shape[0]):\n",
    "    cv2.imwrite(\"./data/oct_noisy_resized/\"+str(i)+\".tif\",noisy_images_rs[i])  \n",
    "    \n",
    "for i in range(ground_truth_rs.shape[0]):\n",
    "    cv2.imwrite(\"./data/oct_gt_resized/\"+str(i)+\".tif\",ground_truth_rs[i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_rs = read_images_from_folder('./data/oct_gt_resized/')\n",
    "ground_truth_rs = np.resize(ground_truth_rs,(ground_truth_rs.shape[0],ground_truth_rs.shape[1],ground_truth_rs.shape[2],1))\n",
    "\n",
    "noisy_images_rs = read_images_from_folder('./data/oct_noisy_resized/')\n",
    "noisy_images_rs = np.resize(noisy_images_rs,(noisy_images_rs.shape[0],noisy_images_rs.shape[1],noisy_images_rs.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('test_noisy.png',noisy_images_rs[33])\n",
    "cv2.imwrite('test.png',ground_truth_rs[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(666, 128, 256, 1)\n",
      "(167, 128, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "#Split into training and cross validation and normalizing\n",
    "train_size = int(ground_truth_rs.shape[0]*0.8)\n",
    "x_train = ground_truth_rs[0:train_size]/255.\n",
    "x_train_noisy = noisy_images_rs[0:train_size]/255.\n",
    "x_test = ground_truth_rs[train_size:]/255.\n",
    "x_test_noisy = noisy_images_rs[train_size:]/255.\n",
    "print (x_train_noisy.shape)\n",
    "print (x_test_noisy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(ground_truth.shape[0]):\n",
    " #   cv2.imwrite(\"./data/cifar-bw/image\"+str(i)+\".png\",ground_truth[i])\n",
    "    \n",
    "#for i in range(noisy_images.shape[0]):\n",
    " #   cv2.imwrite(\"./data/noisy-cifar-bw/image\"+str(i)+\".png\",noisy_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), cooldown=0, patience=2, min_lr=0.5e-6)\n",
    "#csv_logger = CSVLogger('./models/simple_cnn_autoencoder.csv')\n",
    "#early_stopper = EarlyStopping(min_delta=0.001,patience=30)\n",
    "model_checkpoint = ModelCheckpoint('./models/simple_cnn_oct.hdf5',monitor = 'loss', verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(666, 128, 256, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the model\n",
    "\n",
    "def get_simple_cnn_autoencoder_model(model_path=None):\n",
    "    \n",
    "    if(model_path is None):\n",
    "        autoencoder = None\n",
    "    else:\n",
    "        autoencoder = read_model_json(model_path) \n",
    "    \n",
    "    if(autoencoder is None):\n",
    "        input_img = Input(shape=((None,None,1)))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = AveragePooling2D((2, 2), padding='same')(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        encoded = AveragePooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        \n",
    "        decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "        autoencoder = Model(input_img, decoded)\n",
    "        \n",
    "        \n",
    "        autoencoder.compile(optimizer='Adam', loss='binary_crossentropy',metrics = ['accuracy','mean_squared_error'])\n",
    "\n",
    "    print (autoencoder.summary())\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, None, 64)    640       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, None, None, 1)     577       \n",
      "=================================================================\n",
      "Total params: 112,001\n",
      "Trainable params: 112,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "autoencoder = get_simple_cnn_autoencoder_model()\n",
    "plot_model(autoencoder, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 666 samples, validate on 167 samples\n",
      "Epoch 1/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6270 - acc: 0.0000e+00 - mean_squared_error: 0.0121Epoch 00000: loss improved from inf to 0.62671, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 53s - loss: 0.6267 - acc: 0.0000e+00 - mean_squared_error: 0.0120 - val_loss: 0.6170 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0063\n",
      "Epoch 2/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6117 - acc: 0.0000e+00 - mean_squared_error: 0.0052Epoch 00001: loss improved from 0.62671 to 0.61169, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6117 - acc: 0.0000e+00 - mean_squared_error: 0.0052 - val_loss: 0.6140 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0049\n",
      "Epoch 3/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6090 - acc: 0.0000e+00 - mean_squared_error: 0.0039Epoch 00002: loss improved from 0.61169 to 0.60904, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6090 - acc: 0.0000e+00 - mean_squared_error: 0.0039 - val_loss: 0.6176 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0065\n",
      "Epoch 4/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6071 - acc: 0.0000e+00 - mean_squared_error: 0.0030Epoch 00003: loss improved from 0.60904 to 0.60715, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6071 - acc: 0.0000e+00 - mean_squared_error: 0.0030 - val_loss: 0.6149 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0053\n",
      "Epoch 5/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6061 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00004: loss improved from 0.60715 to 0.60609, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6061 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.6094 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 6/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6059 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00005: loss improved from 0.60609 to 0.60592, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6059 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.6085 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 7/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6047 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00006: loss improved from 0.60592 to 0.60481, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6048 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.6089 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 8/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6052 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00007: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6053 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.6074 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 9/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6042 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00008: loss improved from 0.60481 to 0.60418, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6042 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.6070 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 10/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6038 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00009: loss improved from 0.60418 to 0.60384, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6038 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.6068 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0016\n",
      "Epoch 11/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6040 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00010: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6040 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.6066 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0015\n",
      "Epoch 12/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6042 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00011: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6041 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.6072 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 13/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6039 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00012: loss improved from 0.60384 to 0.60383, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6038 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.6092 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 14/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6039 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00013: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6039 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.6064 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0014\n",
      "Epoch 15/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6034 - acc: 0.0000e+00 - mean_squared_error: 0.0014Epoch 00014: loss improved from 0.60383 to 0.60344, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6034 - acc: 0.0000e+00 - mean_squared_error: 0.0014 - val_loss: 0.6077 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 16/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6035 - acc: 0.0000e+00 - mean_squared_error: 0.0014Epoch 00015: loss improved from 0.60344 to 0.60342, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6034 - acc: 0.0000e+00 - mean_squared_error: 0.0014 - val_loss: 0.6065 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0015\n",
      "Epoch 17/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6036 - acc: 0.0000e+00 - mean_squared_error: 0.0014Epoch 00016: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6035 - acc: 0.0000e+00 - mean_squared_error: 0.0014 - val_loss: 0.6067 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0016\n",
      "Epoch 18/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6036 - acc: 0.0000e+00 - mean_squared_error: 0.0014Epoch 00017: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6035 - acc: 0.0000e+00 - mean_squared_error: 0.0014 - val_loss: 0.6063 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0014\n",
      "Epoch 19/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0013Epoch 00018: loss improved from 0.60342 to 0.60329, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0013 - val_loss: 0.6063 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0014\n",
      "Epoch 20/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.0000e+00 - mean_squared_error: 0.0013Epoch 00019: loss improved from 0.60329 to 0.60317, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6032 - acc: 0.0000e+00 - mean_squared_error: 0.0013 - val_loss: 0.6063 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0014\n",
      "Epoch 21/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6032 - acc: 0.0000e+00 - mean_squared_error: 0.0013Epoch 00020: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0013 - val_loss: 0.6070 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/666 [============================>.] - ETA: 0s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0014Epoch 00021: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0014 - val_loss: 0.6075 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 23/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6035 - acc: 0.0000e+00 - mean_squared_error: 0.0014Epoch 00022: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6035 - acc: 0.0000e+00 - mean_squared_error: 0.0014 - val_loss: 0.6066 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0015\n",
      "Epoch 24/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6034 - acc: 0.0000e+00 - mean_squared_error: 0.0014Epoch 00023: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0014 - val_loss: 0.6067 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0015\n",
      "Epoch 25/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0013Epoch 00024: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6032 - acc: 0.0000e+00 - mean_squared_error: 0.0013 - val_loss: 0.6060 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0013\n",
      "Epoch 26/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00025: loss improved from 0.60317 to 0.60305, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6060 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 27/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6034 - acc: 0.0000e+00 - mean_squared_error: 0.0013Epoch 00026: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0013 - val_loss: 0.6061 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0013\n",
      "Epoch 28/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6034 - acc: 0.0000e+00 - mean_squared_error: 0.0013Epoch 00027: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0013 - val_loss: 0.6067 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0015\n",
      "Epoch 29/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0013Epoch 00028: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6031 - acc: 0.0000e+00 - mean_squared_error: 0.0013 - val_loss: 0.6065 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0015\n",
      "Epoch 30/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6032 - acc: 0.0000e+00 - mean_squared_error: 0.0013Epoch 00029: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0013 - val_loss: 0.6071 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 31/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6029 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00030: loss improved from 0.60305 to 0.60301, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6059 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 32/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0013Epoch 00031: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6031 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6061 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0013\n",
      "Epoch 33/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6032 - acc: 0.0000e+00 - mean_squared_error: 0.0013Epoch 00032: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6032 - acc: 0.0000e+00 - mean_squared_error: 0.0013 - val_loss: 0.6061 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0013\n",
      "Epoch 34/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00033: loss improved from 0.60301 to 0.60299, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6059 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 35/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0014Epoch 00034: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0014 - val_loss: 0.6063 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0014\n",
      "Epoch 36/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00035: loss improved from 0.60299 to 0.60292, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6029 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6070 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 37/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6032 - acc: 0.0000e+00 - mean_squared_error: 0.0013Epoch 00036: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0013 - val_loss: 0.6061 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0013\n",
      "Epoch 38/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6033 - acc: 0.0000e+00 - mean_squared_error: 0.0014Epoch 00037: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6034 - acc: 0.0000e+00 - mean_squared_error: 0.0014 - val_loss: 0.6061 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0013\n",
      "Epoch 39/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6032 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00038: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6029 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6063 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0014\n",
      "Epoch 40/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00039: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6066 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0015\n",
      "Epoch 41/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6029 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00040: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6058 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 42/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00041: loss improved from 0.60292 to 0.60291, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6029 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6060 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0013\n",
      "Epoch 43/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00042: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6058 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 44/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6027 - acc: 0.0000e+00 - mean_squared_error: 0.0011Epoch 00043: loss improved from 0.60291 to 0.60283, saving model to ./models/simple_cnn_oct.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 48s - loss: 0.6028 - acc: 0.0000e+00 - mean_squared_error: 0.0011 - val_loss: 0.6058 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 45/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6029 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00044: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6029 - acc: 0.0000e+00 - mean_squared_error: 0.0011 - val_loss: 0.6060 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 46/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00045: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6058 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 47/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00046: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6058 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 48/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6030 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00047: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6031 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6063 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0014\n",
      "Epoch 49/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6028 - acc: 0.0000e+00 - mean_squared_error: 0.0011Epoch 00048: loss improved from 0.60283 to 0.60281, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6028 - acc: 0.0000e+00 - mean_squared_error: 0.0011 - val_loss: 0.6059 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 50/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6028 - acc: 0.0000e+00 - mean_squared_error: 0.0011Epoch 00049: loss improved from 0.60281 to 0.60276, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6028 - acc: 0.0000e+00 - mean_squared_error: 0.0011 - val_loss: 0.6057 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 51/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6028 - acc: 0.0000e+00 - mean_squared_error: 0.0011Epoch 00050: loss improved from 0.60276 to 0.60267, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6027 - acc: 0.0000e+00 - mean_squared_error: 0.0011 - val_loss: 0.6056 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 52/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6029 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00051: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6029 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6061 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0013\n",
      "Epoch 53/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6025 - acc: 0.0000e+00 - mean_squared_error: 0.0010Epoch 00052: loss improved from 0.60267 to 0.60261, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6026 - acc: 0.0000e+00 - mean_squared_error: 0.0010 - val_loss: 0.6078 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 54/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.0000e+00 - mean_squared_error: 0.0012Epoch 00053: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6029 - acc: 0.0000e+00 - mean_squared_error: 0.0012 - val_loss: 0.6066 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0015\n",
      "Epoch 55/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.0000e+00 - mean_squared_error: 0.0013Epoch 00054: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6031 - acc: 0.0000e+00 - mean_squared_error: 0.0013 - val_loss: 0.6056 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0010\n",
      "Epoch 56/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6027 - acc: 0.0000e+00 - mean_squared_error: 0.0010Epoch 00055: loss improved from 0.60261 to 0.60260, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6026 - acc: 0.0000e+00 - mean_squared_error: 0.0010 - val_loss: 0.6056 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 57/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6027 - acc: 0.0000e+00 - mean_squared_error: 0.0010Epoch 00056: loss improved from 0.60260 to 0.60259, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6026 - acc: 0.0000e+00 - mean_squared_error: 0.0010 - val_loss: 0.6062 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0013\n",
      "Epoch 58/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6025 - acc: 0.0000e+00 - mean_squared_error: 0.0010Epoch 00057: loss improved from 0.60259 to 0.60256, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6026 - acc: 0.0000e+00 - mean_squared_error: 0.0010 - val_loss: 0.6062 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0013\n",
      "Epoch 59/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6026 - acc: 0.0000e+00 - mean_squared_error: 9.8107e-04Epoch 00058: loss improved from 0.60256 to 0.60249, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6025 - acc: 0.0000e+00 - mean_squared_error: 9.8003e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.6896e-04\n",
      "Epoch 60/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.5018e-04Epoch 00059: loss improved from 0.60249 to 0.60243, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.5079e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.5768e-04\n",
      "Epoch 61/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 9.3296e-04Epoch 00060: loss improved from 0.60243 to 0.60239, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.3494e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.5933e-04\n",
      "Epoch 62/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6025 - acc: 0.0000e+00 - mean_squared_error: 9.9425e-04Epoch 00061: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6025 - acc: 0.0000e+00 - mean_squared_error: 9.9806e-04 - val_loss: 0.6059 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 63/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6027 - acc: 0.0000e+00 - mean_squared_error: 0.0011Epoch 00062: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6028 - acc: 0.0000e+00 - mean_squared_error: 0.0011 - val_loss: 0.6058 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 64/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 9.3125e-04Epoch 00063: loss improved from 0.60239 to 0.60239, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.3223e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.3539e-04\n",
      "Epoch 65/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 9.1273e-04Epoch 00064: loss improved from 0.60239 to 0.60235, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 9.1362e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.1980e-04\n",
      "Epoch 66/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.7207e-04Epoch 00065: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6025 - acc: 0.0000e+00 - mean_squared_error: 9.7271e-04 - val_loss: 0.6055 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0010\n",
      "Epoch 67/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6028 - acc: 0.0000e+00 - mean_squared_error: 0.0011Epoch 00066: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6027 - acc: 0.0000e+00 - mean_squared_error: 0.0011 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.6456e-04\n",
      "Epoch 68/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 9.2138e-04Epoch 00067: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.2018e-04 - val_loss: 0.6056 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0010\n",
      "Epoch 69/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 9.4779e-04Epoch 00068: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.4691e-04 - val_loss: 0.6058 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 70/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.6513e-04Epoch 00069: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6025 - acc: 0.0000e+00 - mean_squared_error: 9.6363e-04 - val_loss: 0.6055 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0010\n",
      "Epoch 71/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6027 - acc: 0.0000e+00 - mean_squared_error: 9.5711e-04Epoch 00070: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6025 - acc: 0.0000e+00 - mean_squared_error: 9.6318e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.0111e-04\n",
      "Epoch 72/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.5325e-04Epoch 00071: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.5296e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.8695e-04\n",
      "Epoch 73/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.6671e-04Epoch 00072: loss improved from 0.60235 to 0.60224, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.6658e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.8735e-04\n",
      "Epoch 74/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 9.2904e-04Epoch 00073: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.2961e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.0844e-04\n",
      "Epoch 75/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.9158e-04Epoch 00074: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.9037e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.6419e-04\n",
      "Epoch 76/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.6605e-04Epoch 00075: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.6836e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.7540e-04\n",
      "Epoch 77/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 8.9558e-04Epoch 00076: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.9748e-04 - val_loss: 0.6055 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0010\n",
      "Epoch 78/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.5776e-04Epoch 00077: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.5607e-04 - val_loss: 0.6057 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 79/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 9.0976e-04Epoch 00078: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 9.0905e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.4825e-04\n",
      "Epoch 80/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.1402e-04Epoch 00079: loss improved from 0.60224 to 0.60212, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.1404e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.3890e-04\n",
      "Epoch 81/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.6345e-04Epoch 00080: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.6361e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.1888e-04\n",
      "Epoch 82/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.2184e-04Epoch 00081: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.2300e-04 - val_loss: 0.6057 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 83/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.4347e-04Epoch 00082: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.4210e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.9965e-04\n",
      "Epoch 84/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.3790e-04Epoch 00083: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.3859e-04 - val_loss: 0.6057 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 85/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 8.4657e-04Epoch 00084: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.4633e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.3828e-04\n",
      "Epoch 86/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 8.9773e-04Epoch 00085: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.9988e-04 - val_loss: 0.6058 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 87/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6027 - acc: 0.0000e+00 - mean_squared_error: 0.0010    Epoch 00086: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6026 - acc: 0.0000e+00 - mean_squared_error: 0.0010 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.5858e-04\n",
      "Epoch 88/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.8036e-04Epoch 00087: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.7892e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.3497e-04\n",
      "Epoch 89/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.1786e-04Epoch 00088: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.1749e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.5429e-04\n",
      "Epoch 90/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.0721e-04Epoch 00089: loss improved from 0.60212 to 0.60211, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.1012e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.3997e-04\n",
      "Epoch 91/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.6043e-04Epoch 00090: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.6174e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.1487e-04\n",
      "Epoch 92/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.3791e-04Epoch 00091: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.3939e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.5822e-04\n",
      "Epoch 93/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.6281e-04Epoch 00092: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.6159e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.0455e-04\n",
      "Epoch 94/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.0488e-04Epoch 00093: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 9.0492e-04 - val_loss: 0.6057 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 95/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.4269e-04Epoch 00094: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.4163e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1971e-04\n",
      "Epoch 96/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 8.0822e-04Epoch 00095: loss improved from 0.60211 to 0.60210, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.0722e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.4415e-04\n",
      "Epoch 97/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.9939e-04Epoch 00096: loss improved from 0.60210 to 0.60209, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.0006e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.4411e-04\n",
      "Epoch 98/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.0720e-04Epoch 00097: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.0837e-04 - val_loss: 0.6062 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0013\n",
      "Epoch 99/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.7427e-04Epoch 00098: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.7268e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.9643e-04\n",
      "Epoch 100/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 8.9510e-04Epoch 00099: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.9609e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.6779e-04\n",
      "Epoch 101/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.4006e-04Epoch 00100: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.3795e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1764e-04\n",
      "Epoch 102/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.8555e-04Epoch 00101: loss improved from 0.60209 to 0.60206, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.8502e-04 - val_loss: 0.6060 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 103/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.7339e-04Epoch 00102: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6025 - acc: 0.0000e+00 - mean_squared_error: 9.7206e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.1916e-04\n",
      "Epoch 104/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.0756e-04Epoch 00103: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.0773e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.2684e-04\n",
      "Epoch 105/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.7081e-04Epoch 00104: loss improved from 0.60206 to 0.60202, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.7074e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8868e-04\n",
      "Epoch 106/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.6861e-04Epoch 00105: loss improved from 0.60202 to 0.60202, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.7010e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8854e-04\n",
      "Epoch 107/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.8572e-04Epoch 00106: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.8511e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1653e-04\n",
      "Epoch 108/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.5694e-04Epoch 00107: loss improved from 0.60202 to 0.60199, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.5579e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.2034e-04\n",
      "Epoch 109/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.4853e-04Epoch 00108: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.4985e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.2453e-04\n",
      "Epoch 110/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.8609e-04Epoch 00109: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.8756e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.6467e-04\n",
      "Epoch 111/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 8.7577e-04Epoch 00110: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.7461e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.2725e-04\n",
      "Epoch 112/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.2715e-04Epoch 00111: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.2663e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.4702e-04\n",
      "Epoch 113/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 7.9057e-04Epoch 00112: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.9698e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.4674e-04\n",
      "Epoch 114/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.4974e-04Epoch 00113: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.5032e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.0830e-04\n",
      "Epoch 115/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.0762e-04Epoch 00114: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 9.0606e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.9243e-04\n",
      "Epoch 116/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.8160e-04Epoch 00115: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.7982e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8559e-04\n",
      "Epoch 117/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 7.6414e-04Epoch 00116: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6320e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.1533e-04\n",
      "Epoch 118/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.9535e-04Epoch 00117: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.9591e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.0757e-04\n",
      "Epoch 119/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.7180e-04Epoch 00118: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.7168e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.6751e-04\n",
      "Epoch 120/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.8798e-04Epoch 00119: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.8876e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.4182e-04\n",
      "Epoch 121/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.2191e-04Epoch 00120: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.2093e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.8950e-04\n",
      "Epoch 122/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.4951e-04Epoch 00121: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.4888e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1551e-04\n",
      "Epoch 123/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 7.7661e-04Epoch 00122: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.7534e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.6870e-04\n",
      "Epoch 124/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 8.0375e-04Epoch 00123: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.0261e-04 - val_loss: 0.6057 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 125/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.8111e-04Epoch 00124: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.8079e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.8304e-04\n",
      "Epoch 126/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4653e-04Epoch 00125: loss improved from 0.60199 to 0.60196, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4532e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.5259e-04\n",
      "Epoch 127/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.1899e-04Epoch 00126: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.1733e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1460e-04\n",
      "Epoch 128/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6771e-04Epoch 00127: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6617e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1206e-04\n",
      "Epoch 129/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 7.9714e-04Epoch 00128: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.9545e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.7169e-04\n",
      "Epoch 130/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4833e-04Epoch 00129: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4824e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.9638e-04\n",
      "Epoch 131/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 7.5862e-04Epoch 00130: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6181e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4824e-04\n",
      "Epoch 132/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 7.9519e-04Epoch 00131: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.9616e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.6347e-04\n",
      "Epoch 133/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4692e-04Epoch 00132: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4578e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.6367e-04\n",
      "Epoch 134/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.3180e-04Epoch 00133: loss improved from 0.60196 to 0.60193, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3132e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.5974e-04\n",
      "Epoch 135/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4286e-04Epoch 00134: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4164e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.4895e-04\n",
      "Epoch 136/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.4737e-04Epoch 00135: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4660e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.4059e-04\n",
      "Epoch 137/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4641e-04Epoch 00136: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4697e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4077e-04\n",
      "Epoch 138/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.6717e-04Epoch 00137: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6851e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3415e-04\n",
      "Epoch 139/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.8466e-04Epoch 00138: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.8345e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.8753e-04\n",
      "Epoch 140/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6025 - acc: 0.0000e+00 - mean_squared_error: 8.6616e-04Epoch 00139: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.6687e-04 - val_loss: 0.6058 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 141/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.3914e-04Epoch 00140: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.3756e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.6204e-04\n",
      "Epoch 142/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1561e-04Epoch 00141: loss improved from 0.60193 to 0.60189, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1646e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.9547e-04\n",
      "Epoch 143/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.6376e-04Epoch 00142: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6843e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.4060e-04\n",
      "Epoch 144/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.5694e-04Epoch 00143: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.5447e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.8779e-04\n",
      "Epoch 145/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.9442e-04Epoch 00144: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.9424e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.9570e-04\n",
      "Epoch 146/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.3353e-04Epoch 00145: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3382e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.5205e-04\n",
      "Epoch 147/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.1020e-04Epoch 00146: loss improved from 0.60189 to 0.60188, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1062e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3367e-04\n",
      "Epoch 148/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4999e-04Epoch 00147: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.5306e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.5422e-04\n",
      "Epoch 149/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.9616e-04Epoch 00148: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.9458e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.5288e-04\n",
      "Epoch 150/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 8.0826e-04Epoch 00149: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.0830e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.2214e-04\n",
      "Epoch 151/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.2974e-04Epoch 00150: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3108e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3494e-04\n",
      "Epoch 152/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6292e-04Epoch 00151: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6249e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3858e-04\n",
      "Epoch 153/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.6427e-04Epoch 00152: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6392e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.0482e-04\n",
      "Epoch 154/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.7388e-04Epoch 00153: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.7359e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.6402e-04\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.3362e-04Epoch 00154: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3195e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.7728e-04\n",
      "Epoch 156/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6239e-04Epoch 00155: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6145e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3207e-04\n",
      "Epoch 157/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.9848e-04Epoch 00156: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.9718e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.8277e-04\n",
      "Epoch 158/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.5981e-04Epoch 00157: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.5837e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2143e-04\n",
      "Epoch 159/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.1470e-04Epoch 00158: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1642e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4352e-04\n",
      "Epoch 160/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.1499e-04Epoch 00159: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.1589e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.5908e-04\n",
      "Epoch 161/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4382e-04Epoch 00160: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4392e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.6365e-04\n",
      "Epoch 162/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3670e-04Epoch 00161: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3872e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2252e-04\n",
      "Epoch 163/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6988e-04Epoch 00162: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.7027e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2436e-04\n",
      "Epoch 164/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4575e-04Epoch 00163: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4487e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.6350e-04\n",
      "Epoch 165/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.3201e-04Epoch 00164: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3122e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2374e-04\n",
      "Epoch 166/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4386e-04Epoch 00165: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4500e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8809e-04\n",
      "Epoch 167/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.3144e-04Epoch 00166: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3539e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0868e-04\n",
      "Epoch 168/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3077e-04Epoch 00167: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3174e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1943e-04\n",
      "Epoch 169/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.2000e-04Epoch 00168: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.2259e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.4718e-04\n",
      "Epoch 170/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.2713e-04Epoch 00169: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.2629e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.1530e-04\n",
      "Epoch 171/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.2580e-04Epoch 00170: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.2699e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4685e-04\n",
      "Epoch 172/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.9781e-04Epoch 00171: loss improved from 0.60188 to 0.60185, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9722e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8007e-04\n",
      "Epoch 173/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.1483e-04Epoch 00172: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1409e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3951e-04\n",
      "Epoch 174/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.3794e-04Epoch 00173: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3914e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4398e-04\n",
      "Epoch 175/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.2580e-04Epoch 00174: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.2787e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.1295e-04\n",
      "Epoch 176/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.4392e-04Epoch 00175: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4464e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2568e-04\n",
      "Epoch 177/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.7580e-04Epoch 00176: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.7513e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.1030e-04\n",
      "Epoch 178/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4273e-04Epoch 00177: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4195e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.1551e-04\n",
      "Epoch 179/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.1067e-04Epoch 00178: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1004e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2438e-04\n",
      "Epoch 180/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9228e-04Epoch 00179: loss improved from 0.60185 to 0.60184, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9205e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2647e-04\n",
      "Epoch 181/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0509e-04Epoch 00180: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0565e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.5908e-04\n",
      "Epoch 182/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1651e-04Epoch 00181: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1634e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.9510e-04\n",
      "Epoch 183/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6092e-04Epoch 00182: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6173e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1410e-04\n",
      "Epoch 184/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.1986e-04Epoch 00183: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1908e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0154e-04\n",
      "Epoch 185/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.0522e-04Epoch 00184: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0472e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.9976e-04\n",
      "Epoch 186/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.0473e-04Epoch 00185: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1041e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.7721e-04\n",
      "Epoch 187/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.3337e-04Epoch 00186: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3213e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0538e-04\n",
      "Epoch 188/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.5362e-04Epoch 00187: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.5313e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.1835e-04\n",
      "Epoch 189/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.5238e-04Epoch 00188: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.5305e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.9516e-04\n",
      "Epoch 190/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6025 - acc: 0.0000e+00 - mean_squared_error: 9.2737e-04Epoch 00189: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6024 - acc: 0.0000e+00 - mean_squared_error: 9.2567e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.5002e-04\n",
      "Epoch 191/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.1150e-04Epoch 00190: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 8.1236e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.5992e-04\n",
      "Epoch 192/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.1433e-04Epoch 00191: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1398e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0551e-04\n",
      "Epoch 193/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.9540e-04Epoch 00192: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9517e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0421e-04\n",
      "Epoch 194/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.9011e-04Epoch 00193: loss improved from 0.60184 to 0.60183, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8893e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2820e-04\n",
      "Epoch 195/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 6.7512e-04Epoch 00194: loss improved from 0.60183 to 0.60179, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7559e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.2072e-04\n",
      "Epoch 196/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.8175e-04Epoch 00195: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8145e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.1097e-04\n",
      "Epoch 197/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.2406e-04Epoch 00196: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.2421e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3310e-04\n",
      "Epoch 198/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.7759e-04Epoch 00197: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.7689e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2708e-04\n",
      "Epoch 199/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8847e-04Epoch 00198: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8800e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0057e-04\n",
      "Epoch 200/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.0332e-04Epoch 00199: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0392e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.5555e-04\n",
      "Epoch 201/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.1764e-04Epoch 00200: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1617e-04 - val_loss: 0.6055 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0010\n",
      "Epoch 202/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 7.7881e-04Epoch 00201: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.7690e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2837e-04\n",
      "Epoch 203/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.9827e-04Epoch 00202: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9820e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0725e-04\n",
      "Epoch 204/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.9550e-04Epoch 00203: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9644e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.9939e-04\n",
      "Epoch 205/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.6717e-04Epoch 00204: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6543e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2517e-04\n",
      "Epoch 206/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9591e-04Epoch 00205: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9786e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0367e-04\n",
      "Epoch 207/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0591e-04Epoch 00206: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0510e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9700e-04\n",
      "Epoch 208/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0779e-04Epoch 00207: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0767e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9858e-04\n",
      "Epoch 209/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 6.7795e-04Epoch 00208: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7859e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2807e-04\n",
      "Epoch 210/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.2333e-04Epoch 00209: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.2166e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8355e-04\n",
      "Epoch 211/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.9058e-04Epoch 00210: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9056e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8648e-04\n",
      "Epoch 212/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.6611e-04Epoch 00211: loss improved from 0.60179 to 0.60177, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6541e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.9431e-04\n",
      "Epoch 213/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8752e-04Epoch 00212: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8689e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.8132e-04\n",
      "Epoch 214/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.5742e-04Epoch 00213: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.5564e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8182e-04\n",
      "Epoch 215/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.1558e-04Epoch 00214: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1472e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.1896e-04\n",
      "Epoch 216/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 6.8344e-04Epoch 00215: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8249e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.0995e-04\n",
      "Epoch 217/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.7013e-04Epoch 00216: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7712e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0401e-04\n",
      "Epoch 218/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4501e-04Epoch 00217: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4549e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.0612e-04\n",
      "Epoch 219/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.0390e-04Epoch 00218: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0305e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1108e-04\n",
      "Epoch 220/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.8715e-04Epoch 00219: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8681e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.1441e-04\n",
      "Epoch 221/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.9236e-04Epoch 00220: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9355e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.2540e-04\n",
      "Epoch 222/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.9881e-04Epoch 00221: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 48s - loss: 0.6021 - acc: 0.0000e+00 - mean_squared_error: 7.9912e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3495e-04\n",
      "Epoch 223/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.5371e-04Epoch 00222: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.5171e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8754e-04\n",
      "Epoch 224/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.6328e-04Epoch 00223: loss improved from 0.60177 to 0.60177, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6331e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6849e-04\n",
      "Epoch 225/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.1210e-04Epoch 00224: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1372e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3711e-04\n",
      "Epoch 226/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9003e-04Epoch 00225: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8980e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3106e-04\n",
      "Epoch 227/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8818e-04Epoch 00226: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8845e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.2346e-04\n",
      "Epoch 228/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.8208e-04Epoch 00227: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.8138e-04 - val_loss: 0.6056 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0010\n",
      "Epoch 229/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.5216e-04Epoch 00228: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.5293e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.1384e-04\n",
      "Epoch 230/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.8473e-04Epoch 00229: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8570e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.6727e-04\n",
      "Epoch 231/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9565e-04Epoch 00230: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9662e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3247e-04\n",
      "Epoch 232/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8488e-04Epoch 00231: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8724e-04 - val_loss: 0.6056 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0010\n",
      "Epoch 233/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3150e-04Epoch 00232: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3039e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8500e-04\n",
      "Epoch 234/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9340e-04Epoch 00233: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9333e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8294e-04\n",
      "Epoch 235/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.7600e-04Epoch 00234: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7513e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7421e-04\n",
      "Epoch 236/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5316e-04Epoch 00235: loss improved from 0.60177 to 0.60175, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5433e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6427e-04\n",
      "Epoch 237/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 6.6355e-04Epoch 00236: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6372e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7533e-04\n",
      "Epoch 238/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 6.5437e-04Epoch 00237: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5917e-04 - val_loss: 0.6069 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0016\n",
      "Epoch 239/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.6907e-04Epoch 00238: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 8.6662e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0031e-04\n",
      "Epoch 240/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7848e-04Epoch 00239: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7876e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8399e-04\n",
      "Epoch 241/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.6284e-04Epoch 00240: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6140e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.3534e-04\n",
      "Epoch 242/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.1598e-04Epoch 00241: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1583e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9676e-04\n",
      "Epoch 243/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3389e-04Epoch 00242: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3478e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.1270e-04\n",
      "Epoch 244/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.7327e-04Epoch 00243: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7307e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9316e-04\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.6275e-04Epoch 00244: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6258e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7292e-04\n",
      "Epoch 246/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.2663e-04Epoch 00245: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.2532e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2365e-04\n",
      "Epoch 247/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.6000e-04Epoch 00246: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6053e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3223e-04\n",
      "Epoch 248/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6812e-04Epoch 00247: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6955e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9858e-04\n",
      "Epoch 249/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.8022e-04Epoch 00248: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8018e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3095e-04\n",
      "Epoch 250/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1932e-04Epoch 00249: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.2073e-04 - val_loss: 0.6058 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0011\n",
      "Epoch 251/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.5765e-04Epoch 00250: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.5604e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4276e-04\n",
      "Epoch 252/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9278e-04Epoch 00251: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9124e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.5036e-04\n",
      "Epoch 253/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.8403e-04Epoch 00252: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8458e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1050e-04\n",
      "Epoch 254/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8621e-04Epoch 00253: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8528e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1313e-04\n",
      "Epoch 255/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8957e-04Epoch 00254: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8853e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4893e-04\n",
      "Epoch 256/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.2029e-04Epoch 00255: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.2169e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.9918e-04\n",
      "Epoch 257/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.6765e-04Epoch 00256: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6645e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7558e-04\n",
      "Epoch 258/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5451e-04Epoch 00257: loss improved from 0.60175 to 0.60174, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5354e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4619e-04\n",
      "Epoch 259/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.8400e-04Epoch 00258: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8565e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.3035e-04\n",
      "Epoch 260/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 7.4772e-04Epoch 00259: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4652e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.9467e-04\n",
      "Epoch 261/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3490e-04Epoch 00260: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3426e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4444e-04\n",
      "Epoch 262/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1049e-04Epoch 00261: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1201e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7467e-04\n",
      "Epoch 263/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5397e-04Epoch 00262: loss improved from 0.60174 to 0.60174, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5371e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7270e-04\n",
      "Epoch 264/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5021e-04Epoch 00263: loss improved from 0.60174 to 0.60174, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5079e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5187e-04\n",
      "Epoch 265/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8354e-04Epoch 00264: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8356e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.3370e-04\n",
      "Epoch 266/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.7234e-04Epoch 00265: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7097e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7584e-04\n",
      "Epoch 267/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4306e-04Epoch 00266: loss improved from 0.60174 to 0.60172, saving model to ./models/simple_cnn_oct.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4246e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5019e-04\n",
      "Epoch 268/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1764e-04Epoch 00267: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1704e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2323e-04\n",
      "Epoch 269/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.0058e-04Epoch 00268: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.9937e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8925e-04\n",
      "Epoch 270/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.4549e-04Epoch 00269: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4595e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7484e-04\n",
      "Epoch 271/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.8652e-04Epoch 00270: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8549e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8500e-04\n",
      "Epoch 272/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5388e-04Epoch 00271: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5327e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6784e-04\n",
      "Epoch 273/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6968e-04Epoch 00272: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6988e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9910e-04\n",
      "Epoch 274/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.0338e-04Epoch 00273: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0173e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.3135e-04\n",
      "Epoch 275/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4750e-04Epoch 00274: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.4629e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0884e-04\n",
      "Epoch 276/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.9462e-04Epoch 00275: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9414e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.8485e-04\n",
      "Epoch 277/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6345e-04Epoch 00276: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.6211e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5884e-04\n",
      "Epoch 278/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.4926e-04Epoch 00277: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4779e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9753e-04\n",
      "Epoch 279/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3988e-04Epoch 00278: loss improved from 0.60172 to 0.60171, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4006e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7003e-04\n",
      "Epoch 280/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 6.8848e-04Epoch 00279: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8836e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6125e-04\n",
      "Epoch 281/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.5943e-04Epoch 00280: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5863e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6744e-04\n",
      "Epoch 282/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4677e-04Epoch 00281: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4641e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4780e-04\n",
      "Epoch 283/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3722e-04Epoch 00282: loss improved from 0.60171 to 0.60171, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3776e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7050e-04\n",
      "Epoch 284/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.4401e-04Epoch 00283: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4503e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3774e-04\n",
      "Epoch 285/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.8174e-04Epoch 00284: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8181e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4894e-04\n",
      "Epoch 286/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3478e-04Epoch 00285: loss improved from 0.60171 to 0.60170, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3463e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5508e-04\n",
      "Epoch 287/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.3286e-04Epoch 00286: loss improved from 0.60170 to 0.60170, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3561e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9737e-04\n",
      "Epoch 288/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.7938e-04Epoch 00287: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7905e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1363e-04\n",
      "Epoch 289/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.7158e-04Epoch 00288: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7028e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7796e-04\n",
      "Epoch 290/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.4144e-04Epoch 00289: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4176e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4782e-04\n",
      "Epoch 291/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3696e-04Epoch 00290: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3729e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6043e-04\n",
      "Epoch 292/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.4478e-04Epoch 00291: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4414e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7817e-04\n",
      "Epoch 293/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 6.7852e-04Epoch 00292: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7834e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5158e-04\n",
      "Epoch 294/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5199e-04Epoch 00293: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5139e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4853e-04\n",
      "Epoch 295/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5414e-04Epoch 00294: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5349e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2038e-04\n",
      "Epoch 296/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.8227e-04Epoch 00295: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8224e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8848e-04\n",
      "Epoch 297/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.7309e-04Epoch 00296: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7835e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6694e-04\n",
      "Epoch 298/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0974e-04Epoch 00297: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0939e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0524e-04\n",
      "Epoch 299/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.7832e-04Epoch 00298: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7955e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4431e-04\n",
      "Epoch 300/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7777e-04Epoch 00299: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7904e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.5764e-04\n",
      "Epoch 301/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.0000e+00 - mean_squared_error: 7.6135e-04Epoch 00300: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.5975e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.5721e-04\n",
      "Epoch 302/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5832e-04Epoch 00301: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5814e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4637e-04\n",
      "Epoch 303/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4356e-04Epoch 00302: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4400e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3644e-04\n",
      "Epoch 304/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.6939e-04Epoch 00303: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6765e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4452e-04\n",
      "Epoch 305/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6992e-04Epoch 00304: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6912e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4704e-04\n",
      "Epoch 306/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3192e-04Epoch 00305: loss improved from 0.60170 to 0.60169, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3199e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8534e-04\n",
      "Epoch 307/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3647e-04Epoch 00306: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3584e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7154e-04\n",
      "Epoch 308/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5052e-04Epoch 00307: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4970e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4032e-04\n",
      "Epoch 309/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5774e-04Epoch 00308: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5773e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2902e-04\n",
      "Epoch 310/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4638e-04Epoch 00309: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4718e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5802e-04\n",
      "Epoch 311/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4305e-04Epoch 00310: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4366e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4779e-04\n",
      "Epoch 312/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.0088e-04Epoch 00311: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0170e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.0237e-04\n",
      "Epoch 313/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.4626e-04Epoch 00312: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4609e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4052e-04\n",
      "Epoch 314/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2026e-04Epoch 00313: loss improved from 0.60169 to 0.60166, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2024e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4618e-04\n",
      "Epoch 315/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5945e-04Epoch 00314: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5820e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8727e-04\n",
      "Epoch 316/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5752e-04Epoch 00315: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5805e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8009e-04\n",
      "Epoch 317/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5046e-04Epoch 00316: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4982e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5298e-04\n",
      "Epoch 318/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.2683e-04Epoch 00317: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2653e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6635e-04\n",
      "Epoch 319/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.0000e+00 - mean_squared_error: 6.1889e-04Epoch 00318: loss improved from 0.60166 to 0.60166, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1845e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4962e-04\n",
      "Epoch 320/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1596e-04Epoch 00319: loss improved from 0.60166 to 0.60166, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1619e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2710e-04\n",
      "Epoch 321/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4491e-04Epoch 00320: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4482e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5983e-04\n",
      "Epoch 322/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5886e-04Epoch 00321: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5851e-04 - val_loss: 0.6059 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 323/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.4045e-04Epoch 00322: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.3873e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4851e-04\n",
      "Epoch 324/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2146e-04Epoch 00323: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2179e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6792e-04\n",
      "Epoch 325/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4302e-04Epoch 00324: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4199e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.8483e-04\n",
      "Epoch 326/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.7023e-04Epoch 00325: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7022e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6627e-04\n",
      "Epoch 327/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.4390e-04Epoch 00326: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4378e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9128e-04\n",
      "Epoch 328/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.2981e-04Epoch 00327: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3147e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2902e-04\n",
      "Epoch 329/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.6858e-04Epoch 00328: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6832e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4339e-04\n",
      "Epoch 330/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1576e-04Epoch 00329: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1616e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.0175e-04\n",
      "Epoch 331/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.6551e-04Epoch 00330: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6680e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6129e-04\n",
      "Epoch 332/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5150e-04Epoch 00331: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5530e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.2550e-04\n",
      "Epoch 333/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.8514e-04Epoch 00332: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6023 - acc: 0.0000e+00 - mean_squared_error: 8.8259e-04 - val_loss: 0.6054 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.7354e-04\n",
      "Epoch 334/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1016e-04Epoch 00333: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0881e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3258e-04\n",
      "Epoch 335/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.5070e-04Epoch 00334: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5120e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8194e-04\n",
      "Epoch 336/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.0010e-04Epoch 00335: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.9963e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4124e-04\n",
      "Epoch 337/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2533e-04Epoch 00336: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2534e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3706e-04\n",
      "Epoch 338/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.3633e-04Epoch 00337: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3543e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6932e-04\n",
      "Epoch 339/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.1880e-04Epoch 00338: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1859e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5783e-04\n",
      "Epoch 340/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.5475e-04Epoch 00339: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5504e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6059e-04\n",
      "Epoch 341/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2607e-04Epoch 00340: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2497e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3243e-04\n",
      "Epoch 342/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0376e-04Epoch 00341: loss improved from 0.60166 to 0.60163, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0450e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6129e-04\n",
      "Epoch 343/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2828e-04Epoch 00342: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2861e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0424e-04\n",
      "Epoch 344/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3638e-04Epoch 00343: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3504e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1527e-04\n",
      "Epoch 345/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.8930e-04Epoch 00344: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8951e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8242e-04\n",
      "Epoch 346/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6177e-04Epoch 00345: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6447e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3506e-04\n",
      "Epoch 347/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.0046e-04Epoch 00346: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.9919e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6967e-04\n",
      "Epoch 348/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4707e-04Epoch 00347: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4593e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7470e-04\n",
      "Epoch 349/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3254e-04Epoch 00348: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3276e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4381e-04\n",
      "Epoch 350/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2367e-04Epoch 00349: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2353e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2979e-04\n",
      "Epoch 351/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7034e-04Epoch 00350: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7023e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6669e-04\n",
      "Epoch 352/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.4243e-04Epoch 00351: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4211e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8106e-04\n",
      "Epoch 353/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.7636e-04Epoch 00352: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7490e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3371e-04\n",
      "Epoch 354/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5895e-04Epoch 00353: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5924e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.3626e-04\n",
      "Epoch 355/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9440e-04Epoch 00354: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.9351e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.5123e-04\n",
      "Epoch 356/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.3671e-04Epoch 00355: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3780e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5628e-04\n",
      "Epoch 357/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1387e-04Epoch 00356: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1434e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3591e-04\n",
      "Epoch 358/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3129e-04Epoch 00357: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3036e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3380e-04\n",
      "Epoch 359/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2595e-04Epoch 00358: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2499e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5146e-04\n",
      "Epoch 360/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1948e-04Epoch 00359: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2068e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4043e-04\n",
      "Epoch 361/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1765e-04Epoch 00360: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1591e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2337e-04\n",
      "Epoch 362/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3492e-04Epoch 00361: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3572e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0407e-04\n",
      "Epoch 363/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1021e-04Epoch 00362: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1101e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3568e-04\n",
      "Epoch 364/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.1046e-04Epoch 00363: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1030e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.1441e-04\n",
      "Epoch 365/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1873e-04Epoch 00364: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1783e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1510e-04\n",
      "Epoch 366/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1963e-04Epoch 00365: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2057e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4082e-04\n",
      "Epoch 367/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2589e-04Epoch 00366: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2594e-04 - val_loss: 0.6053 - val_acc: 0.0000e+00 - val_mean_squared_error: 9.0970e-04\n",
      "Epoch 368/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3554e-04Epoch 00367: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3590e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9636e-04\n",
      "Epoch 369/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3184e-04Epoch 00368: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3139e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7222e-04\n",
      "Epoch 370/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.4794e-04Epoch 00369: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5175e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6798e-04\n",
      "Epoch 371/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.6133e-04Epoch 00370: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6130e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3736e-04\n",
      "Epoch 372/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1737e-04Epoch 00371: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1708e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6875e-04\n",
      "Epoch 373/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.2713e-04Epoch 00372: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2600e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2897e-04\n",
      "Epoch 374/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2564e-04Epoch 00373: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2643e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2885e-04\n",
      "Epoch 375/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5378e-04Epoch 00374: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5326e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2647e-04\n",
      "Epoch 376/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1413e-04Epoch 00375: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1477e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2444e-04\n",
      "Epoch 377/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.1529e-04Epoch 00376: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1452e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8336e-04\n",
      "Epoch 378/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8932e-04Epoch 00377: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.8977e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4544e-04\n",
      "Epoch 379/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3454e-04Epoch 00378: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3465e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5171e-04\n",
      "Epoch 380/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.5077e-04Epoch 00379: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5002e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9493e-04\n",
      "Epoch 381/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1027e-04Epoch 00380: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0963e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2672e-04\n",
      "Epoch 382/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3021e-04Epoch 00381: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2966e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9966e-04\n",
      "Epoch 383/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5491e-04Epoch 00382: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5435e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6554e-04\n",
      "Epoch 384/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2471e-04Epoch 00383: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2443e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9032e-04\n",
      "Epoch 385/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0889e-04Epoch 00384: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0964e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5337e-04\n",
      "Epoch 386/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.1495e-04Epoch 00385: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1474e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2714e-04\n",
      "Epoch 387/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4363e-04Epoch 00386: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4275e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9970e-04\n",
      "Epoch 388/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2908e-04Epoch 00387: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2842e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3720e-04\n",
      "Epoch 389/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0221e-04Epoch 00388: loss improved from 0.60163 to 0.60162, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0263e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3266e-04\n",
      "Epoch 390/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2768e-04Epoch 00389: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2686e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2985e-04\n",
      "Epoch 391/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1007e-04Epoch 00390: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1057e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3360e-04\n",
      "Epoch 392/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0837e-04Epoch 00391: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0798e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0941e-04\n",
      "Epoch 393/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6286e-04Epoch 00392: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6588e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5340e-04\n",
      "Epoch 394/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 7.1703e-04Epoch 00393: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1756e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9086e-04\n",
      "Epoch 395/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1713e-04Epoch 00394: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1815e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2257e-04\n",
      "Epoch 396/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2194e-04Epoch 00395: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2294e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.6603e-04\n",
      "Epoch 397/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.0510e-04Epoch 00396: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.0501e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6065e-04\n",
      "Epoch 398/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4502e-04Epoch 00397: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4527e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0260e-04\n",
      "Epoch 399/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7990e-04Epoch 00398: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7914e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8466e-04\n",
      "Epoch 400/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5949e-04Epoch 00399: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.5881e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7669e-04\n",
      "Epoch 401/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1161e-04Epoch 00400: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1121e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.2971e-04\n",
      "Epoch 402/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3687e-04Epoch 00401: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3690e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.1137e-04\n",
      "Epoch 403/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2102e-04Epoch 00402: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2100e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2862e-04\n",
      "Epoch 404/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.2611e-04Epoch 00403: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2494e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3283e-04\n",
      "Epoch 405/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.0198e-04Epoch 00404: loss improved from 0.60162 to 0.60162, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0190e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1692e-04\n",
      "Epoch 406/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0089e-04Epoch 00405: loss improved from 0.60162 to 0.60162, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0027e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1113e-04\n",
      "Epoch 407/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3123e-04Epoch 00406: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3130e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2710e-04\n",
      "Epoch 408/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.0488e-04Epoch 00407: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0459e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1940e-04\n",
      "Epoch 409/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0893e-04Epoch 00408: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0753e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1486e-04\n",
      "Epoch 410/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.2570e-04Epoch 00409: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2470e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3321e-04\n",
      "Epoch 411/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0947e-04Epoch 00410: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0867e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4407e-04\n",
      "Epoch 412/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1941e-04Epoch 00411: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1822e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1907e-04\n",
      "Epoch 413/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1065e-04Epoch 00412: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0963e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1645e-04\n",
      "Epoch 414/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.0000e+00 - mean_squared_error: 6.0810e-04Epoch 00413: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0937e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1682e-04\n",
      "Epoch 415/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3107e-04Epoch 00414: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3406e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3137e-04\n",
      "Epoch 416/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9930e-04Epoch 00415: loss improved from 0.60162 to 0.60161, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9886e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8733e-04\n",
      "Epoch 417/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1002e-04Epoch 00416: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0905e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3310e-04\n",
      "Epoch 418/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.3615e-04Epoch 00417: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3601e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4468e-04\n",
      "Epoch 419/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1560e-04Epoch 00418: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1572e-04 - val_loss: 0.6052 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.9362e-04\n",
      "Epoch 420/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3194e-04Epoch 00419: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3125e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1283e-04\n",
      "Epoch 421/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.1147e-04Epoch 00420: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1303e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5762e-04\n",
      "Epoch 422/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4178e-04Epoch 00421: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4241e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6750e-04\n",
      "Epoch 423/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0711e-04Epoch 00422: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0674e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0394e-04\n",
      "Epoch 424/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9862e-04Epoch 00423: loss improved from 0.60161 to 0.60161, saving model to ./models/simple_cnn_oct.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9804e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2636e-04\n",
      "Epoch 425/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1421e-04Epoch 00424: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1378e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3622e-04\n",
      "Epoch 426/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0961e-04Epoch 00425: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0927e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6385e-04\n",
      "Epoch 427/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1826e-04Epoch 00426: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1844e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7486e-04\n",
      "Epoch 428/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3348e-04Epoch 00427: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3352e-04 - val_loss: 0.6051 - val_acc: 0.0000e+00 - val_mean_squared_error: 8.4326e-04\n",
      "Epoch 429/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.2365e-04Epoch 00428: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2312e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7096e-04\n",
      "Epoch 430/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1725e-04Epoch 00429: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1747e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6112e-04\n",
      "Epoch 431/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1658e-04Epoch 00430: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1646e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6859e-04\n",
      "Epoch 432/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3311e-04Epoch 00431: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3258e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7170e-04\n",
      "Epoch 433/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0914e-04Epoch 00432: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1141e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6737e-04\n",
      "Epoch 434/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7922e-04Epoch 00433: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7776e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7350e-04\n",
      "Epoch 435/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.1217e-04Epoch 00434: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1191e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1873e-04\n",
      "Epoch 436/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9713e-04Epoch 00435: loss improved from 0.60161 to 0.60161, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9624e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.6548e-04\n",
      "Epoch 437/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2889e-04Epoch 00436: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2876e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9474e-04\n",
      "Epoch 438/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1741e-04Epoch 00437: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1797e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2130e-04\n",
      "Epoch 439/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1013e-04Epoch 00438: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1191e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.1787e-04\n",
      "Epoch 440/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3483e-04Epoch 00439: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3412e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3225e-04\n",
      "Epoch 441/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.0063e-04Epoch 00440: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9995e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2809e-04\n",
      "Epoch 442/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.0000e+00 - mean_squared_error: 6.0812e-04Epoch 00441: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0795e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1962e-04\n",
      "Epoch 443/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.0000e+00 - mean_squared_error: 5.9163e-04Epoch 00442: loss improved from 0.60161 to 0.60160, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9133e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2063e-04\n",
      "Epoch 444/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2393e-04Epoch 00443: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2251e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5432e-04\n",
      "Epoch 445/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.7831e-04Epoch 00444: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7831e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.5779e-04\n",
      "Epoch 446/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1704e-04Epoch 00445: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1661e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3265e-04\n",
      "Epoch 447/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9813e-04Epoch 00446: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9780e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8982e-04\n",
      "Epoch 448/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0628e-04Epoch 00447: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0615e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.5683e-04\n",
      "Epoch 449/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7192e-04Epoch 00448: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.7082e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4135e-04\n",
      "Epoch 450/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.1701e-04Epoch 00449: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1743e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3384e-04\n",
      "Epoch 451/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2633e-04Epoch 00450: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2551e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.6255e-04\n",
      "Epoch 452/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.6925e-04Epoch 00451: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.6959e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2804e-04\n",
      "Epoch 453/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.3252e-04Epoch 00452: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3231e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2628e-04\n",
      "Epoch 454/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9630e-04Epoch 00453: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9728e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1653e-04\n",
      "Epoch 455/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.8582e-04Epoch 00454: loss improved from 0.60160 to 0.60158, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.8493e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.5071e-04\n",
      "Epoch 456/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.4880e-04Epoch 00455: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.4794e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3565e-04\n",
      "Epoch 457/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.2792e-04Epoch 00456: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2705e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2164e-04\n",
      "Epoch 458/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 5.9768e-04Epoch 00457: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9648e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7471e-04\n",
      "Epoch 459/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 5.9894e-04Epoch 00458: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9811e-04 - val_loss: 0.6045 - val_acc: 0.0000e+00 - val_mean_squared_error: 5.9707e-04\n",
      "Epoch 460/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.0000e+00 - mean_squared_error: 5.7782e-04Epoch 00459: loss improved from 0.60158 to 0.60156, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.7823e-04 - val_loss: 0.6045 - val_acc: 0.0000e+00 - val_mean_squared_error: 5.9942e-04\n",
      "Epoch 461/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 5.8088e-04Epoch 00460: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.8066e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1411e-04\n",
      "Epoch 462/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 5.9639e-04Epoch 00461: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9666e-04 - val_loss: 0.6045 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.0695e-04\n",
      "Epoch 463/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9646e-04Epoch 00462: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9643e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1878e-04\n",
      "Epoch 464/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1428e-04Epoch 00463: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1458e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2886e-04\n",
      "Epoch 465/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 6.1736e-04Epoch 00464: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1691e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7074e-04\n",
      "Epoch 466/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.0000e+00 - mean_squared_error: 6.0347e-04Epoch 00465: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0329e-04 - val_loss: 0.6045 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.0232e-04\n",
      "Epoch 467/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1774e-04Epoch 00466: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1718e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5190e-04\n",
      "Epoch 468/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.3006e-04Epoch 00467: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2967e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.8531e-04\n",
      "Epoch 469/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.5272e-04Epoch 00468: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.5207e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.8448e-04\n",
      "Epoch 470/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 5.8803e-04Epoch 00469: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.8765e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7465e-04\n",
      "Epoch 471/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0558e-04Epoch 00470: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0559e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3203e-04\n",
      "Epoch 472/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9628e-04Epoch 00471: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9580e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2648e-04\n",
      "Epoch 473/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2288e-04Epoch 00472: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2207e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4165e-04\n",
      "Epoch 474/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1571e-04Epoch 00473: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1543e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2619e-04\n",
      "Epoch 475/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.0000e+00 - mean_squared_error: 5.9320e-04Epoch 00474: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9259e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7540e-04\n",
      "Epoch 476/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 5.7854e-04Epoch 00475: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.7805e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.1536e-04\n",
      "Epoch 477/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1384e-04Epoch 00476: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1386e-04 - val_loss: 0.6045 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.0472e-04\n",
      "Epoch 478/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.7506e-04Epoch 00477: loss improved from 0.60156 to 0.60156, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.7565e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.5466e-04\n",
      "Epoch 479/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.0000e+00 - mean_squared_error: 5.8573e-04Epoch 00478: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.8649e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.3313e-04\n",
      "Epoch 480/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 6.1456e-04Epoch 00479: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1368e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.0087e-04\n",
      "Epoch 481/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 5.9053e-04Epoch 00480: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9103e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.4673e-04\n",
      "Epoch 482/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.1897e-04Epoch 00481: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.1833e-04 - val_loss: 0.6050 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.6762e-04\n",
      "Epoch 483/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0776e-04Epoch 00482: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0745e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.0712e-04\n",
      "Epoch 484/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9592e-04Epoch 00483: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9520e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7883e-04\n",
      "Epoch 485/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9948e-04Epoch 00484: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9868e-04 - val_loss: 0.6049 - val_acc: 0.0000e+00 - val_mean_squared_error: 7.4212e-04\n",
      "Epoch 486/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.0000e+00 - mean_squared_error: 6.0004e-04Epoch 00485: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0038e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1331e-04\n",
      "Epoch 487/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 6.0110e-04Epoch 00486: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0112e-04 - val_loss: 0.6059 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0012\n",
      "Epoch 488/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.0000e+00 - mean_squared_error: 7.1914e-04Epoch 00487: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6019 - acc: 0.0000e+00 - mean_squared_error: 7.1868e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2753e-04\n",
      "Epoch 489/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9308e-04Epoch 00488: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9267e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1997e-04\n",
      "Epoch 490/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.0000e+00 - mean_squared_error: 5.8257e-04Epoch 00489: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.8284e-04 - val_loss: 0.6045 - val_acc: 0.0000e+00 - val_mean_squared_error: 5.9775e-04\n",
      "Epoch 491/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.0000e+00 - mean_squared_error: 5.8750e-04Epoch 00490: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.8753e-04 - val_loss: 0.6048 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.9256e-04\n",
      "Epoch 492/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.0374e-04Epoch 00491: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0320e-04 - val_loss: 0.6045 - val_acc: 0.0000e+00 - val_mean_squared_error: 5.9663e-04\n",
      "Epoch 493/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.0000e+00 - mean_squared_error: 5.7470e-04Epoch 00492: loss improved from 0.60156 to 0.60156, saving model to ./models/simple_cnn_oct.hdf5\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.7459e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2028e-04\n",
      "Epoch 494/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2713e-04Epoch 00493: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2781e-04 - val_loss: 0.6047 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.7466e-04\n",
      "Epoch 495/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 5.9513e-04Epoch 00494: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.9491e-04 - val_loss: 0.6045 - val_acc: 0.0000e+00 - val_mean_squared_error: 5.9256e-04\n",
      "Epoch 496/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.8456e-04Epoch 00495: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.8406e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.0978e-04\n",
      "Epoch 497/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.8923e-04Epoch 00496: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 5.8910e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.1282e-04\n",
      "Epoch 498/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.2668e-04Epoch 00497: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6017 - acc: 0.0000e+00 - mean_squared_error: 6.2648e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.2648e-04\n",
      "Epoch 499/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0562e-04Epoch 00498: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0636e-04 - val_loss: 0.6045 - val_acc: 0.0000e+00 - val_mean_squared_error: 5.9804e-04\n",
      "Epoch 500/500\n",
      "660/666 [============================>.] - ETA: 0s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0533e-04Epoch 00499: loss did not improve\n",
      "666/666 [==============================] - 48s - loss: 0.6016 - acc: 0.0000e+00 - mean_squared_error: 6.0443e-04 - val_loss: 0.6046 - val_acc: 0.0000e+00 - val_mean_squared_error: 6.3950e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa573d27f50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=500,\n",
    "                batch_size=20,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder', histogram_freq=0, write_graph=True), model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Function to get saved keras model\n",
    "def read_model_json(jsonfilePath,h5filePath):\n",
    "    try:\n",
    "        json_file = open(jsonfilePath, 'r')\n",
    "        print json_file\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        print \"hello\"\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "         \n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(h5filePath)\n",
    "\n",
    "        return loaded_model\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gated_connections(gatePercentageFactor,inputLayer):\n",
    "    gateFactor = Input(tensor = K.variable([gatePercentageFactor]))\n",
    "    fractionG = Lambda(lambda x: x[0]*x[1])([inputLayer,gateFactor])\n",
    "    complement = Lambda(lambda x: x[0] - x[1])([inputLayer,fractionG])\n",
    "    \n",
    "    return gateFactor,fractionG,complement\n",
    "\n",
    "#x is conv layer\n",
    "#y is de-conv layer\n",
    "#gf is gating factor\n",
    "#fg is fractional input from gate\n",
    "#c is complement ie remaining fraction from the gate\n",
    "#jt joining tensor of convolution layer and previous de-conv layer \n",
    "\n",
    "def get_cnn_dsc_architecture(model_path=None):\n",
    "    \n",
    "    if(model_path is None):\n",
    "        sym_autoencoder = None\n",
    "    else:\n",
    "        sym_autoencoder = read_model_json(model_path[0],model_path[1])\n",
    "        print model_path[0],model_path[1]\n",
    "    if(sym_autoencoder is None):\n",
    "        input_img = Input(shape=(None,None,1), name = \"Image_input\")  # adapt this if using `channels_first` image data format\n",
    "        x1 = Conv2D(64, (4, 4), activation='relu', padding='same')(input_img)\n",
    "        gf1,fg1,c1 = get_gated_connections(0.1,x1)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(fg1)\n",
    "        x2 = Conv2D(64, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf2,fg2,c2 = get_gated_connections(0.2,x2)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(fg2)\n",
    "        x3 = Conv2D(128, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf3,fg3,c3 = get_gated_connections(0.3,x3)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x3)\n",
    "        x4 = Conv2D(256, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf4,fg4,c4 = get_gated_connections(0.4,x4)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x4)\n",
    "        x5 = Conv2D(512, (4, 4), activation='relu', padding='same')(x) \n",
    "\n",
    "        x = UpSampling2D((2, 2))(x5)\n",
    "        y1 = Conv2DTranspose(256, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt4 = Add()([y1,c4])\n",
    "        x = UpSampling2D((2, 2))(jt4)\n",
    "\n",
    "        y2 = Conv2DTranspose(128, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt3 = Add()([y2,c3])\n",
    "        x = UpSampling2D((2, 2))(jt3)\n",
    "\n",
    "        y3 = Conv2DTranspose(64, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt2 = Add()([y3,c2])\n",
    "        x = UpSampling2D((2, 2))(jt2)\n",
    "\n",
    "        jt1 = Add()([x,c1])\n",
    "        y4 = Conv2DTranspose(64, (4, 4), activation='relu', padding='same')(jt1)\n",
    "        y5 = Conv2DTranspose(1, (4, 4), activation='relu', padding='same')(y4) \n",
    "\n",
    "        layers = y5\n",
    "\n",
    "        sym_autoencoder = Model([input_img,gf1,gf2,gf3,gf4],layers)\n",
    "        sym_autoencoder.compile(optimizer='sgd', loss = 'mean_squared_error', metrics = ['accuracy','mean_squared_error'])\n",
    "        print \"Model created\"\n",
    "    else:\n",
    "        print \"Saved model loaded\"\n",
    "    print sym_autoencoder.summary()\n",
    "    return sym_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "Image_input (InputLayer)         (None, None, None, 1) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, None, None, 64 1088        Image_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "input_1 (InputLayer)             (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, None, None, 64 0           conv2d_1[0][0]                   \n",
      "                                                                   input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, None, None, 64 0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, None, None, 64 65600       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)                (None, None, None, 64 0           conv2d_2[0][0]                   \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, None, None, 64 0           lambda_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, None, None, 12 131200      max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, None, None, 12 0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, None, None, 25 524544      max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, None, None, 25 0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, None, None, 51 2097664     max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)   (None, None, None, 51 0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)                (None, None, None, 25 0           conv2d_4[0][0]                   \n",
      "                                                                   input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTransp (None, None, None, 25 2097408     up_sampling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)                (None, None, None, 25 0           conv2d_4[0][0]                   \n",
      "                                                                   lambda_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, None, None, 25 0           conv2d_transpose_1[0][0]         \n",
      "                                                                   lambda_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)   (None, None, None, 25 0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)                (None, None, None, 12 0           conv2d_3[0][0]                   \n",
      "                                                                   input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTransp (None, None, None, 12 524416      up_sampling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)                (None, None, None, 12 0           conv2d_3[0][0]                   \n",
      "                                                                   lambda_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, None, None, 12 0           conv2d_transpose_2[0][0]         \n",
      "                                                                   lambda_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)   (None, None, None, 12 0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTransp (None, None, None, 64 131136      up_sampling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)                (None, None, None, 64 0           conv2d_2[0][0]                   \n",
      "                                                                   lambda_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, None, None, 64 0           conv2d_transpose_3[0][0]         \n",
      "                                                                   lambda_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)   (None, None, None, 64 0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, None, None, 64 0           conv2d_1[0][0]                   \n",
      "                                                                   lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, None, None, 64 0           up_sampling2d_4[0][0]            \n",
      "                                                                   lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTransp (None, None, None, 64 65600       add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTransp (None, None, None, 1) 1025        conv2d_transpose_4[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 5,639,681\n",
      "Trainable params: 5,639,681\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5bf1989673d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msym_autoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cnn_dsc_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sys.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "sym_autoencoder = get_cnn_dsc_architecture()\n",
    "plot_model(autoencoder, to_file='sys.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint1 = ModelCheckpoint('./models/gated_cnn_autoencoder_oct.hdf5',monitor = 'loss', verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 666 samples, validate on 167 samples\n",
      "Epoch 1/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.0000e+00 - mean_squared_error: 0.0352Epoch 00000: loss improved from inf to 0.03510, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 181s - loss: 0.0351 - acc: 0.0000e+00 - mean_squared_error: 0.0351 - val_loss: 0.0064 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0064\n",
      "Epoch 2/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.0000e+00 - mean_squared_error: 0.0055Epoch 00001: loss improved from 0.03510 to 0.00553, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0055 - acc: 0.0000e+00 - mean_squared_error: 0.0055 - val_loss: 0.0058 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0058\n",
      "Epoch 3/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.0000e+00 - mean_squared_error: 0.0051Epoch 00002: loss improved from 0.00553 to 0.00505, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0051 - acc: 0.0000e+00 - mean_squared_error: 0.0051 - val_loss: 0.0056 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0056\n",
      "Epoch 4/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.0000e+00 - mean_squared_error: 0.0048Epoch 00003: loss improved from 0.00505 to 0.00477, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0048 - acc: 0.0000e+00 - mean_squared_error: 0.0048 - val_loss: 0.0053 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0053\n",
      "Epoch 5/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.0000e+00 - mean_squared_error: 0.0046Epoch 00004: loss improved from 0.00477 to 0.00459, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0046 - acc: 0.0000e+00 - mean_squared_error: 0.0046 - val_loss: 0.0055 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0055\n",
      "Epoch 6/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.0000e+00 - mean_squared_error: 0.0045Epoch 00005: loss improved from 0.00459 to 0.00449, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0045 - acc: 0.0000e+00 - mean_squared_error: 0.0045 - val_loss: 0.0052 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0052\n",
      "Epoch 7/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.0000e+00 - mean_squared_error: 0.0044Epoch 00006: loss improved from 0.00449 to 0.00438, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0044 - acc: 0.0000e+00 - mean_squared_error: 0.0044 - val_loss: 0.0051 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0051\n",
      "Epoch 8/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.0000e+00 - mean_squared_error: 0.0043Epoch 00007: loss improved from 0.00438 to 0.00433, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0043 - acc: 0.0000e+00 - mean_squared_error: 0.0043 - val_loss: 0.0050 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0050\n",
      "Epoch 9/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.0000e+00 - mean_squared_error: 0.0042Epoch 00008: loss improved from 0.00433 to 0.00422, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0042 - acc: 0.0000e+00 - mean_squared_error: 0.0042 - val_loss: 0.0049 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0049\n",
      "Epoch 10/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.0000e+00 - mean_squared_error: 0.0041Epoch 00009: loss improved from 0.00422 to 0.00413, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0041 - acc: 0.0000e+00 - mean_squared_error: 0.0041 - val_loss: 0.0049 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0049\n",
      "Epoch 11/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.0000e+00 - mean_squared_error: 0.0041Epoch 00010: loss improved from 0.00413 to 0.00410, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0041 - acc: 0.0000e+00 - mean_squared_error: 0.0041 - val_loss: 0.0047 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0047\n",
      "Epoch 12/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.0000e+00 - mean_squared_error: 0.0040Epoch 00011: loss improved from 0.00410 to 0.00403, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0040 - acc: 0.0000e+00 - mean_squared_error: 0.0040 - val_loss: 0.0049 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0049\n",
      "Epoch 13/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.0000e+00 - mean_squared_error: 0.0040Epoch 00012: loss improved from 0.00403 to 0.00399, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0040 - acc: 0.0000e+00 - mean_squared_error: 0.0040 - val_loss: 0.0048 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0048\n",
      "Epoch 14/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.0000e+00 - mean_squared_error: 0.0039Epoch 00013: loss improved from 0.00399 to 0.00393, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0039 - acc: 0.0000e+00 - mean_squared_error: 0.0039 - val_loss: 0.0051 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0051\n",
      "Epoch 15/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.0000e+00 - mean_squared_error: 0.0039Epoch 00014: loss improved from 0.00393 to 0.00390, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0039 - acc: 0.0000e+00 - mean_squared_error: 0.0039 - val_loss: 0.0047 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0047\n",
      "Epoch 16/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.0000e+00 - mean_squared_error: 0.0039Epoch 00015: loss improved from 0.00390 to 0.00386, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0039 - acc: 0.0000e+00 - mean_squared_error: 0.0039 - val_loss: 0.0047 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0047\n",
      "Epoch 17/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.0000e+00 - mean_squared_error: 0.0038Epoch 00016: loss improved from 0.00386 to 0.00381, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0038 - acc: 0.0000e+00 - mean_squared_error: 0.0038 - val_loss: 0.0046 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0046\n",
      "Epoch 18/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.0000e+00 - mean_squared_error: 0.0038Epoch 00017: loss improved from 0.00381 to 0.00376, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0038 - acc: 0.0000e+00 - mean_squared_error: 0.0038 - val_loss: 0.0046 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0046\n",
      "Epoch 19/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.0000e+00 - mean_squared_error: 0.0037Epoch 00018: loss improved from 0.00376 to 0.00374, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0037 - acc: 0.0000e+00 - mean_squared_error: 0.0037 - val_loss: 0.0048 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0048\n",
      "Epoch 20/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.0000e+00 - mean_squared_error: 0.0037Epoch 00019: loss improved from 0.00374 to 0.00370, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0037 - acc: 0.0000e+00 - mean_squared_error: 0.0037 - val_loss: 0.0046 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0046\n",
      "Epoch 21/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.0000e+00 - mean_squared_error: 0.0037Epoch 00020: loss improved from 0.00370 to 0.00369, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0037 - acc: 0.0000e+00 - mean_squared_error: 0.0037 - val_loss: 0.0044 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0044\n",
      "Epoch 22/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.0000e+00 - mean_squared_error: 0.0036Epoch 00021: loss improved from 0.00369 to 0.00363, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0036 - acc: 0.0000e+00 - mean_squared_error: 0.0036 - val_loss: 0.0049 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0049\n",
      "Epoch 23/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.0000e+00 - mean_squared_error: 0.0036Epoch 00022: loss improved from 0.00363 to 0.00362, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0036 - acc: 0.0000e+00 - mean_squared_error: 0.0036 - val_loss: 0.0042 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0042\n",
      "Epoch 24/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.0000e+00 - mean_squared_error: 0.0036Epoch 00023: loss improved from 0.00362 to 0.00359, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0036 - acc: 0.0000e+00 - mean_squared_error: 0.0036 - val_loss: 0.0042 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0042\n",
      "Epoch 25/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.0000e+00 - mean_squared_error: 0.0035Epoch 00024: loss improved from 0.00359 to 0.00353, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0035 - acc: 0.0000e+00 - mean_squared_error: 0.0035 - val_loss: 0.0043 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0043\n",
      "Epoch 26/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.0000e+00 - mean_squared_error: 0.0035Epoch 00025: loss improved from 0.00353 to 0.00351, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0035 - acc: 0.0000e+00 - mean_squared_error: 0.0035 - val_loss: 0.0042 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0042\n",
      "Epoch 27/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.0000e+00 - mean_squared_error: 0.0035Epoch 00026: loss improved from 0.00351 to 0.00346, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0035 - acc: 0.0000e+00 - mean_squared_error: 0.0035 - val_loss: 0.0043 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0043\n",
      "Epoch 28/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034Epoch 00027: loss improved from 0.00346 to 0.00344, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034 - val_loss: 0.0048 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0048\n",
      "Epoch 29/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034Epoch 00028: loss improved from 0.00344 to 0.00343, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034 - val_loss: 0.0043 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0043\n",
      "Epoch 30/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034Epoch 00029: loss improved from 0.00343 to 0.00335, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034 - val_loss: 0.0042 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0042\n",
      "Epoch 31/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.0000e+00 - mean_squared_error: 0.0033Epoch 00030: loss improved from 0.00335 to 0.00334, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0033 - acc: 0.0000e+00 - mean_squared_error: 0.0033 - val_loss: 0.0040 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0040\n",
      "Epoch 32/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034Epoch 00031: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034 - val_loss: 0.0040 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0040\n",
      "Epoch 33/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.0000e+00 - mean_squared_error: 0.0033Epoch 00032: loss improved from 0.00334 to 0.00331, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0033 - acc: 0.0000e+00 - mean_squared_error: 0.0033 - val_loss: 0.0043 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0043\n",
      "Epoch 34/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.0000e+00 - mean_squared_error: 0.0033Epoch 00033: loss improved from 0.00331 to 0.00328, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0033 - acc: 0.0000e+00 - mean_squared_error: 0.0033 - val_loss: 0.0041 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0041\n",
      "Epoch 35/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032Epoch 00034: loss improved from 0.00328 to 0.00324, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 36/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032Epoch 00035: loss improved from 0.00324 to 0.00321, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 37/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032Epoch 00036: loss improved from 0.00321 to 0.00321, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032 - val_loss: 0.0041 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0041\n",
      "Epoch 38/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031Epoch 00037: loss improved from 0.00321 to 0.00313, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 39/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032Epoch 00038: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032 - val_loss: 0.0041 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0041\n",
      "Epoch 40/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031Epoch 00039: loss improved from 0.00313 to 0.00313, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 41/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031Epoch 00040: loss improved from 0.00313 to 0.00313, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 42/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031Epoch 00041: loss improved from 0.00313 to 0.00308, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 43/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031Epoch 00042: loss improved from 0.00308 to 0.00307, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 44/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030Epoch 00043: loss improved from 0.00307 to 0.00304, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 45/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030Epoch 00044: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030 - val_loss: 0.0041 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0041\n",
      "Epoch 46/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030Epoch 00045: loss improved from 0.00304 to 0.00301, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 170s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 47/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030Epoch 00046: loss improved from 0.00301 to 0.00298, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 48/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030Epoch 00047: loss improved from 0.00298 to 0.00296, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030 - val_loss: 0.0037 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0037\n",
      "Epoch 49/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00048: loss improved from 0.00296 to 0.00291, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0043 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0043\n",
      "Epoch 50/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00049: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 51/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00050: loss improved from 0.00291 to 0.00289, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 52/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00051: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0040 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0040\n",
      "Epoch 53/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00052: loss improved from 0.00289 to 0.00287, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0040 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0040\n",
      "Epoch 54/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00053: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 55/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00054: loss improved from 0.00287 to 0.00285, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 56/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028Epoch 00055: loss improved from 0.00285 to 0.00281, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028 - val_loss: 0.0037 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0037\n",
      "Epoch 57/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028Epoch 00056: loss improved from 0.00281 to 0.00280, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 58/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028Epoch 00057: loss improved from 0.00280 to 0.00278, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028 - val_loss: 0.0037 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0037\n",
      "Epoch 59/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028Epoch 00058: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 60/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028Epoch 00059: loss improved from 0.00278 to 0.00276, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028 - val_loss: 0.0037 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0037\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00060: loss improved from 0.00276 to 0.00274, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 62/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028Epoch 00061: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 63/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00062: loss improved from 0.00274 to 0.00271, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 64/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00063: loss improved from 0.00271 to 0.00271, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 65/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00064: loss improved from 0.00271 to 0.00266, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 66/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00065: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 67/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00066: loss improved from 0.00266 to 0.00265, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 68/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00067: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 69/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00068: loss improved from 0.00265 to 0.00265, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 70/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00069: loss improved from 0.00265 to 0.00263, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 71/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00070: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 72/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00071: loss improved from 0.00263 to 0.00261, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 73/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00072: loss improved from 0.00261 to 0.00260, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 74/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00073: loss improved from 0.00260 to 0.00259, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 75/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00074: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 76/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00075: loss improved from 0.00259 to 0.00257, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 77/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00076: loss improved from 0.00257 to 0.00256, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 78/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00077: loss improved from 0.00256 to 0.00253, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 79/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00078: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 80/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00079: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 81/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00080: loss improved from 0.00253 to 0.00247, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 82/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00081: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 83/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00082: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 84/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00083: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 85/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00084: loss improved from 0.00247 to 0.00247, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 86/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00085: loss improved from 0.00247 to 0.00247, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 87/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00086: loss improved from 0.00247 to 0.00246, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 88/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00087: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 89/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00088: loss improved from 0.00246 to 0.00244, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 90/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00089: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 91/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00090: loss improved from 0.00244 to 0.00244, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 92/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00091: loss improved from 0.00244 to 0.00242, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 93/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00092: loss improved from 0.00242 to 0.00241, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 94/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00093: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 95/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00094: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 96/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00095: loss improved from 0.00241 to 0.00240, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 97/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00096: loss improved from 0.00240 to 0.00233, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 98/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00097: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 99/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00098: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 100/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00099: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 101/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00100: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 102/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00101: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 103/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00102: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0041 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0041\n",
      "Epoch 104/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00103: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 105/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00104: loss improved from 0.00233 to 0.00231, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 106/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00105: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 107/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00106: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 108/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00107: loss improved from 0.00231 to 0.00229, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 109/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00108: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 110/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00109: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 111/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00110: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 112/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00111: loss improved from 0.00229 to 0.00229, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 113/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00112: loss improved from 0.00229 to 0.00227, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 114/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00113: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 115/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00114: loss improved from 0.00227 to 0.00227, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0042 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0042\n",
      "Epoch 116/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00115: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 117/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00116: loss improved from 0.00227 to 0.00226, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 118/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00117: loss improved from 0.00226 to 0.00221, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 119/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00118: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 120/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00119: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 121/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00120: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 122/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00121: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0037\n",
      "Epoch 123/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00122: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 124/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00123: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 125/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00124: loss improved from 0.00221 to 0.00220, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 126/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00125: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 127/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00126: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 128/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00127: loss improved from 0.00220 to 0.00220, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 129/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00128: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 130/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00129: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 131/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00130: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 132/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00131: loss improved from 0.00220 to 0.00219, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 133/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00132: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 134/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00133: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 135/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00134: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 136/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00135: loss improved from 0.00219 to 0.00216, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 137/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00136: loss improved from 0.00216 to 0.00215, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 138/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00137: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 139/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00138: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 140/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00139: loss improved from 0.00215 to 0.00213, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 141/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00140: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 142/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00141: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 143/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00142: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 144/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00143: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 145/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00144: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 146/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00145: loss improved from 0.00213 to 0.00212, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 147/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00146: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 148/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00147: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 149/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00148: loss improved from 0.00212 to 0.00208, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 150/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00149: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 151/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00150: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 152/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00151: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 153/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00152: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 154/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00153: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 155/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00154: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 156/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00155: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 157/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00156: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 158/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00157: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 159/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00158: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 160/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00159: loss did not improve\n",
      "666/666 [==============================] - 171s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 161/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00160: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 162/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00161: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 163/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00162: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 164/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00163: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 165/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00164: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 166/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00165: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 167/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00166: loss improved from 0.00208 to 0.00207, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 168/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00167: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 169/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00168: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 170/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00169: loss improved from 0.00207 to 0.00206, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 171/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00170: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 172/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00171: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 173/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00172: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 174/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00173: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 175/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00174: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 176/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00175: loss improved from 0.00206 to 0.00204, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 177/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00176: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 178/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00177: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 179/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00178: loss improved from 0.00204 to 0.00203, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 180/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00179: loss improved from 0.00203 to 0.00200, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 181/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00180: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 182/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00181: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 183/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00182: loss improved from 0.00200 to 0.00198, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 184/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00183: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 185/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00184: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 186/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00185: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 187/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00186: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 188/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00187: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 189/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00188: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 190/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00189: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 191/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00190: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 192/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00191: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 193/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00192: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 194/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00193: loss improved from 0.00198 to 0.00198, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 195/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00194: loss improved from 0.00198 to 0.00197, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 196/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00195: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 197/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00196: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 198/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00197: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 199/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00198: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 200/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00199: loss improved from 0.00197 to 0.00197, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 201/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00200: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 202/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00201: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 203/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00202: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 204/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00203: loss improved from 0.00197 to 0.00196, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 205/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00204: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 206/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00205: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 207/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00206: loss improved from 0.00196 to 0.00193, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 208/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00207: loss improved from 0.00193 to 0.00192, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 209/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00208: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 210/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00209: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 211/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00210: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 212/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00211: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 213/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00212: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 214/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00213: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 215/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00214: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 216/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00215: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 217/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00216: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 218/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00217: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 219/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00218: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 220/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00219: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 221/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00220: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 222/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00221: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 223/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00222: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 224/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00223: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 225/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00224: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 226/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00225: loss improved from 0.00192 to 0.00192, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 227/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00226: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 228/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00227: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 229/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00228: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 230/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00229: loss improved from 0.00192 to 0.00191, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 231/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00230: loss improved from 0.00191 to 0.00191, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 232/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00231: loss improved from 0.00191 to 0.00191, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 233/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00232: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 234/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00233: loss improved from 0.00191 to 0.00188, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 235/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00234: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 236/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00235: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 237/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00236: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00237: loss improved from 0.00188 to 0.00186, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 239/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00238: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 240/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00239: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 241/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00240: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 242/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00241: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 243/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00242: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 244/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00243: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 245/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00244: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 246/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00245: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 247/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00246: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 248/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00247: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 249/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00248: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 250/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00249: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 251/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00250: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 252/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00251: loss improved from 0.00186 to 0.00186, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 253/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00252: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 254/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00253: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 255/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00254: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 256/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00255: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 257/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00256: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 258/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00257: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 259/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00258: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 260/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00259: loss improved from 0.00186 to 0.00184, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 261/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00260: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 262/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00261: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 263/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00262: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 264/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00263: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 265/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00264: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 266/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00265: loss improved from 0.00184 to 0.00181, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 267/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00266: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 268/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00267: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 269/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00268: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 270/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00269: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 271/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00270: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 272/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00271: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 273/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00272: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 274/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00273: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 275/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00274: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 276/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00275: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 277/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00276: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 278/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00277: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 279/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00278: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 280/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00279: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 281/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00280: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 282/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00281: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 283/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00282: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 284/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00283: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 285/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00284: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 286/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00285: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 287/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00286: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 288/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00287: loss improved from 0.00181 to 0.00180, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 289/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00288: loss improved from 0.00180 to 0.00179, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 290/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00289: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 291/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00290: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 292/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00291: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 293/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00292: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 294/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00293: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 295/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00294: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 296/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00295: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 297/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00296: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 298/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00297: loss improved from 0.00179 to 0.00176, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 299/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00298: loss improved from 0.00176 to 0.00176, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 300/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00299: loss improved from 0.00176 to 0.00176, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 301/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00300: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 302/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00301: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 303/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00302: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 304/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00303: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 305/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00304: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 306/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00305: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00306: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 308/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00307: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 309/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00308: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 310/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00309: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 311/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00310: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 312/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00311: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 313/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00312: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 314/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00313: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 315/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00314: loss improved from 0.00176 to 0.00175, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 316/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00315: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 317/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00316: loss improved from 0.00175 to 0.00173, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 318/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00317: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 319/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00318: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 320/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00319: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 321/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00320: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 322/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00321: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 323/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00322: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0056 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0056\n",
      "Epoch 324/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00323: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 325/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00324: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 326/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00325: loss improved from 0.00173 to 0.00172, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 327/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00326: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 328/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00327: loss improved from 0.00172 to 0.00170, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 329/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00328: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 330/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00329: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 331/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00330: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 332/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00331: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 333/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00332: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 334/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00333: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 335/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00334: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 336/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00335: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 337/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00336: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 338/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00337: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 339/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00338: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 340/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00339: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 341/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00340: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 342/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00341: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 343/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00342: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 344/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00343: loss improved from 0.00170 to 0.00168, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 345/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00344: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 346/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00345: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 347/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00346: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 348/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00347: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 349/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00348: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 350/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00349: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 351/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00350: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 352/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00351: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 353/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00352: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 354/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00353: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 355/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00354: loss improved from 0.00168 to 0.00165, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 356/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00355: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 357/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00356: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 358/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00357: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 359/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00358: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 360/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00359: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 361/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00360: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 362/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00361: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 363/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00362: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 364/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00363: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 365/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00364: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 366/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00365: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 367/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00366: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 368/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00367: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 369/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00368: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 370/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00369: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 371/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00370: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 372/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00371: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 373/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00372: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 374/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00373: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 375/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00374: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 376/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00375: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 377/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00376: loss improved from 0.00165 to 0.00165, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 378/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00377: loss improved from 0.00165 to 0.00163, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 379/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00378: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 380/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00379: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 381/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00380: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 382/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00381: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 383/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00382: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 384/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00383: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 385/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00384: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 386/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00385: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0047 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0047\n",
      "Epoch 387/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00386: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 388/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00387: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 389/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00388: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 390/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00389: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 391/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00390: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 392/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00391: loss improved from 0.00163 to 0.00161, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 393/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00392: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 394/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00393: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 395/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00394: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 396/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00395: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 397/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00396: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 398/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00397: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 399/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00398: loss improved from 0.00161 to 0.00160, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 400/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00399: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 401/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00400: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 402/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00401: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 403/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00402: loss improved from 0.00160 to 0.00159, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 404/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00403: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 405/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00404: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 406/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00405: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 407/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00406: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 408/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00407: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 409/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00408: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 410/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00409: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0051 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0051\n",
      "Epoch 411/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00410: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 412/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00411: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 413/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00412: loss improved from 0.00159 to 0.00156, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 414/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00413: loss improved from 0.00156 to 0.00155, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 415/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00414: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 416/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015Epoch 00415: loss improved from 0.00155 to 0.00155, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 417/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00416: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 418/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015Epoch 00417: loss improved from 0.00155 to 0.00153, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 419/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00418: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 420/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00419: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 421/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015Epoch 00420: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 422/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/666 [======>.......................] - ETA: 117s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017"
     ]
    }
   ],
   "source": [
    "sym_autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=500,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/gated_cnn_autoencoder', \n",
    "                                       histogram_freq=0,\n",
    "                                       write_graph=True),model_checkpoint1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = load_model('./models/simple_cnn_autoencoder.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.imshow(out_autoencoder[0])\n",
    "\n",
    "def predict_save(model,image_path):\n",
    "    test = cv2.imread(image_path,0)\n",
    "    test = np.array(test)\n",
    "    test = test.reshape(1,test.shape[0],test.shape[1],1)\n",
    "    test =  test/255.0\n",
    "    \n",
    "    out = model.predict(test,verbose=1)\n",
    "    cv2.imwrite(\"out.png\",(out[0]*255))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "predict_save(autoencoder,'./data/standard_test_images/noise/image21.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    cv2.imwrite(\"./data/denoise-cifar-bw/\"+str(i)+\".png\",out_autoencoder[i]*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_psnr(imageA,imageB):\n",
    "    maxI = 1.0\n",
    "    try:\n",
    "        return 20*math.log10(maxI) - 10*math.log10(compare_mse(imageA.flatten(),imageB.flatten()))\n",
    "    except:\n",
    "        return 20*math.log10(maxI)\n",
    "\n",
    "def get_psnr_result(x_test, out):\n",
    "    psnr_sum = 0\n",
    "    for i in range(out.shape[0]):\n",
    "        psnr_sum += compare_psnr(x_test[i].reshape(32,32,1),out[i].reshape(32,32,1),data_range=255)\n",
    "        \n",
    "    return 1.0*psnr_sum/out.shape[0];\n",
    "\n",
    "def get_ssim_result(originalSet,noisySet):\n",
    "    ssim_sum = 0\n",
    "    originalSet = originalSet.reshape(originalSet.shape[0],32,32,1)\n",
    "    noisySet = noisySet.reshape(noisySet.shape[0],32,32,1)\n",
    "    for i in range(originalSet.shape[0]):\n",
    "        ssim_sum += ssim(originalSet[i], noisySet[i],data_range=originalSet[i].max() - noisySet[i].min(), multichannel=True)\n",
    "    return 1.0*ssim_sum/originalSet.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bm3d_denoise(noisy_image):\n",
    "    noisy_image = noisy_image.reshape(noisy_image.shape[0],32,32)\n",
    "    denoised = []\n",
    "    count = 1\n",
    "    for i in range(noisy_image.shape[0]):\n",
    "        Basic_img = bm3d.BM3D_1st_step(noisy_image[i])\n",
    "        Final_img = bm3d.BM3D_2nd_step(Basic_img, noisy_image[i])\n",
    "        denoised.append(Final_img)\n",
    "        if (count%10 == 0):\n",
    "            print (str(count)+ \"images denoised\")\n",
    "        count+=1\n",
    "        \n",
    "    return np.array(denoised)\n",
    "\n",
    "def nlm_denoise(noisy_image):\n",
    "    noisy_image = noisy_image.reshape(noisy_image.shape[0],32,32,1)\n",
    "    denoised = []\n",
    "    count = 1\n",
    "    \n",
    "    for image in noisy_image:\n",
    "        denoised_image = denoise_nl_means(image, 7, 11, 0.5,multichannel = False)\n",
    "        denoised.append(denoised_image)\n",
    "        if(count%100 == 0) :\n",
    "            print(str(count)+\" images denoised\")\n",
    "        count+=1\n",
    "    return np.array(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10000, 32, 32, 1), (10000, 32, 32, 1))\n",
      "458.092258419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.066576979897317"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (test_images.shape,out_autoencoder.shape)\n",
    "print (compare_mse(test_images[0].flatten(),(out_autoencoder[0]*255.).flatten()))\n",
    "get_psnr_result(out_autoencoder*255.,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_sym_autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-c6ec004857a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_sym_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_sym_autoencoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_psnr_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_sym_autoencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_sym_autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "print (test_images.shape,out_sym_autoencoder.shape)\n",
    "print (mean_squared_error(test_images[0].flatten(),out_sym_autoencoder[0].flatten()))\n",
    "get_psnr_result(out_sym_autoencoder,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bm3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "/home/travis/miniconda/conda-bld/work/opencv-2.4.11/modules/core/src/dxt.cpp:2330: error: (-213) Odd-size DCT's are not implemented in function dct\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-14100dc74e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbm3d_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm3d_denoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-5e994559fb52>\u001b[0m in \u001b[0;36mbm3d_denoise\u001b[0;34m(noisy_image)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mBasic_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBM3D_1st_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mFinal_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBM3D_2nd_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasic_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdenoised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFinal_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/Image-Denoising-with-Convolutional-Denoising-Autoencoders/bm3d.pyc\u001b[0m in \u001b[0;36mBM3D_1st_step\u001b[0;34m(_noisyImg)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHeight_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mm_blockPoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocate_blk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblk_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_Size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mSimilar_Blks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStep1_fast_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_noisyImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_blockPoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mSimilar_Blks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatis_nonzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStep1_3DFiltering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimilar_Blks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mAggregation_hardthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimilar_Blks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBasic_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_Wight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatis_nonzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_Kaiser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/Image-Denoising-with-Convolutional-Denoising-Autoencoders/bm3d.pyc\u001b[0m in \u001b[0;36mStep1_fast_match\u001b[0;34m(_noisyImg, _BlockPoint)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mtem_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_noisyImg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpresent_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpresent_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBlk_Size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpresent_y\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBlk_Size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdct_Tem_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtem_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mm_Distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdct_img\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdct_Tem_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBlk_Size\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /home/travis/miniconda/conda-bld/work/opencv-2.4.11/modules/core/src/dxt.cpp:2330: error: (-213) Odd-size DCT's are not implemented in function dct\n"
     ]
    }
   ],
   "source": [
    "noisy_test_images.shape\n",
    "bm3d_out = bm3d_denoise(noisy_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm3d_out_norm = bm3d_out.astype('float64')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_psnr_result(bm3d_out_norm,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-c8bb56579059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlm_denoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnlm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-165-85427f2402e9>\u001b[0m in \u001b[0;36mnlm_denoise\u001b[0;34m(noisy_image)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoisy_image\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mdenoised_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenoise_nl_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultichannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mdenoised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenoised_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/skimage/restoration/non_local_means.pyc\u001b[0m in \u001b[0;36mdenoise_nl_means\u001b[0;34m(image, patch_size, patch_distance, h, multichannel, fast_mode)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfast_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             return np.array(_fast_nl_means_denoising_3d(image, s=patch_size,\n\u001b[0;32m--> 127\u001b[0;31m                                                         d=patch_distance, h=h))\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             return np.array(_nl_means_denoising_3d(image, patch_size,\n",
      "\u001b[0;32mskimage/restoration/_nl_means_denoising.pyx\u001b[0m in \u001b[0;36mskimage.restoration._nl_means_denoising._fast_nl_means_denoising_3d (skimage/restoration/_nl_means_denoising.c:8689)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36mzeros_like\u001b[0;34m(a, dtype, order, subok)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \"\"\"\n\u001b[1;32m     89\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mzeros\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(noisy_test_images.shape)\n",
    "nlm_out = nlm_denoise(noisy_test_images*255.)\n",
    "nlm_out = nlm_out.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32) (10000, 32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.414818545893922"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print nlm_out.shape,test_images.shape\n",
    "get_psnr_result(nlm_out,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69608629344603479"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,out_autoencoder*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.718734871276698"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,out_sym_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_ssim_result(test_images,bm3d_out_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49438484841716263"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,nlm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"./models/oct_epoch_500_batch_20/simple_cnn_oct.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 64)    640       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 1)     577       \n",
      "=================================================================\n",
      "Total params: 112,001\n",
      "Trainable params: 112,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_images_from_folder_with_names(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path,filename),0)\n",
    "        if img is not None:\n",
    "            images.append((filename,img))\n",
    "    return images\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 900)\n"
     ]
    }
   ],
   "source": [
    "#Adding Gamma noise\n",
    "test_image = cv2.imread('./test_data/5.tif',0)\n",
    "test_image = cv2.resize(test_image,(900,448),interpolation = cv2.INTER_CUBIC)\n",
    "print test_image.shape\n",
    "gamma_param = [(3,2),(4,3),(4,4),(6,6),(8,7)]\n",
    "for param in gamma_param:\n",
    "    shape = param[0]\n",
    "    scale = param[1]\n",
    "    noise = np.random.gamma(shape,scale,test_image.shape)\n",
    "    noisy_img = np.clip(noise + test_image,0.,255.)\n",
    "    cv2.imwrite('./test_data/noisy/oct_shape_'+str(shape)+'_scale_'+str(scale)+'.tif',noisy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_set = read_images_from_folder_with_names('./test_data/noisy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oct_shape_8_scale_7.tif', array([[179,  93, 157, ..., 124, 137, 138],\n",
       "         [150, 115, 103, ..., 134, 118, 149],\n",
       "         [156,  86, 123, ..., 104, 109, 109],\n",
       "         ..., \n",
       "         [126,  69,  81, ..., 119, 110,  83],\n",
       "         [ 74,  77,  78, ..., 108,  80, 101],\n",
       "         [144,  79, 137, ..., 117, 113,  87]], dtype=uint8)),\n",
       " ('oct_shape_6_scale_6.tif', array([[136, 110,  90, ...,  87,  85,  97],\n",
       "         [ 98,  91, 162, ...,  95, 103, 126],\n",
       "         [141, 105, 111, ..., 120,  94, 103],\n",
       "         ..., \n",
       "         [ 78, 102,  84, ...,  88,  61,  85],\n",
       "         [ 71,  81,  74, ...,  80,  86,  80],\n",
       "         [ 78,  86, 107, ...,  92, 100,  62]], dtype=uint8)),\n",
       " ('oct_shape_4_scale_3.tif', array([[ 84,  76,  88, ...,  62,  86,  93],\n",
       "         [ 77,  92, 101, ...,  79,  76,  84],\n",
       "         [100,  71,  97, ...,  85,  86,  78],\n",
       "         ..., \n",
       "         [ 41,  63,  62, ...,  49,  61,  56],\n",
       "         [ 53,  47,  64, ...,  47,  72,  55],\n",
       "         [ 54,  48,  48, ...,  65,  58,  59]], dtype=uint8)),\n",
       " ('oct_shape_4_scale_4.tif', array([[99, 79, 86, ..., 66, 80, 78],\n",
       "         [79, 95, 87, ..., 81, 76, 84],\n",
       "         [76, 82, 80, ..., 85, 86, 91],\n",
       "         ..., \n",
       "         [50, 56, 61, ..., 46, 80, 57],\n",
       "         [62, 56, 55, ..., 54, 55, 61],\n",
       "         [60, 44, 61, ..., 80, 54, 68]], dtype=uint8)),\n",
       " ('oct_shape_3_scale_2.tif', array([[79, 72, 80, ..., 63, 81, 78],\n",
       "         [76, 82, 81, ..., 79, 69, 82],\n",
       "         [73, 72, 85, ..., 75, 76, 77],\n",
       "         ..., \n",
       "         [43, 54, 61, ..., 39, 58, 56],\n",
       "         [52, 44, 53, ..., 52, 48, 53],\n",
       "         [44, 45, 48, ..., 62, 54, 48]], dtype=uint8))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s\n",
      "(448, 900, 1) (448, 900, 1)\n",
      "12.0867435625 0.362787193898\n",
      "oct_shape_8_scale_7.\n",
      "(1, 448, 900, 1)\n",
      "1/1 [==============================] - 0s\n",
      "(448, 900, 1) (448, 900, 1)\n",
      "15.4330490672 0.506303201293\n",
      "oct_shape_6_scale_6.\n",
      "(1, 448, 900, 1)\n",
      "1/1 [==============================] - 0s\n",
      "(448, 900, 1) (448, 900, 1)\n",
      "23.9350194443 0.82419290964\n",
      "oct_shape_4_scale_3.\n",
      "(1, 448, 900, 1)\n",
      "1/1 [==============================] - 0s\n",
      "(448, 900, 1) (448, 900, 1)\n",
      "21.6362136498 0.753850963892\n",
      "oct_shape_4_scale_4.\n",
      "(1, 448, 900, 1)\n",
      "1/1 [==============================] - 0s\n",
      "(448, 900, 1) (448, 900, 1)\n",
      "27.3646630162 0.891757839356\n",
      "oct_shape_3_scale_2.\n",
      "(1, 448, 900, 1)\n"
     ]
    }
   ],
   "source": [
    "for idx,test_image in enumerate(test_image_set):\n",
    "    #test_image_norm = cv2.resize(test_image,(256,128),interpolation = cv2.INTER_CUBIC)\n",
    "    test_image_norm = [test_image[1]]\n",
    "    test_image_norm = np.array(test_image_norm,dtype=np.float32)\n",
    "    test_image_norm = test_image_norm/255.\n",
    "    test_image_norm = test_image_norm.reshape((test_image_norm.shape[0],test_image_norm.shape[1],test_image_norm.shape[2],1))\n",
    "    \n",
    "    out_image = model.predict(test_image_norm,verbose=1)\n",
    "    print test_image_norm[0].shape,out_image[0].shape\n",
    "    psnr = compare_psnr(test_image_norm[0]*255.,out_image[0]*255.,data_range=256)\n",
    "    ssim = compare_ssim(test_image_norm[0],out_image[0],multichannel=True)\n",
    "    print psnr,ssim\n",
    "    print test_image[0][:-3]\n",
    "    cv2.imwrite('./test_data/denoised/'+test_image[0][:-3] + '_'+str(psnr)+'.tif',out_image[0]*255.)\n",
    "    print test_image_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "out_image = model.predict(test_image_norm,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('denoise_test.tif',out_image[0]*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 900)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
