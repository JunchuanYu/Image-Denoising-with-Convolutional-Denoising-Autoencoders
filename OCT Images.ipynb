{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import skimage\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage import data, img_as_float\n",
    "from skimage.restoration import denoise_nl_means\n",
    "from skimage.measure import compare_ssim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "from random import shuffle\n",
    "import math\n",
    "from keras.models import model_from_json, load_model\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.core import Lambda\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "from random import randint\n",
    "from utilities import *\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,:,0], rgb[:,:,:,1], rgb[:,:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray\n",
    "\n",
    "def read_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path,filename),0)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_images(src_path,dest_path,sizeX,sizeY):\n",
    "    images = []\n",
    "    width,height = sizeX,sizeY\n",
    "    for filename in os.listdir(src_path):\n",
    "        img = cv2.imread(src_path + filename)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    cnt =1\n",
    "    for img in images:\n",
    "        im2 = cv2.resize(img,(width, height),interpolation = cv2.INTER_CUBIC)\n",
    "        \n",
    "        \n",
    "        ext = \".png\"\n",
    "        cv2.imwrite(dest_path + \"image\" +  str(cnt) + ext,im2)\n",
    "        cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_images = read_images_from_folder('./data/oct_gt/')\n",
    "raw_images = np.resize(raw_images,(raw_images.shape[0],448,900,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding noise to images\n",
    "def add_noise(images):\n",
    "    \n",
    "    noisy_set = []\n",
    "    for image in images:\n",
    "        print len(noisy_set)\n",
    "        for shape in xrange(2,9,1):\n",
    "            for scale in xrange(2,9,1):\n",
    "                noise = np.random.gamma(shape,scale,image.shape)\n",
    "                noisy_set.append((image,np.clip(noise + image,0.,255.)))\n",
    "    shuffle(noisy_set)\n",
    "    return np.array(noisy_set)\n",
    "   \n",
    "#Shuffle the noisy image ground truth pair to randomize the noise distribution in the dataset\n",
    "def expand_pair(noisy_set):   \n",
    "    ground_truth=[]\n",
    "    noisy_images = []\n",
    "    for i in range(noisy_set.shape[0]):\n",
    "        ground_truth.append(noisy_set[i][0].reshape((noisy_set[i][0].shape[0],noisy_set[i][0].shape[1],1)))\n",
    "        #print( str(noisy_set[i][0].shape[0]) +\" \"+ str(noisy_set[i][0].shape[1]))\n",
    "        noisy_images.append(noisy_set[i][1].reshape((noisy_set[i][1].shape[0],noisy_set[i][1].shape[1],1)))\n",
    "    return np.array(ground_truth), np.array(noisy_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "49\n",
      "98\n",
      "147\n",
      "196\n",
      "245\n",
      "294\n",
      "343\n",
      "392\n",
      "441\n",
      "490\n",
      "539\n",
      "588\n",
      "637\n",
      "686\n",
      "735\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "noisy_set = add_noise(raw_images)\n",
    "for i in range(noisy_set.shape[0]):\n",
    "    cv2.imwrite(\"./data/oct_noisy/\"+str(i)+\".tif\",noisy_set[i][1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((833, 448, 900, 1), (833, 448, 900, 1), (833, 2, 448, 900, 1))\n"
     ]
    }
   ],
   "source": [
    "#Shuffling and adding noise to the dataset\n",
    "ground_truth,noisy_images = expand_pair(noisy_set)\n",
    "print (ground_truth.shape, noisy_images.shape, noisy_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print np.std(ground_truth/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ground_truth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2c25719b28fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresized_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mground_truth_rs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mnoisy_images_rs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ground_truth' is not defined"
     ]
    }
   ],
   "source": [
    "def resize_images(images,size):\n",
    "    resized_images = []\n",
    "    \n",
    "    for img in images:\n",
    "        im2 = cv2.resize(img,size,interpolation = cv2.INTER_CUBIC)\n",
    "        resized_images.append(im2)\n",
    "    \n",
    "    resized_images = np.array(resized_images)\n",
    "    resized_images = np.reshape(resized_images,(resized_images.shape[0],resized_images.shape[1],resized_images.shape[2],1))\n",
    "    \n",
    "    return resized_images\n",
    "\n",
    "ground_truth_rs = resize_images(ground_truth,(256,128))\n",
    "noisy_images_rs = resize_images(noisy_images,(256,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(833, 128, 256, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_images_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(noisy_images_rs.shape[0]):\n",
    "    cv2.imwrite(\"./data/oct_noisy_resized/\"+str(i)+\".tif\",noisy_images_rs[i])  \n",
    "    \n",
    "for i in range(ground_truth_rs.shape[0]):\n",
    "    cv2.imwrite(\"./data/oct_gt_resized/\"+str(i)+\".tif\",ground_truth_rs[i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_rs = read_images_from_folder('./data/oct_gt_resized/')\n",
    "ground_truth_rs = np.resize(ground_truth_rs,(ground_truth_rs.shape[0],ground_truth_rs.shape[1],ground_truth_rs.shape[2],1))\n",
    "\n",
    "noisy_images_rs = read_images_from_folder('./data/oct_noisy_resized/')\n",
    "noisy_images_rs = np.resize(noisy_images_rs,(noisy_images_rs.shape[0],noisy_images_rs.shape[1],noisy_images_rs.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('test_noisy.png',noisy_images_rs[33])\n",
    "cv2.imwrite('test.png',ground_truth_rs[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(666, 128, 256, 1)\n",
      "(167, 128, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "#Split into training and cross validation and normalizing\n",
    "train_size = int(ground_truth_rs.shape[0]*0.8)\n",
    "x_train = ground_truth_rs[0:train_size]/255.\n",
    "x_train_noisy = noisy_images_rs[0:train_size]/255.\n",
    "x_test = ground_truth_rs[train_size:]/255.\n",
    "x_test_noisy = noisy_images_rs[train_size:]/255.\n",
    "print (x_train_noisy.shape)\n",
    "print (x_test_noisy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(ground_truth.shape[0]):\n",
    " #   cv2.imwrite(\"./data/cifar-bw/image\"+str(i)+\".png\",ground_truth[i])\n",
    "    \n",
    "#for i in range(noisy_images.shape[0]):\n",
    " #   cv2.imwrite(\"./data/noisy-cifar-bw/image\"+str(i)+\".png\",noisy_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), cooldown=0, patience=2, min_lr=0.5e-6)\n",
    "#csv_logger = CSVLogger('./models/simple_cnn_autoencoder.csv')\n",
    "#early_stopper = EarlyStopping(min_delta=0.001,patience=30)\n",
    "model_checkpoint = ModelCheckpoint('./models/simple_cnn_oct.hdf5',monitor = 'loss', verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(666, 128, 256, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the model\n",
    "\n",
    "def get_simple_cnn_autoencoder_model(model_path=None):\n",
    "    \n",
    "    if(model_path is None):\n",
    "        autoencoder = None\n",
    "    else:\n",
    "        autoencoder = read_model_json(model_path) \n",
    "    \n",
    "    if(autoencoder is None):\n",
    "        input_img = Input(shape=((None,None,1)))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        \n",
    "        decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "        autoencoder = Model(input_img, decoded)\n",
    "        \n",
    "        \n",
    "        autoencoder.compile(optimizer='Adam', loss='mean_squared_error',metrics = ['accuracy','mean_squared_error'])\n",
    "\n",
    "    print (autoencoder.summary())\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, None, 64)    640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, None, None, 1)     577       \n",
      "=================================================================\n",
      "Total params: 112,001\n",
      "Trainable params: 112,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "autoencoder = get_simple_cnn_autoencoder_model()\n",
    "#plot_model(autoencoder, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 666 samples, validate on 167 samples\n",
      "Epoch 1/500\n",
      " 80/666 [==>...........................] - ETA: 3:04 - loss: 0.0351 - acc: 0.0000e+00 - mean_squared_error: 0.0351"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2af049e86683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 callbacks=[TensorBoard(log_dir='/tmp/autoencoder', histogram_freq=0, write_graph=True), model_checkpoint])\n\u001b[0m",
      "\u001b[0;32m/home/sandukuttan/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/sandukuttan/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sandukuttan/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sandukuttan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sandukuttan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sandukuttan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sandukuttan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sandukuttan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=500,\n",
    "                batch_size=20,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder', histogram_freq=0, write_graph=True), model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perceptual loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gated_connections(gatePercentageFactor,inputLayer):\n",
    "    gateFactor = Input(tensor = K.variable([gatePercentageFactor]))\n",
    "    fractionG = Lambda(lambda x: x[0]*x[1])([inputLayer,gateFactor])\n",
    "    complement = Lambda(lambda x: x[0] - x[1])([inputLayer,fractionG])\n",
    "    \n",
    "    return gateFactor,fractionG,complement\n",
    "\n",
    "#x is conv layer\n",
    "#y is de-conv layer\n",
    "#gf is gating factor\n",
    "#fg is fractional input from gate\n",
    "#c is complement ie remaining fraction from the gate\n",
    "#jt joining tensor of convolution layer and previous de-conv layer \n",
    "\n",
    "def get_cnn_dsc_architecture(model_path=None):\n",
    "    \n",
    "    if(model_path is None):\n",
    "        sym_autoencoder = None\n",
    "    else:\n",
    "        sym_autoencoder = read_model_json(model_path[0],model_path[1])\n",
    "        print model_path[0],model_path[1]\n",
    "    if(sym_autoencoder is None):\n",
    "        input_img = Input(shape=(None,None,1), name = \"Image_input\")  # adapt this if using `channels_first` image data format\n",
    "        x1 = Conv2D(64, (4, 4), activation='relu', padding='same')(input_img)\n",
    "        gf1,fg1,c1 = get_gated_connections(0.1,x1)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(fg1)\n",
    "        x2 = Conv2D(64, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf2,fg2,c2 = get_gated_connections(0.2,x2)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(fg2)\n",
    "        x3 = Conv2D(128, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf3,fg3,c3 = get_gated_connections(0.3,x3)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x3)\n",
    "        x4 = Conv2D(256, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf4,fg4,c4 = get_gated_connections(0.4,x4)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x4)\n",
    "        x5 = Conv2D(512, (4, 4), activation='relu', padding='same')(x) \n",
    "\n",
    "        x = UpSampling2D((2, 2))(x5)\n",
    "        y1 = Conv2DTranspose(256, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt4 = Add()([y1,c4])\n",
    "        x = UpSampling2D((2, 2))(jt4)\n",
    "\n",
    "        y2 = Conv2DTranspose(128, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt3 = Add()([y2,c3])\n",
    "        x = UpSampling2D((2, 2))(jt3)\n",
    "\n",
    "        y3 = Conv2DTranspose(64, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt2 = Add()([y3,c2])\n",
    "        x = UpSampling2D((2, 2))(jt2)\n",
    "\n",
    "        jt1 = Add()([x,c1])\n",
    "        y4 = Conv2DTranspose(64, (4, 4), activation='relu', padding='same')(jt1)\n",
    "        y5 = Conv2DTranspose(1, (4, 4), activation='relu', padding='same')(y4) \n",
    "\n",
    "        layers = y5\n",
    "\n",
    "        sym_autoencoder = Model([input_img,gf1,gf2,gf3,gf4],layers)\n",
    "        sym_autoencoder.compile(optimizer='sgd', loss = 'mean_squared_error', metrics = ['accuracy','mean_squared_error'])\n",
    "        print \"Model created\"\n",
    "    else:\n",
    "        print \"Saved model loaded\"\n",
    "    print sym_autoencoder.summary()\n",
    "    return sym_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "Image_input (InputLayer)         (None, None, None, 1) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, None, None, 64 1088        Image_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "input_1 (InputLayer)             (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)                (None, None, None, 64 0           conv2d_1[0][0]                   \n",
      "                                                                   input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, None, None, 64 0           lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, None, None, 64 65600       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)                (None, None, None, 64 0           conv2d_2[0][0]                   \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, None, None, 64 0           lambda_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, None, None, 12 131200      max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, None, None, 12 0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, None, None, 25 524544      max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, None, None, 25 0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, None, None, 51 2097664     max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)   (None, None, None, 51 0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)                (None, None, None, 25 0           conv2d_4[0][0]                   \n",
      "                                                                   input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTransp (None, None, None, 25 2097408     up_sampling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)                (None, None, None, 25 0           conv2d_4[0][0]                   \n",
      "                                                                   lambda_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, None, None, 25 0           conv2d_transpose_1[0][0]         \n",
      "                                                                   lambda_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)   (None, None, None, 25 0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)                (None, None, None, 12 0           conv2d_3[0][0]                   \n",
      "                                                                   input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTransp (None, None, None, 12 524416      up_sampling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)                (None, None, None, 12 0           conv2d_3[0][0]                   \n",
      "                                                                   lambda_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, None, None, 12 0           conv2d_transpose_2[0][0]         \n",
      "                                                                   lambda_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)   (None, None, None, 12 0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTransp (None, None, None, 64 131136      up_sampling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)                (None, None, None, 64 0           conv2d_2[0][0]                   \n",
      "                                                                   lambda_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, None, None, 64 0           conv2d_transpose_3[0][0]         \n",
      "                                                                   lambda_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)   (None, None, None, 64 0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, None, None, 64 0           conv2d_1[0][0]                   \n",
      "                                                                   lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, None, None, 64 0           up_sampling2d_4[0][0]            \n",
      "                                                                   lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTransp (None, None, None, 64 65600       add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTransp (None, None, None, 1) 1025        conv2d_transpose_4[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 5,639,681\n",
      "Trainable params: 5,639,681\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5bf1989673d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msym_autoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cnn_dsc_architecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sys.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "sym_autoencoder = get_cnn_dsc_architecture()\n",
    "plot_model(autoencoder, to_file='sys.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint1 = ModelCheckpoint('./models/gated_cnn_autoencoder_oct.hdf5',monitor = 'loss', verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 666 samples, validate on 167 samples\n",
      "Epoch 1/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.0000e+00 - mean_squared_error: 0.0352Epoch 00000: loss improved from inf to 0.03510, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 181s - loss: 0.0351 - acc: 0.0000e+00 - mean_squared_error: 0.0351 - val_loss: 0.0064 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0064\n",
      "Epoch 2/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.0000e+00 - mean_squared_error: 0.0055Epoch 00001: loss improved from 0.03510 to 0.00553, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0055 - acc: 0.0000e+00 - mean_squared_error: 0.0055 - val_loss: 0.0058 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0058\n",
      "Epoch 3/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.0000e+00 - mean_squared_error: 0.0051Epoch 00002: loss improved from 0.00553 to 0.00505, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0051 - acc: 0.0000e+00 - mean_squared_error: 0.0051 - val_loss: 0.0056 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0056\n",
      "Epoch 4/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.0000e+00 - mean_squared_error: 0.0048Epoch 00003: loss improved from 0.00505 to 0.00477, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0048 - acc: 0.0000e+00 - mean_squared_error: 0.0048 - val_loss: 0.0053 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0053\n",
      "Epoch 5/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.0000e+00 - mean_squared_error: 0.0046Epoch 00004: loss improved from 0.00477 to 0.00459, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0046 - acc: 0.0000e+00 - mean_squared_error: 0.0046 - val_loss: 0.0055 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0055\n",
      "Epoch 6/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.0000e+00 - mean_squared_error: 0.0045Epoch 00005: loss improved from 0.00459 to 0.00449, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0045 - acc: 0.0000e+00 - mean_squared_error: 0.0045 - val_loss: 0.0052 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0052\n",
      "Epoch 7/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.0000e+00 - mean_squared_error: 0.0044Epoch 00006: loss improved from 0.00449 to 0.00438, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0044 - acc: 0.0000e+00 - mean_squared_error: 0.0044 - val_loss: 0.0051 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0051\n",
      "Epoch 8/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.0000e+00 - mean_squared_error: 0.0043Epoch 00007: loss improved from 0.00438 to 0.00433, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0043 - acc: 0.0000e+00 - mean_squared_error: 0.0043 - val_loss: 0.0050 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0050\n",
      "Epoch 9/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.0000e+00 - mean_squared_error: 0.0042Epoch 00008: loss improved from 0.00433 to 0.00422, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0042 - acc: 0.0000e+00 - mean_squared_error: 0.0042 - val_loss: 0.0049 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0049\n",
      "Epoch 10/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.0000e+00 - mean_squared_error: 0.0041Epoch 00009: loss improved from 0.00422 to 0.00413, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0041 - acc: 0.0000e+00 - mean_squared_error: 0.0041 - val_loss: 0.0049 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0049\n",
      "Epoch 11/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.0000e+00 - mean_squared_error: 0.0041Epoch 00010: loss improved from 0.00413 to 0.00410, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0041 - acc: 0.0000e+00 - mean_squared_error: 0.0041 - val_loss: 0.0047 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0047\n",
      "Epoch 12/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.0000e+00 - mean_squared_error: 0.0040Epoch 00011: loss improved from 0.00410 to 0.00403, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0040 - acc: 0.0000e+00 - mean_squared_error: 0.0040 - val_loss: 0.0049 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0049\n",
      "Epoch 13/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.0000e+00 - mean_squared_error: 0.0040Epoch 00012: loss improved from 0.00403 to 0.00399, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0040 - acc: 0.0000e+00 - mean_squared_error: 0.0040 - val_loss: 0.0048 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0048\n",
      "Epoch 14/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.0000e+00 - mean_squared_error: 0.0039Epoch 00013: loss improved from 0.00399 to 0.00393, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0039 - acc: 0.0000e+00 - mean_squared_error: 0.0039 - val_loss: 0.0051 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0051\n",
      "Epoch 15/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.0000e+00 - mean_squared_error: 0.0039Epoch 00014: loss improved from 0.00393 to 0.00390, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0039 - acc: 0.0000e+00 - mean_squared_error: 0.0039 - val_loss: 0.0047 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0047\n",
      "Epoch 16/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.0000e+00 - mean_squared_error: 0.0039Epoch 00015: loss improved from 0.00390 to 0.00386, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0039 - acc: 0.0000e+00 - mean_squared_error: 0.0039 - val_loss: 0.0047 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0047\n",
      "Epoch 17/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.0000e+00 - mean_squared_error: 0.0038Epoch 00016: loss improved from 0.00386 to 0.00381, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0038 - acc: 0.0000e+00 - mean_squared_error: 0.0038 - val_loss: 0.0046 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0046\n",
      "Epoch 18/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.0000e+00 - mean_squared_error: 0.0038Epoch 00017: loss improved from 0.00381 to 0.00376, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0038 - acc: 0.0000e+00 - mean_squared_error: 0.0038 - val_loss: 0.0046 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0046\n",
      "Epoch 19/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.0000e+00 - mean_squared_error: 0.0037Epoch 00018: loss improved from 0.00376 to 0.00374, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0037 - acc: 0.0000e+00 - mean_squared_error: 0.0037 - val_loss: 0.0048 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0048\n",
      "Epoch 20/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.0000e+00 - mean_squared_error: 0.0037Epoch 00019: loss improved from 0.00374 to 0.00370, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0037 - acc: 0.0000e+00 - mean_squared_error: 0.0037 - val_loss: 0.0046 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0046\n",
      "Epoch 21/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.0000e+00 - mean_squared_error: 0.0037Epoch 00020: loss improved from 0.00370 to 0.00369, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0037 - acc: 0.0000e+00 - mean_squared_error: 0.0037 - val_loss: 0.0044 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0044\n",
      "Epoch 22/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.0000e+00 - mean_squared_error: 0.0036Epoch 00021: loss improved from 0.00369 to 0.00363, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0036 - acc: 0.0000e+00 - mean_squared_error: 0.0036 - val_loss: 0.0049 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0049\n",
      "Epoch 23/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.0000e+00 - mean_squared_error: 0.0036Epoch 00022: loss improved from 0.00363 to 0.00362, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0036 - acc: 0.0000e+00 - mean_squared_error: 0.0036 - val_loss: 0.0042 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0042\n",
      "Epoch 24/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.0000e+00 - mean_squared_error: 0.0036Epoch 00023: loss improved from 0.00362 to 0.00359, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0036 - acc: 0.0000e+00 - mean_squared_error: 0.0036 - val_loss: 0.0042 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0042\n",
      "Epoch 25/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.0000e+00 - mean_squared_error: 0.0035Epoch 00024: loss improved from 0.00359 to 0.00353, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0035 - acc: 0.0000e+00 - mean_squared_error: 0.0035 - val_loss: 0.0043 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0043\n",
      "Epoch 26/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.0000e+00 - mean_squared_error: 0.0035Epoch 00025: loss improved from 0.00353 to 0.00351, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0035 - acc: 0.0000e+00 - mean_squared_error: 0.0035 - val_loss: 0.0042 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0042\n",
      "Epoch 27/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.0000e+00 - mean_squared_error: 0.0035Epoch 00026: loss improved from 0.00351 to 0.00346, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0035 - acc: 0.0000e+00 - mean_squared_error: 0.0035 - val_loss: 0.0043 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0043\n",
      "Epoch 28/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034Epoch 00027: loss improved from 0.00346 to 0.00344, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034 - val_loss: 0.0048 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0048\n",
      "Epoch 29/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034Epoch 00028: loss improved from 0.00344 to 0.00343, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034 - val_loss: 0.0043 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0043\n",
      "Epoch 30/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034Epoch 00029: loss improved from 0.00343 to 0.00335, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034 - val_loss: 0.0042 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0042\n",
      "Epoch 31/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.0000e+00 - mean_squared_error: 0.0033Epoch 00030: loss improved from 0.00335 to 0.00334, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0033 - acc: 0.0000e+00 - mean_squared_error: 0.0033 - val_loss: 0.0040 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0040\n",
      "Epoch 32/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034Epoch 00031: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0034 - acc: 0.0000e+00 - mean_squared_error: 0.0034 - val_loss: 0.0040 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0040\n",
      "Epoch 33/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.0000e+00 - mean_squared_error: 0.0033Epoch 00032: loss improved from 0.00334 to 0.00331, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0033 - acc: 0.0000e+00 - mean_squared_error: 0.0033 - val_loss: 0.0043 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0043\n",
      "Epoch 34/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.0000e+00 - mean_squared_error: 0.0033Epoch 00033: loss improved from 0.00331 to 0.00328, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0033 - acc: 0.0000e+00 - mean_squared_error: 0.0033 - val_loss: 0.0041 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0041\n",
      "Epoch 35/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032Epoch 00034: loss improved from 0.00328 to 0.00324, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 36/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032Epoch 00035: loss improved from 0.00324 to 0.00321, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 37/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032Epoch 00036: loss improved from 0.00321 to 0.00321, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032 - val_loss: 0.0041 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0041\n",
      "Epoch 38/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031Epoch 00037: loss improved from 0.00321 to 0.00313, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 39/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032Epoch 00038: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0032 - acc: 0.0000e+00 - mean_squared_error: 0.0032 - val_loss: 0.0041 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0041\n",
      "Epoch 40/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031Epoch 00039: loss improved from 0.00313 to 0.00313, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 41/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031Epoch 00040: loss improved from 0.00313 to 0.00313, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 42/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031Epoch 00041: loss improved from 0.00313 to 0.00308, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 43/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031Epoch 00042: loss improved from 0.00308 to 0.00307, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0031 - acc: 0.0000e+00 - mean_squared_error: 0.0031 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 44/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030Epoch 00043: loss improved from 0.00307 to 0.00304, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 45/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030Epoch 00044: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030 - val_loss: 0.0041 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0041\n",
      "Epoch 46/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030Epoch 00045: loss improved from 0.00304 to 0.00301, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 170s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 47/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030Epoch 00046: loss improved from 0.00301 to 0.00298, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 48/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030Epoch 00047: loss improved from 0.00298 to 0.00296, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0030 - acc: 0.0000e+00 - mean_squared_error: 0.0030 - val_loss: 0.0037 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0037\n",
      "Epoch 49/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00048: loss improved from 0.00296 to 0.00291, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0043 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0043\n",
      "Epoch 50/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00049: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 51/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00050: loss improved from 0.00291 to 0.00289, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 52/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00051: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0040 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0040\n",
      "Epoch 53/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00052: loss improved from 0.00289 to 0.00287, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0040 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0040\n",
      "Epoch 54/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00053: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 55/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029Epoch 00054: loss improved from 0.00287 to 0.00285, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0029 - acc: 0.0000e+00 - mean_squared_error: 0.0029 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 56/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028Epoch 00055: loss improved from 0.00285 to 0.00281, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028 - val_loss: 0.0037 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0037\n",
      "Epoch 57/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028Epoch 00056: loss improved from 0.00281 to 0.00280, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 58/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028Epoch 00057: loss improved from 0.00280 to 0.00278, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028 - val_loss: 0.0037 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0037\n",
      "Epoch 59/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028Epoch 00058: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 60/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028Epoch 00059: loss improved from 0.00278 to 0.00276, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028 - val_loss: 0.0037 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0037\n",
      "Epoch 61/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00060: loss improved from 0.00276 to 0.00274, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 62/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028Epoch 00061: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0028 - acc: 0.0000e+00 - mean_squared_error: 0.0028 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 63/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00062: loss improved from 0.00274 to 0.00271, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 64/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00063: loss improved from 0.00271 to 0.00271, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 65/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00064: loss improved from 0.00271 to 0.00266, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 66/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00065: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 67/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00066: loss improved from 0.00266 to 0.00265, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 68/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00067: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 69/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00068: loss improved from 0.00265 to 0.00265, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 70/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00069: loss improved from 0.00265 to 0.00263, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 71/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027Epoch 00070: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0027 - acc: 0.0000e+00 - mean_squared_error: 0.0027 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 72/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00071: loss improved from 0.00263 to 0.00261, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 73/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00072: loss improved from 0.00261 to 0.00260, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 74/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00073: loss improved from 0.00260 to 0.00259, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 75/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00074: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 76/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00075: loss improved from 0.00259 to 0.00257, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 77/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026Epoch 00076: loss improved from 0.00257 to 0.00256, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0026 - acc: 0.0000e+00 - mean_squared_error: 0.0026 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 78/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00077: loss improved from 0.00256 to 0.00253, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 79/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00078: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 80/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00079: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 81/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00080: loss improved from 0.00253 to 0.00247, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 82/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00081: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 83/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00082: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 84/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00083: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 85/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00084: loss improved from 0.00247 to 0.00247, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 86/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00085: loss improved from 0.00247 to 0.00247, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 87/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00086: loss improved from 0.00247 to 0.00246, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 88/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00087: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 89/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00088: loss improved from 0.00246 to 0.00244, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 90/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025Epoch 00089: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0025 - acc: 0.0000e+00 - mean_squared_error: 0.0025 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 91/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00090: loss improved from 0.00244 to 0.00244, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 92/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00091: loss improved from 0.00244 to 0.00242, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 93/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00092: loss improved from 0.00242 to 0.00241, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 94/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00093: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 95/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00094: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 96/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00095: loss improved from 0.00241 to 0.00240, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 97/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00096: loss improved from 0.00240 to 0.00233, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 98/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00097: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 99/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00098: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 100/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00099: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 101/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00100: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 102/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00101: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 103/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00102: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0041 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0041\n",
      "Epoch 104/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024Epoch 00103: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0024 - acc: 0.0000e+00 - mean_squared_error: 0.0024 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 105/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00104: loss improved from 0.00233 to 0.00231, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 106/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00105: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 107/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00106: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 108/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00107: loss improved from 0.00231 to 0.00229, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0036 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0036\n",
      "Epoch 109/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00108: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 110/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00109: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 111/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00110: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 112/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00111: loss improved from 0.00229 to 0.00229, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 113/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00112: loss improved from 0.00229 to 0.00227, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 114/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00113: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 115/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00114: loss improved from 0.00227 to 0.00227, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0042 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0042\n",
      "Epoch 116/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00115: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 117/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00116: loss improved from 0.00227 to 0.00226, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 118/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00117: loss improved from 0.00226 to 0.00221, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 119/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00118: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 120/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00119: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 121/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00120: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 122/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00121: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0037 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0037\n",
      "Epoch 123/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00122: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 124/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023Epoch 00123: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0023 - acc: 0.0000e+00 - mean_squared_error: 0.0023 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 125/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00124: loss improved from 0.00221 to 0.00220, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 126/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00125: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 127/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00126: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 128/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00127: loss improved from 0.00220 to 0.00220, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 129/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00128: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 130/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00129: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 131/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00130: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 132/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00131: loss improved from 0.00220 to 0.00219, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 133/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00132: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 134/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00133: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 135/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00134: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 136/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00135: loss improved from 0.00219 to 0.00216, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 137/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00136: loss improved from 0.00216 to 0.00215, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 138/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00137: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 139/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00138: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 140/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00139: loss improved from 0.00215 to 0.00213, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 141/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00140: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 142/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00141: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 143/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00142: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 144/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00143: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 145/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00144: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 146/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00145: loss improved from 0.00213 to 0.00212, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 147/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00146: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 148/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00147: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 149/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00148: loss improved from 0.00212 to 0.00208, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 150/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00149: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 151/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00150: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 152/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.0000e+00 - mean_squared_error: 0.0022Epoch 00151: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0035 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0035\n",
      "Epoch 153/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00152: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 154/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00153: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 155/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00154: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 156/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00155: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 157/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00156: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 158/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00157: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 159/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00158: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 160/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00159: loss did not improve\n",
      "666/666 [==============================] - 171s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 161/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00160: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 162/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00161: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 163/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00162: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 164/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00163: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 165/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00164: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 166/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00165: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 167/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00166: loss improved from 0.00208 to 0.00207, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 168/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00167: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 169/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00168: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 170/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00169: loss improved from 0.00207 to 0.00206, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 171/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00170: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 172/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00171: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 173/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00172: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 174/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00173: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 175/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00174: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 176/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00175: loss improved from 0.00206 to 0.00204, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 177/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00176: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 178/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00177: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 179/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00178: loss improved from 0.00204 to 0.00203, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 180/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00179: loss improved from 0.00203 to 0.00200, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 181/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00180: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 182/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00181: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 183/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00182: loss improved from 0.00200 to 0.00198, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 184/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00183: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 185/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00184: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 186/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021Epoch 00185: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0021 - acc: 0.0000e+00 - mean_squared_error: 0.0021 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 187/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00186: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 188/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00187: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 189/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00188: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 190/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00189: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 191/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00190: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 192/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00191: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 193/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00192: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 194/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00193: loss improved from 0.00198 to 0.00198, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 195/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00194: loss improved from 0.00198 to 0.00197, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 196/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00195: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 197/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00196: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 198/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00197: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 199/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00198: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 200/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00199: loss improved from 0.00197 to 0.00197, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 201/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00200: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 202/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00201: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 203/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00202: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 204/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00203: loss improved from 0.00197 to 0.00196, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 205/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00204: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 206/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00205: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 207/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00206: loss improved from 0.00196 to 0.00193, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 208/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00207: loss improved from 0.00193 to 0.00192, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 209/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00208: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 210/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00209: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 211/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00210: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 212/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00211: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 213/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00212: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 214/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00213: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 215/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00214: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 216/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00215: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 217/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00216: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 218/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00217: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 219/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00218: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 220/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00219: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 221/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00220: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 222/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00221: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 223/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020Epoch 00222: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0020 - acc: 0.0000e+00 - mean_squared_error: 0.0020 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 224/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00223: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 225/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00224: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 226/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00225: loss improved from 0.00192 to 0.00192, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 227/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00226: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 228/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00227: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 229/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00228: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 230/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00229: loss improved from 0.00192 to 0.00191, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 231/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00230: loss improved from 0.00191 to 0.00191, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 232/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00231: loss improved from 0.00191 to 0.00191, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 233/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00232: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 234/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00233: loss improved from 0.00191 to 0.00188, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 235/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00234: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 236/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00235: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 237/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00236: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00237: loss improved from 0.00188 to 0.00186, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 239/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00238: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 240/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00239: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 241/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00240: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 242/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00241: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 243/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00242: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 244/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00243: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 245/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00244: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 246/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00245: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 247/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00246: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 248/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00247: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 249/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00248: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 250/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00249: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 251/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00250: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 252/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00251: loss improved from 0.00186 to 0.00186, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 253/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00252: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 254/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00253: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 255/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00254: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 256/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00255: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 257/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00256: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 258/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00257: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 259/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00258: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 260/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00259: loss improved from 0.00186 to 0.00184, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 261/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00260: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 262/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00261: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 263/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00262: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 264/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00263: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 265/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00264: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 266/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00265: loss improved from 0.00184 to 0.00181, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 267/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00266: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 268/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00267: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 269/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00268: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 270/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00269: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 271/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00270: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 272/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00271: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 273/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00272: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 274/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00273: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 275/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00274: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 276/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00275: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 277/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00276: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 278/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00277: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 279/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00278: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 280/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00279: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 281/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019Epoch 00280: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0019 - acc: 0.0000e+00 - mean_squared_error: 0.0019 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 282/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00281: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 283/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00282: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 284/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00283: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 285/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00284: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 286/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00285: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 287/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00286: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 288/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00287: loss improved from 0.00181 to 0.00180, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 289/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00288: loss improved from 0.00180 to 0.00179, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 290/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00289: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 291/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00290: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0039 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0039\n",
      "Epoch 292/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00291: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 293/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00292: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 294/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00293: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 295/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00294: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0038 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0038\n",
      "Epoch 296/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00295: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 297/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00296: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 298/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00297: loss improved from 0.00179 to 0.00176, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 299/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00298: loss improved from 0.00176 to 0.00176, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 300/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00299: loss improved from 0.00176 to 0.00176, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 301/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00300: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 302/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00301: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 303/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00302: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 304/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00303: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 305/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00304: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 306/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00305: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 307/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00306: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0030 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0030\n",
      "Epoch 308/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00307: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 309/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00308: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 310/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00309: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 311/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00310: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 312/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00311: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 313/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00312: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 314/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00313: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 315/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00314: loss improved from 0.00176 to 0.00175, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 316/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00315: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 317/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00316: loss improved from 0.00175 to 0.00173, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 318/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00317: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 319/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00318: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 320/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00319: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 321/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00320: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 322/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00321: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 323/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00322: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0056 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0056\n",
      "Epoch 324/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00323: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 325/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00324: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 326/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00325: loss improved from 0.00173 to 0.00172, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 327/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00326: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 328/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00327: loss improved from 0.00172 to 0.00170, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 329/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00328: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 330/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00329: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 331/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00330: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0029 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0029\n",
      "Epoch 332/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00331: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 333/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00332: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 334/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00333: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 335/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00334: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 336/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00335: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 337/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00336: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 338/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00337: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0034 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0034\n",
      "Epoch 339/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00338: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 340/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00339: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 341/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00340: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 342/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00341: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 343/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00342: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 344/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00343: loss improved from 0.00170 to 0.00168, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0033 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0033\n",
      "Epoch 345/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00344: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 346/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00345: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 347/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00346: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 348/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00347: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 349/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00348: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 350/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00349: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 351/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00350: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 352/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00351: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0031 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0031\n",
      "Epoch 353/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00352: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 354/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00353: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 355/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00354: loss improved from 0.00168 to 0.00165, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0027 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0027\n",
      "Epoch 356/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00355: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 357/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00356: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 358/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00357: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 359/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00358: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 360/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00359: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 361/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00360: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 362/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00361: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 363/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00362: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 364/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00363: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 365/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00364: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 366/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00365: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 367/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00366: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 368/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00367: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 369/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00368: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 370/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00369: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 371/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00370: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 372/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00371: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 373/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00372: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 374/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00373: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 375/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00374: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 376/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00375: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 377/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00376: loss improved from 0.00165 to 0.00165, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 378/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00377: loss improved from 0.00165 to 0.00163, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 379/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00378: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 380/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00379: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 381/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00380: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 382/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00381: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 383/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00382: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 384/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00383: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 385/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00384: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 386/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00385: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0047 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0047\n",
      "Epoch 387/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00386: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0025 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0025\n",
      "Epoch 388/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00387: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 389/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00388: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 390/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00389: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 391/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00390: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 392/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00391: loss improved from 0.00163 to 0.00161, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 393/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00392: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 394/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00393: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 395/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00394: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 396/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00395: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 397/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00396: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0023 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0023\n",
      "Epoch 398/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00397: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 399/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00398: loss improved from 0.00161 to 0.00160, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0028 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0028\n",
      "Epoch 400/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017Epoch 00399: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 401/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00400: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 402/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00401: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 403/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00402: loss improved from 0.00160 to 0.00159, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0022 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0022\n",
      "Epoch 404/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018Epoch 00403: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0018 - acc: 0.0000e+00 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0018\n",
      "Epoch 405/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00404: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 406/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00405: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 407/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00406: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 408/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00407: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0021 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0021\n",
      "Epoch 409/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00408: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0019 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0019\n",
      "Epoch 410/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00409: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0051 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0051\n",
      "Epoch 411/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00410: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0026 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0026\n",
      "Epoch 412/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00411: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 413/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00412: loss improved from 0.00159 to 0.00156, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 414/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00413: loss improved from 0.00156 to 0.00155, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015 - val_loss: 0.0032 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0032\n",
      "Epoch 415/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00414: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 416/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015Epoch 00415: loss improved from 0.00155 to 0.00155, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015 - val_loss: 0.0024 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0024\n",
      "Epoch 417/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00416: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 418/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015Epoch 00417: loss improved from 0.00155 to 0.00153, saving model to ./models/gated_cnn_autoencoder_oct.hdf5\n",
      "666/666 [==============================] - 168s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 419/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00418: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0020 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0020\n",
      "Epoch 420/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016Epoch 00419: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0016 - acc: 0.0000e+00 - mean_squared_error: 0.0016 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 421/500\n",
      "664/666 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015Epoch 00420: loss did not improve\n",
      "666/666 [==============================] - 168s - loss: 0.0015 - acc: 0.0000e+00 - mean_squared_error: 0.0015 - val_loss: 0.0017 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.0017\n",
      "Epoch 422/500\n",
      "168/666 [======>.......................] - ETA: 117s - loss: 0.0017 - acc: 0.0000e+00 - mean_squared_error: 0.0017"
     ]
    }
   ],
   "source": [
    "sym_autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=500,\n",
    "                batch_size=8,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/gated_cnn_autoencoder', \n",
    "                                       histogram_freq=0,\n",
    "                                       write_graph=True),model_checkpoint1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = load_model('./models/simple_cnn_autoencoder.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.imshow(out_autoencoder[0])\n",
    "\n",
    "def predict_save(model,image_path):\n",
    "    test = cv2.imread(image_path,0)\n",
    "    test = np.array(test)\n",
    "    test = test.reshape(1,test.shape[0],test.shape[1],1)\n",
    "    test =  test/255.0\n",
    "    \n",
    "    out = model.predict(test,verbose=1)\n",
    "    cv2.imwrite(\"out.png\",(out[0]*255))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    }
   ],
   "source": [
    "predict_save(autoencoder,'./data/standard_test_images/noise/image21.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    cv2.imwrite(\"./data/denoise-cifar-bw/\"+str(i)+\".png\",out_autoencoder[i]*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_psnr(imageA,imageB):\n",
    "    maxI = 1.0\n",
    "    try:\n",
    "        return 20*math.log10(maxI) - 10*math.log10(compare_mse(imageA.flatten(),imageB.flatten()))\n",
    "    except:\n",
    "        return 20*math.log10(maxI)\n",
    "\n",
    "def get_psnr_result(x_test, out):\n",
    "    psnr_sum = 0\n",
    "    for i in range(out.shape[0]):\n",
    "        psnr_sum += compare_psnr(x_test[i].reshape(32,32,1),out[i].reshape(32,32,1),data_range=255)\n",
    "        \n",
    "    return 1.0*psnr_sum/out.shape[0];\n",
    "\n",
    "def get_ssim_result(originalSet,noisySet):\n",
    "    ssim_sum = 0\n",
    "    originalSet = originalSet.reshape(originalSet.shape[0],32,32,1)\n",
    "    noisySet = noisySet.reshape(noisySet.shape[0],32,32,1)\n",
    "    for i in range(originalSet.shape[0]):\n",
    "        ssim_sum += ssim(originalSet[i], noisySet[i],data_range=originalSet[i].max() - noisySet[i].min(), multichannel=True)\n",
    "    return 1.0*ssim_sum/originalSet.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bm3d_denoise(noisy_image):\n",
    "    noisy_image = noisy_image.reshape(noisy_image.shape[0],32,32)\n",
    "    denoised = []\n",
    "    count = 1\n",
    "    for i in range(noisy_image.shape[0]):\n",
    "        Basic_img = bm3d.BM3D_1st_step(noisy_image[i])\n",
    "        Final_img = bm3d.BM3D_2nd_step(Basic_img, noisy_image[i])\n",
    "        denoised.append(Final_img)\n",
    "        if (count%10 == 0):\n",
    "            print (str(count)+ \"images denoised\")\n",
    "        count+=1\n",
    "        \n",
    "    return np.array(denoised)\n",
    "\n",
    "def nlm_denoise(noisy_image):\n",
    "    noisy_image = noisy_image.reshape(noisy_image.shape[0],32,32,1)\n",
    "    denoised = []\n",
    "    count = 1\n",
    "    \n",
    "    for image in noisy_image:\n",
    "        denoised_image = denoise_nl_means(image, 7, 11, 0.5,multichannel = False)\n",
    "        denoised.append(denoised_image)\n",
    "        if(count%100 == 0) :\n",
    "            print(str(count)+\" images denoised\")\n",
    "        count+=1\n",
    "    return np.array(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10000, 32, 32, 1), (10000, 32, 32, 1))\n",
      "458.092258419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.066576979897317"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (test_images.shape,out_autoencoder.shape)\n",
    "print (compare_mse(test_images[0].flatten(),(out_autoencoder[0]*255.).flatten()))\n",
    "get_psnr_result(out_autoencoder*255.,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_sym_autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-c6ec004857a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_sym_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_sym_autoencoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_psnr_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_sym_autoencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_sym_autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "print (test_images.shape,out_sym_autoencoder.shape)\n",
    "print (mean_squared_error(test_images[0].flatten(),out_sym_autoencoder[0].flatten()))\n",
    "get_psnr_result(out_sym_autoencoder,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bm3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "/home/travis/miniconda/conda-bld/work/opencv-2.4.11/modules/core/src/dxt.cpp:2330: error: (-213) Odd-size DCT's are not implemented in function dct\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-14100dc74e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbm3d_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm3d_denoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-5e994559fb52>\u001b[0m in \u001b[0;36mbm3d_denoise\u001b[0;34m(noisy_image)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mBasic_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBM3D_1st_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mFinal_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBM3D_2nd_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasic_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdenoised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFinal_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/Image-Denoising-with-Convolutional-Denoising-Autoencoders/bm3d.pyc\u001b[0m in \u001b[0;36mBM3D_1st_step\u001b[0;34m(_noisyImg)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHeight_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mm_blockPoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocate_blk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblk_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_Size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mSimilar_Blks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStep1_fast_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_noisyImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_blockPoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mSimilar_Blks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatis_nonzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStep1_3DFiltering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimilar_Blks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mAggregation_hardthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimilar_Blks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBasic_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_Wight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatis_nonzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_Kaiser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/Image-Denoising-with-Convolutional-Denoising-Autoencoders/bm3d.pyc\u001b[0m in \u001b[0;36mStep1_fast_match\u001b[0;34m(_noisyImg, _BlockPoint)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mtem_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_noisyImg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpresent_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpresent_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBlk_Size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpresent_y\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBlk_Size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdct_Tem_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtem_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mm_Distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdct_img\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdct_Tem_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBlk_Size\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /home/travis/miniconda/conda-bld/work/opencv-2.4.11/modules/core/src/dxt.cpp:2330: error: (-213) Odd-size DCT's are not implemented in function dct\n"
     ]
    }
   ],
   "source": [
    "noisy_test_images.shape\n",
    "bm3d_out = bm3d_denoise(noisy_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm3d_out_norm = bm3d_out.astype('float64')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_psnr_result(bm3d_out_norm,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-c8bb56579059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlm_denoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnlm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-165-85427f2402e9>\u001b[0m in \u001b[0;36mnlm_denoise\u001b[0;34m(noisy_image)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoisy_image\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mdenoised_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenoise_nl_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultichannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mdenoised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenoised_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/skimage/restoration/non_local_means.pyc\u001b[0m in \u001b[0;36mdenoise_nl_means\u001b[0;34m(image, patch_size, patch_distance, h, multichannel, fast_mode)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfast_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             return np.array(_fast_nl_means_denoising_3d(image, s=patch_size,\n\u001b[0;32m--> 127\u001b[0;31m                                                         d=patch_distance, h=h))\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             return np.array(_nl_means_denoising_3d(image, patch_size,\n",
      "\u001b[0;32mskimage/restoration/_nl_means_denoising.pyx\u001b[0m in \u001b[0;36mskimage.restoration._nl_means_denoising._fast_nl_means_denoising_3d (skimage/restoration/_nl_means_denoising.c:8689)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36mzeros_like\u001b[0;34m(a, dtype, order, subok)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \"\"\"\n\u001b[1;32m     89\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mzeros\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(noisy_test_images.shape)\n",
    "nlm_out = nlm_denoise(noisy_test_images*255.)\n",
    "nlm_out = nlm_out.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32) (10000, 32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.414818545893922"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print nlm_out.shape,test_images.shape\n",
    "get_psnr_result(nlm_out,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69608629344603479"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,out_autoencoder*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.718734871276698"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,out_sym_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_ssim_result(test_images,bm3d_out_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49438484841716263"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,nlm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"./models/oct_epoch_500_batch_20/simple_cnn_oct.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, None, 64)    640       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, None, None, 1)     577       \n",
      "=================================================================\n",
      "Total params: 112,001\n",
      "Trainable params: 112,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Testing\n",
    "phantom_test = sio.loadmat('./test_data/phantom.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3739db6a323f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphantom_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'InputImage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'count'"
     ]
    }
   ],
   "source": [
    "np.array(phantom_test['InputImage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./test_data/phantom.png',phantom_test['InputImage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_images_from_folder_with_names(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path,filename),0)\n",
    "        if img is not None:\n",
    "            images.append((filename,img))\n",
    "    return images\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(790, 790)\n"
     ]
    }
   ],
   "source": [
    "#Adding Gamma noise\n",
    "test_image = cv2.imread('./test_data/phantom.tif',0)\n",
    "#test_image = cv2.resize(test_image,(900,448),interpolation = cv2.INTER_CUBIC)\n",
    "print test_image.shape\n",
    "\n",
    "gamma_param = [(3,2),(4,3),(4,4),(6,6),(8,7)]\n",
    "for param in gamma_param:\n",
    "    shape = param[0]\n",
    "    scale = param[1]\n",
    "    noise = np.random.gamma(shape,scale,test_image.shape)\n",
    "    noisy_img = np.clip(noise + test_image,0.,255.)\n",
    "    cv2.imwrite('./test_data/phantom_noisy/phantom_shape_'+str(shape)+'_scale_'+str(scale)+'.tif',noisy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_image_set = read_images_from_folder_with_names('./test_data/phantom_noisy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('phantom_shape_4_scale_3.tif', array([[ 6, 14, 21, ..., 12, 14,  3],\n",
       "         [11,  5,  7, ..., 10,  6, 16],\n",
       "         [ 7,  4,  3, ..., 14,  6,  8],\n",
       "         ..., \n",
       "         [ 6, 11, 10, ..., 11, 11, 16],\n",
       "         [19,  7, 18, ...,  7,  6,  7],\n",
       "         [12, 15, 15, ..., 15, 18,  8]], dtype=uint8)),\n",
       " ('phantom_shape_3_scale_2.tif', array([[10,  4,  9, ...,  3,  6,  9],\n",
       "         [ 2,  6,  4, ...,  5, 12,  8],\n",
       "         [ 6, 17, 10, ...,  5,  8,  6],\n",
       "         ..., \n",
       "         [ 4,  6, 12, ...,  5,  6,  6],\n",
       "         [ 8,  9, 10, ...,  5,  3, 10],\n",
       "         [ 5,  1,  5, ...,  5,  6,  3]], dtype=uint8)),\n",
       " ('phantom_shape_8_scale_7.tif', array([[ 47,  69,  48, ...,  84,  25,  43],\n",
       "         [ 56,  27,  45, ...,  48,  42,  58],\n",
       "         [ 53, 151,  35, ...,  46,  43,  62],\n",
       "         ..., \n",
       "         [ 30,  49,  51, ...,  34,  39,  44],\n",
       "         [ 66,  88,  52, ...,  46,  40,  60],\n",
       "         [ 48,  55, 103, ...,  29,  86,  82]], dtype=uint8)),\n",
       " ('phantom_shape_4_scale_4.tif', array([[13, 20, 15, ..., 18, 10, 18],\n",
       "         [10, 11, 16, ...,  9,  5, 10],\n",
       "         [ 8,  8, 13, ..., 18, 14,  9],\n",
       "         ..., \n",
       "         [ 8, 22,  4, ..., 15, 24,  5],\n",
       "         [18, 13, 47, ..., 28, 32,  9],\n",
       "         [ 5, 25, 35, ..., 10, 40, 14]], dtype=uint8)),\n",
       " ('phantom_shape_6_scale_6.tif', array([[44, 36, 20, ..., 54, 43, 34],\n",
       "         [71, 82, 17, ..., 44, 20, 37],\n",
       "         [39, 37, 25, ..., 40, 47, 19],\n",
       "         ..., \n",
       "         [42, 48, 26, ..., 24, 42, 31],\n",
       "         [28, 49, 15, ..., 40, 54, 20],\n",
       "         [58, 17, 33, ..., 35, 32, 28]], dtype=uint8))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "(792, 792, 1) (792, 792, 1)\n",
      "14.1688053995 0.538685767461\n",
      "phantom_shape_4_scale_3\n",
      "True\n",
      "./test_data/phantom_denoised/phantom_shape_4_scale_3_14.1688053995.tif\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "(792, 792, 1) (792, 792, 1)\n",
      "13.0058097454 0.481478793641\n",
      "phantom_shape_3_scale_2\n",
      "True\n",
      "./test_data/phantom_denoised/phantom_shape_3_scale_2_13.0058097454.tif\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "(792, 792, 1) (792, 792, 1)\n",
      "16.436941766 0.462860742425\n",
      "phantom_shape_8_scale_7\n",
      "True\n",
      "./test_data/phantom_denoised/phantom_shape_8_scale_7_16.436941766.tif\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "(792, 792, 1) (792, 792, 1)\n",
      "14.8847776604 0.55732322882\n",
      "phantom_shape_4_scale_4\n",
      "True\n",
      "./test_data/phantom_denoised/phantom_shape_4_scale_4_14.8847776604.tif\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "(792, 792, 1) (792, 792, 1)\n",
      "17.9598867905 0.57967343949\n",
      "phantom_shape_6_scale_6\n",
      "True\n",
      "./test_data/phantom_denoised/phantom_shape_6_scale_6_17.9598867905.tif\n"
     ]
    }
   ],
   "source": [
    "for idx,test_image in enumerate(test_image_set):\n",
    "    test_image_norm = cv2.resize(test_image[1],(792,792),interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    test_image_norm = [test_image_norm]\n",
    "    test_image_norm = np.array(test_image_norm,dtype=np.float64)\n",
    "    test_image_norm = test_image_norm/255.\n",
    "    test_image_norm = test_image_norm.reshape((test_image_norm.shape[0],test_image_norm.shape[1],test_image_norm.shape[2],1))\n",
    "    \n",
    "    out_image = model.predict(test_image_norm,verbose=1)\n",
    "    out_image = out_image.astype(np.float64)\n",
    "    print test_image_norm[0].shape,out_image[0].shape\n",
    "    psnr = compare_psnr(test_image_norm[0]*255.,out_image[0]*255.,data_range=256)\n",
    "    ssim = compare_ssim(test_image_norm[0],out_image[0],multichannel=True)\n",
    "    print psnr,ssim\n",
    "    print test_image[0][:-4]\n",
    "    print cv2.imwrite('./test_data/phantom_denoised/'+test_image[0][:-4] + '_'+str(psnr)+'.tif',out_image[0]*255.)\n",
    "    print './test_data/phantom_denoised/'+test_image[0][:-4] + '_'+str(psnr)+'.tif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input_2 to have 4 dimensions, but got array with shape (790, 790)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-9c147c4d79eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sandukuttan/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1728\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1729\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sandukuttan/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected input_2 to have 4 dimensions, but got array with shape (790, 790)"
     ]
    }
   ],
   "source": [
    "out_image = model.predict(test_image_set[1][1],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('denoise_test.tif',out_image[0]*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 900)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
