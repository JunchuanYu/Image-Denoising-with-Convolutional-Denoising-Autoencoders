{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import skimage\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage import data, img_as_float\n",
    "from skimage.restoration import denoise_nl_means\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from random import shuffle\n",
    "import math\n",
    "from keras.models import model_from_json\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.core import Lambda\n",
    "import pickle\n",
    "\n",
    "from utilities import *\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readcifar(path) : \n",
    "    with open(path, 'rb') as f:\n",
    "        train_set= pickle.load(f)\n",
    "    return train_set[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_set1 = readcifar('data/cifar-10-batches-py/data_batch_1')\n",
    "raw_train_set2 = readcifar('data/cifar-10-batches-py/data_batch_2')\n",
    "raw_train_set3 = readcifar('data/cifar-10-batches-py/data_batch_3')\n",
    "raw_train_set4 = readcifar('data/cifar-10-batches-py/data_batch_4')\n",
    "raw_train_set5 = readcifar('data/cifar-10-batches-py/data_batch_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train_set = np.concatenate((raw_train_set1,raw_train_set2,raw_train_set3,raw_train_set4,raw_train_set5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(images) :\n",
    "    images = images.astype('float32')/255.\n",
    "    images = np.reshape(images, (images.shape[0],32,32,3))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = preprocess(raw_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualise_cifar10():\n",
    "    from six.moves import cPickle \n",
    "\n",
    "    f = open('data/cifar-10-batches-py/data_batch_1', 'rb')\n",
    "    datadict = cPickle.load(f)\n",
    "    f.close()\n",
    "    X = datadict[\"data\"] \n",
    "    Y = datadict['labels']\n",
    "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    #Visualizing CIFAR 10\n",
    "    fig, axes1 = plt.subplots(5,5,figsize=(3,3))\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            i = np.random.choice(range(len(X)))\n",
    "            axes1[j][k].set_axis_off()\n",
    "            axes1[j][k].imshow(X[i:i+1][0])\n",
    "            \n",
    "#Display last 'n' images from object 'images'\n",
    "def display_colour_images(images,n,sizeX,sizeY):\n",
    "    size = images.shape[0]\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    for i in range(1,n):\n",
    "        ax = plt.subplot(1, n, i)\n",
    "        plt.imshow(images[size - i].reshape(sizeX, sizeY,3))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not create write struct",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2206\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2208\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2209\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2210\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             _png.write_png(renderer._renderer, filename_or_obj,\n\u001b[0;32m--> 526\u001b[0;31m                            self.figure.dpi, metadata=metadata)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not create write struct"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff29e9108d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualise_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not create write struct",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/home/yeshwanth/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yeshwanth/anaconda2/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yeshwanth/anaconda2/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yeshwanth/anaconda2/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2206\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2208\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2209\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2210\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yeshwanth/anaconda2/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             _png.write_png(renderer._renderer, filename_or_obj,\n\u001b[0;32m--> 526\u001b[0;31m                            self.figure.dpi, metadata=metadata)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not create write struct"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc725f82ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_colour_images(train_set,10,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding noise to images\n",
    "def add_noise(images):\n",
    "    #x_train = np.reshape(x_train, (len(x_train), 64*64))  # adapt this if using `channels_first` image data format\n",
    "    #x_test = np.reshape(x_test, (len(x_test), 64*64))  # adapt this if using `channels_first` image data format\n",
    "    batch = images.shape[0]//4;\n",
    "    noise1 = gaussian_noise(images[0:batch],0,1,0.1)\n",
    "    noise2 = gaussian_noise(images[batch:2*batch],0,1,0.5)\n",
    "    noise3 = gaussian_noise(images[2*batch:3*batch],0,2,0.2)\n",
    "    noise4 = gaussian_noise(images[3*batch:],0,3,0.1)\n",
    "    \n",
    "    noisy_set = []\n",
    "    for data in [noise1,noise2,noise3,noise4]:\n",
    "        for image in data:\n",
    "            noisy_set.append(image)\n",
    "    \n",
    "    return np.array(noisy_set)\n",
    "   \n",
    "#Shuffle the noisy image ground truth pair to randomize the noise distribution in the dataset\n",
    "def pair_shuffle(images,noisy_set):\n",
    "    image_pair = []\n",
    "    for i in range(images.shape[0]):\n",
    "        image_pair.append((images[i],noisy_set[i]))\n",
    "    shuffle(image_pair)\n",
    "    \n",
    "    ground_truth=[]\n",
    "    noisy_images = []\n",
    "    for i in range(images.shape[0]):\n",
    "        ground_truth.append(image_pair[i][0])\n",
    "        noisy_images.append(image_pair[i][1])\n",
    "    return np.array(ground_truth), np.array(noisy_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling and adding noise to the dataset\n",
    "shuffle(train_set)\n",
    "#Getting the noisy image set\n",
    "noisy_set = add_noise(train_set)\n",
    "ground_truth,noisy_images = pair_shuffle(train_set,noisy_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#Split into training and cross validation\n",
    "train_size = int(ground_truth.shape[0]*0.8)\n",
    "x_train = ground_truth[0:train_size]\n",
    "x_train_noisy = noisy_images[0:train_size]\n",
    "x_test = ground_truth[train_size:]\n",
    "x_test_noisy = noisy_images[train_size:]\n",
    "print (x_train_noisy.shape)\n",
    "print (x_test_noisy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'display_images(ground_truth,10)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ground truth\n",
    "\"\"\"display_images(ground_truth,10)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'display_images(noisy_images,10)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Noisy images\n",
    "\"\"\"display_images(noisy_images,10)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), cooldown=0, patience=2, min_lr=0.5e-6)\n",
    "csv_logger = CSVLogger('./models/autoencoder.csv')\n",
    "early_stopper = EarlyStopping(min_delta=0.001,patience=30)\n",
    "model_checkpoint = ModelCheckpoint('./models/autoencoder.hdf5',monitor = 'loss', verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the model\n",
    "\n",
    "def get_simple_autoencoder_model(model_path=None):\n",
    "    \n",
    "    if(model_path is None):\n",
    "        autoencoder = None\n",
    "    else:\n",
    "        autoencoder = read_model_json(model_path) \n",
    "    \n",
    "    if(autoencoder is None):\n",
    "        input_img = Input(shape=x_train_noisy[0].shape)  # adapt this if using `channels_first` image data format\n",
    "\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "        autoencoder = Model(input_img, decoded)\n",
    "        autoencoder.compile(optimizer='sgd', loss='mean_squared_error',metrics = ['accuracy'])\n",
    "\n",
    "    print (autoencoder.summary())\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 32, 32, 3)         1731      \n",
      "=================================================================\n",
      "Total params: 114,307\n",
      "Trainable params: 114,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.3277Epoch 00000: loss improved from inf to 0.06121, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0612 - acc: 0.3277 - val_loss: 0.0560 - val_acc: 0.3368\n",
      "Epoch 2/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.3379Epoch 00001: loss improved from 0.06121 to 0.04642, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 100s - loss: 0.0464 - acc: 0.3379 - val_loss: 0.0394 - val_acc: 0.3384\n",
      "Epoch 3/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.3402Epoch 00002: loss improved from 0.04642 to 0.03582, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0358 - acc: 0.3402 - val_loss: 0.0340 - val_acc: 0.3428\n",
      "Epoch 4/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.3472Epoch 00003: loss improved from 0.03582 to 0.03262, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0326 - acc: 0.3472 - val_loss: 0.0319 - val_acc: 0.3515\n",
      "Epoch 5/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.3558Epoch 00004: loss improved from 0.03262 to 0.03098, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0310 - acc: 0.3559 - val_loss: 0.0306 - val_acc: 0.3599\n",
      "Epoch 6/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.3637Epoch 00005: loss improved from 0.03098 to 0.02987, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0299 - acc: 0.3637 - val_loss: 0.0296 - val_acc: 0.3671\n",
      "Epoch 7/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.3700Epoch 00006: loss improved from 0.02987 to 0.02907, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0291 - acc: 0.3700 - val_loss: 0.0289 - val_acc: 0.3720\n",
      "Epoch 8/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.3749Epoch 00007: loss improved from 0.02907 to 0.02845, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0284 - acc: 0.3749 - val_loss: 0.0284 - val_acc: 0.3762\n",
      "Epoch 9/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.3789Epoch 00008: loss improved from 0.02845 to 0.02794, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0279 - acc: 0.3789 - val_loss: 0.0278 - val_acc: 0.3813\n",
      "Epoch 10/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.3823Epoch 00009: loss improved from 0.02794 to 0.02752, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0275 - acc: 0.3823 - val_loss: 0.0274 - val_acc: 0.3869\n",
      "Epoch 11/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.3854Epoch 00010: loss improved from 0.02752 to 0.02717, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0272 - acc: 0.3854 - val_loss: 0.0272 - val_acc: 0.3879\n",
      "Epoch 12/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.3881Epoch 00011: loss improved from 0.02717 to 0.02685, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0269 - acc: 0.3881 - val_loss: 0.0269 - val_acc: 0.3917\n",
      "Epoch 13/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.3908Epoch 00012: loss improved from 0.02685 to 0.02657, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0266 - acc: 0.3908 - val_loss: 0.0266 - val_acc: 0.3936\n",
      "Epoch 14/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.3932Epoch 00013: loss improved from 0.02657 to 0.02633, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0263 - acc: 0.3932 - val_loss: 0.0263 - val_acc: 0.3931\n",
      "Epoch 15/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.3953Epoch 00014: loss improved from 0.02633 to 0.02611, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0261 - acc: 0.3953 - val_loss: 0.0264 - val_acc: 0.3962\n",
      "Epoch 16/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.3970Epoch 00015: loss improved from 0.02611 to 0.02591, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0259 - acc: 0.3970 - val_loss: 0.0259 - val_acc: 0.3989\n",
      "Epoch 17/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.3985Epoch 00016: loss improved from 0.02591 to 0.02572, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 100s - loss: 0.0257 - acc: 0.3985 - val_loss: 0.0257 - val_acc: 0.4004\n",
      "Epoch 18/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.3999Epoch 00017: loss improved from 0.02572 to 0.02556, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0256 - acc: 0.3999 - val_loss: 0.0256 - val_acc: 0.4006\n",
      "Epoch 19/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.4011Epoch 00018: loss improved from 0.02556 to 0.02541, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0254 - acc: 0.4011 - val_loss: 0.0255 - val_acc: 0.4023\n",
      "Epoch 20/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.4023Epoch 00019: loss improved from 0.02541 to 0.02527, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0253 - acc: 0.4023 - val_loss: 0.0253 - val_acc: 0.4037\n",
      "Epoch 21/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.4034Epoch 00020: loss improved from 0.02527 to 0.02514, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0251 - acc: 0.4034 - val_loss: 0.0254 - val_acc: 0.4043\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.4043Epoch 00021: loss improved from 0.02514 to 0.02502, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0250 - acc: 0.4043 - val_loss: 0.0251 - val_acc: 0.4055\n",
      "Epoch 23/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.4050Epoch 00022: loss improved from 0.02502 to 0.02491, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0249 - acc: 0.4050 - val_loss: 0.0249 - val_acc: 0.4062\n",
      "Epoch 24/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.4058Epoch 00023: loss improved from 0.02491 to 0.02480, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0248 - acc: 0.4058 - val_loss: 0.0249 - val_acc: 0.4067\n",
      "Epoch 25/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.4065Epoch 00024: loss improved from 0.02480 to 0.02469, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0247 - acc: 0.4065 - val_loss: 0.0247 - val_acc: 0.4079\n",
      "Epoch 26/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.4072Epoch 00025: loss improved from 0.02469 to 0.02460, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0246 - acc: 0.4072 - val_loss: 0.0247 - val_acc: 0.4081\n",
      "Epoch 27/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.4078Epoch 00026: loss improved from 0.02460 to 0.02450, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0245 - acc: 0.4078 - val_loss: 0.0245 - val_acc: 0.4092\n",
      "Epoch 28/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.4084Epoch 00027: loss improved from 0.02450 to 0.02441, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0244 - acc: 0.4084 - val_loss: 0.0245 - val_acc: 0.4100\n",
      "Epoch 29/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.4090Epoch 00028: loss improved from 0.02441 to 0.02433, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0243 - acc: 0.4090 - val_loss: 0.0244 - val_acc: 0.4106\n",
      "Epoch 30/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.4095Epoch 00029: loss improved from 0.02433 to 0.02425, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0243 - acc: 0.4095 - val_loss: 0.0243 - val_acc: 0.4105\n",
      "Epoch 31/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.4100Epoch 00030: loss improved from 0.02425 to 0.02417, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0242 - acc: 0.4100 - val_loss: 0.0242 - val_acc: 0.4116\n",
      "Epoch 32/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.4104Epoch 00031: loss improved from 0.02417 to 0.02409, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0241 - acc: 0.4104 - val_loss: 0.0242 - val_acc: 0.4116\n",
      "Epoch 33/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.4109Epoch 00032: loss improved from 0.02409 to 0.02403, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0240 - acc: 0.4109 - val_loss: 0.0242 - val_acc: 0.4117\n",
      "Epoch 34/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.4113Epoch 00033: loss improved from 0.02403 to 0.02395, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0240 - acc: 0.4113 - val_loss: 0.0240 - val_acc: 0.4124\n",
      "Epoch 35/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.4117Epoch 00034: loss improved from 0.02395 to 0.02389, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0239 - acc: 0.4117 - val_loss: 0.0240 - val_acc: 0.4123\n",
      "Epoch 36/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.4121Epoch 00035: loss improved from 0.02389 to 0.02382, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0238 - acc: 0.4121 - val_loss: 0.0239 - val_acc: 0.4136\n",
      "Epoch 37/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.4125Epoch 00036: loss improved from 0.02382 to 0.02376, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0238 - acc: 0.4125 - val_loss: 0.0238 - val_acc: 0.4142\n",
      "Epoch 38/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.4128Epoch 00037: loss improved from 0.02376 to 0.02370, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0237 - acc: 0.4129 - val_loss: 0.0237 - val_acc: 0.4137\n",
      "Epoch 39/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.4132Epoch 00038: loss improved from 0.02370 to 0.02364, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0236 - acc: 0.4132 - val_loss: 0.0237 - val_acc: 0.4147\n",
      "Epoch 40/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.4136Epoch 00039: loss improved from 0.02364 to 0.02358, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0236 - acc: 0.4136 - val_loss: 0.0236 - val_acc: 0.4144\n",
      "Epoch 41/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.4139Epoch 00040: loss improved from 0.02358 to 0.02352, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0235 - acc: 0.4139 - val_loss: 0.0236 - val_acc: 0.4150\n",
      "Epoch 42/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.4142Epoch 00041: loss improved from 0.02352 to 0.02347, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0235 - acc: 0.4142 - val_loss: 0.0235 - val_acc: 0.4154\n",
      "Epoch 43/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.4146Epoch 00042: loss improved from 0.02347 to 0.02342, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0234 - acc: 0.4146 - val_loss: 0.0235 - val_acc: 0.4167\n",
      "Epoch 44/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.4149Epoch 00043: loss improved from 0.02342 to 0.02336, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0234 - acc: 0.4149 - val_loss: 0.0234 - val_acc: 0.4158\n",
      "Epoch 45/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.4152Epoch 00044: loss improved from 0.02336 to 0.02332, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0233 - acc: 0.4152 - val_loss: 0.0234 - val_acc: 0.4174\n",
      "Epoch 46/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.4156Epoch 00045: loss improved from 0.02332 to 0.02327, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0233 - acc: 0.4156 - val_loss: 0.0233 - val_acc: 0.4183\n",
      "Epoch 47/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.4159Epoch 00046: loss improved from 0.02327 to 0.02322, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0232 - acc: 0.4159 - val_loss: 0.0233 - val_acc: 0.4170\n",
      "Epoch 48/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.4162Epoch 00047: loss improved from 0.02322 to 0.02317, saving model to ./models/autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 99s - loss: 0.0232 - acc: 0.4162 - val_loss: 0.0232 - val_acc: 0.4171\n",
      "Epoch 49/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.4164Epoch 00048: loss improved from 0.02317 to 0.02313, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0231 - acc: 0.4164 - val_loss: 0.0232 - val_acc: 0.4178\n",
      "Epoch 50/50\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.4168Epoch 00049: loss improved from 0.02313 to 0.02308, saving model to ./models/autoencoder.hdf5\n",
      "40000/40000 [==============================] - 99s - loss: 0.0231 - acc: 0.4168 - val_loss: 0.0231 - val_acc: 0.4183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff29c9cff50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "autoencoder = get_simple_autoencoder_model()\n",
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=20,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder', histogram_freq=0, write_graph=True), model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to get saved keras model\n",
    "def read_model_json(jsonfilePath,h5filePath):\n",
    "    try:\n",
    "        json_file = open(jsonfilePath, 'r')\n",
    "        print json_file\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        print \"hello\"\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "         \n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(h5filePath)\n",
    "\n",
    "        return loaded_model\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gated_connections(gatePercentageFactor,inputLayer):\n",
    "    gateFactor = Input(tensor = K.variable([gatePercentageFactor]))\n",
    "    fractionG = Lambda(lambda x: x[0]*x[1])([inputLayer,gateFactor])\n",
    "    complement = Lambda(lambda x: x[0] - x[1])([inputLayer,fractionG])\n",
    "    \n",
    "    return gateFactor,fractionG,complement\n",
    "\n",
    "#x is conv layer\n",
    "#y is de-conv layer\n",
    "#gf is gating factor\n",
    "#fg is fractional input from gate\n",
    "#c is complement ie remaining fraction from the gate\n",
    "#jt joining tensor of convolution layer and previous de-conv layer \n",
    "\n",
    "def get_cnn_dsc_architecture(model_path=None):\n",
    "    \n",
    "    if(model_path is None):\n",
    "        sym_autoencoder = None\n",
    "    else:\n",
    "        sym_autoencoder = read_model_json(model_path[0],model_path[1])\n",
    "        print model_path[0],model_path[1]\n",
    "    if(sym_autoencoder is None):\n",
    "        input_img = Input(shape=(32,32,3))  # adapt this if using `channels_first` image data format\n",
    "        x1 = Conv2D(64, (4, 4), activation='relu', padding='same')(input_img)\n",
    "        gf1,fg1,c1 = get_gated_connections(0.1,x1)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(fg1)\n",
    "        x2 = Conv2D(64, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf2,fg2,c2 = get_gated_connections(0.2,x2)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(fg2)\n",
    "        x3 = Conv2D(128, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf3,fg3,c3 = get_gated_connections(0.3,x3)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x3)\n",
    "        x4 = Conv2D(256, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf4,fg4,c4 = get_gated_connections(0.4,x4)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x4)\n",
    "        x5 = Conv2D(512, (4, 4), activation='relu', padding='same')(x) \n",
    "\n",
    "        x = UpSampling2D((2, 2))(x5)\n",
    "        y1 = Conv2DTranspose(256, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt4 = Add()([y1,c4])\n",
    "        x = UpSampling2D((2, 2))(jt4)\n",
    "\n",
    "        y2 = Conv2DTranspose(128, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt3 = Add()([y2,c3])\n",
    "        x = UpSampling2D((2, 2))(jt3)\n",
    "\n",
    "        y3 = Conv2DTranspose(64, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt2 = Add()([y3,c2])\n",
    "        x = UpSampling2D((2, 2))(jt2)\n",
    "\n",
    "        jt1 = Add()([x,c1])\n",
    "        y4 = Conv2DTranspose(64, (4, 4), activation='relu', padding='same')(jt1)\n",
    "        y5 = Conv2DTranspose(3, (4, 4), activation='relu', padding='same')(y4) \n",
    "\n",
    "        layers = y5\n",
    "\n",
    "        sym_autoencoder = Model([input_img,gf1,gf2,gf3,gf4],layers)\n",
    "        sym_autoencoder.compile(optimizer='sgd', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "        print \"Model created\"\n",
    "    else:\n",
    "        print \"Saved model loaded\"\n",
    "    print sym_autoencoder.summary()\n",
    "    return sym_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_18 (InputLayer)            (None, 32, 32, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, 32, 32, 64)    3136        input_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_19 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)               (None, 32, 32, 64)    0           conv2d_46[0][0]                  \n",
      "                                                                   input_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D)  (None, 16, 16, 64)    0           lambda_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, 16, 16, 64)    65600       max_pooling2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "input_20 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)               (None, 16, 16, 64)    0           conv2d_47[0][0]                  \n",
      "                                                                   input_20[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D)  (None, 8, 8, 64)      0           lambda_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, 8, 8, 128)     131200      max_pooling2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D)  (None, 4, 4, 128)     0           conv2d_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, 4, 4, 256)     524544      max_pooling2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D)  (None, 2, 2, 256)     0           conv2d_49[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, 2, 2, 512)     2097664     max_pooling2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "input_22 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_23 (UpSampling2D)  (None, 4, 4, 512)     0           conv2d_50[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)               (None, 4, 4, 256)     0           conv2d_49[0][0]                  \n",
      "                                                                   input_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTrans (None, 4, 4, 256)     2097408     up_sampling2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)               (None, 4, 4, 256)     0           conv2d_49[0][0]                  \n",
      "                                                                   lambda_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 4, 4, 256)     0           conv2d_transpose_11[0][0]        \n",
      "                                                                   lambda_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_21 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling2D)  (None, 8, 8, 256)     0           add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)               (None, 8, 8, 128)     0           conv2d_48[0][0]                  \n",
      "                                                                   input_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTrans (None, 8, 8, 128)     524416      up_sampling2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)               (None, 8, 8, 128)     0           conv2d_48[0][0]                  \n",
      "                                                                   lambda_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, 8, 8, 128)     0           conv2d_transpose_12[0][0]        \n",
      "                                                                   lambda_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_25 (UpSampling2D)  (None, 16, 16, 128)   0           add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTrans (None, 16, 16, 64)    131136      up_sampling2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)               (None, 16, 16, 64)    0           conv2d_47[0][0]                  \n",
      "                                                                   lambda_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, 16, 16, 64)    0           conv2d_transpose_13[0][0]        \n",
      "                                                                   lambda_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_26 (UpSampling2D)  (None, 32, 32, 64)    0           add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)               (None, 32, 32, 64)    0           conv2d_46[0][0]                  \n",
      "                                                                   lambda_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, 32, 32, 64)    0           up_sampling2d_26[0][0]           \n",
      "                                                                   lambda_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTrans (None, 32, 32, 64)    65600       add_12[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTrans (None, 32, 32, 3)     3075        conv2d_transpose_14[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 5,643,779\n",
      "Trainable params: 5,643,779\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sym_autoencoder = get_cnn_dsc_architecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint1 = ModelCheckpoint('./models/sym_autoencoder.hdf5',monitor = 'loss', verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.3827Epoch 00000: loss improved from inf to 0.02658, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 470s - loss: 0.0266 - acc: 0.3827 - val_loss: 0.0192 - val_acc: 0.4124\n",
      "Epoch 2/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.4291Epoch 00001: loss improved from 0.02658 to 0.01826, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 469s - loss: 0.0183 - acc: 0.4291 - val_loss: 0.0177 - val_acc: 0.4422\n",
      "Epoch 3/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.4485Epoch 00002: loss improved from 0.01826 to 0.01750, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 469s - loss: 0.0175 - acc: 0.4485 - val_loss: 0.0173 - val_acc: 0.4541\n",
      "Epoch 4/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.4574Epoch 00003: loss improved from 0.01750 to 0.01719, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 469s - loss: 0.0172 - acc: 0.4574 - val_loss: 0.0171 - val_acc: 0.4592\n",
      "Epoch 5/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.4629Epoch 00004: loss improved from 0.01719 to 0.01699, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 469s - loss: 0.0170 - acc: 0.4629 - val_loss: 0.0169 - val_acc: 0.4643\n",
      "Epoch 6/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.4667Epoch 00005: loss improved from 0.01699 to 0.01686, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 469s - loss: 0.0169 - acc: 0.4666 - val_loss: 0.0168 - val_acc: 0.4683\n",
      "Epoch 7/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.4695Epoch 00006: loss improved from 0.01686 to 0.01676, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0168 - acc: 0.4695 - val_loss: 0.0167 - val_acc: 0.4723\n",
      "Epoch 8/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.4716Epoch 00007: loss improved from 0.01676 to 0.01667, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0167 - acc: 0.4716 - val_loss: 0.0166 - val_acc: 0.4737\n",
      "Epoch 9/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.4733Epoch 00008: loss improved from 0.01667 to 0.01661, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0166 - acc: 0.4733 - val_loss: 0.0165 - val_acc: 0.4753\n",
      "Epoch 10/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.4746Epoch 00009: loss improved from 0.01661 to 0.01655, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 469s - loss: 0.0166 - acc: 0.4746 - val_loss: 0.0165 - val_acc: 0.4779\n",
      "Epoch 11/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.4756Epoch 00010: loss improved from 0.01655 to 0.01650, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 469s - loss: 0.0165 - acc: 0.4756 - val_loss: 0.0165 - val_acc: 0.4755\n",
      "Epoch 12/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.4765Epoch 00011: loss improved from 0.01650 to 0.01646, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 469s - loss: 0.0165 - acc: 0.4765 - val_loss: 0.0164 - val_acc: 0.4779\n",
      "Epoch 13/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.4773Epoch 00012: loss improved from 0.01646 to 0.01642, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 469s - loss: 0.0164 - acc: 0.4773 - val_loss: 0.0164 - val_acc: 0.4761\n",
      "Epoch 14/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.4780Epoch 00013: loss improved from 0.01642 to 0.01639, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0164 - acc: 0.4780 - val_loss: 0.0163 - val_acc: 0.4791\n",
      "Epoch 15/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.4786Epoch 00014: loss improved from 0.01639 to 0.01636, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 469s - loss: 0.0164 - acc: 0.4786 - val_loss: 0.0163 - val_acc: 0.4805\n",
      "Epoch 16/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.4792Epoch 00015: loss improved from 0.01636 to 0.01633, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 470s - loss: 0.0163 - acc: 0.4792 - val_loss: 0.0163 - val_acc: 0.4780\n",
      "Epoch 17/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.4797Epoch 00016: loss improved from 0.01633 to 0.01630, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 470s - loss: 0.0163 - acc: 0.4797 - val_loss: 0.0162 - val_acc: 0.4806\n",
      "Epoch 18/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.4802Epoch 00017: loss improved from 0.01630 to 0.01627, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 471s - loss: 0.0163 - acc: 0.4802 - val_loss: 0.0162 - val_acc: 0.4824\n",
      "Epoch 19/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.4806Epoch 00018: loss improved from 0.01627 to 0.01625, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 470s - loss: 0.0163 - acc: 0.4806 - val_loss: 0.0162 - val_acc: 0.4817\n",
      "Epoch 20/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.4810Epoch 00019: loss improved from 0.01625 to 0.01623, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 470s - loss: 0.0162 - acc: 0.4810 - val_loss: 0.0162 - val_acc: 0.4817\n",
      "Epoch 21/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.4814Epoch 00020: loss improved from 0.01623 to 0.01621, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 470s - loss: 0.0162 - acc: 0.4814 - val_loss: 0.0161 - val_acc: 0.4820\n",
      "Epoch 22/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.4816Epoch 00021: loss improved from 0.01621 to 0.01619, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0162 - acc: 0.4816 - val_loss: 0.0161 - val_acc: 0.4831\n",
      "Epoch 23/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.4820Epoch 00022: loss improved from 0.01619 to 0.01617, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0162 - acc: 0.4820 - val_loss: 0.0161 - val_acc: 0.4813\n",
      "Epoch 24/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.4822Epoch 00023: loss improved from 0.01617 to 0.01615, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0162 - acc: 0.4822 - val_loss: 0.0161 - val_acc: 0.4845\n",
      "Epoch 25/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.4825Epoch 00024: loss improved from 0.01615 to 0.01613, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0161 - acc: 0.4825 - val_loss: 0.0163 - val_acc: 0.4802\n",
      "Epoch 26/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.4827Epoch 00025: loss improved from 0.01613 to 0.01611, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0161 - acc: 0.4827 - val_loss: 0.0161 - val_acc: 0.4817\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.4829Epoch 00026: loss improved from 0.01611 to 0.01610, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0161 - acc: 0.4829 - val_loss: 0.0161 - val_acc: 0.4852\n",
      "Epoch 28/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.4830Epoch 00027: loss improved from 0.01610 to 0.01608, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0161 - acc: 0.4830 - val_loss: 0.0161 - val_acc: 0.4856\n",
      "Epoch 29/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.4833Epoch 00028: loss improved from 0.01608 to 0.01606, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0161 - acc: 0.4833 - val_loss: 0.0160 - val_acc: 0.4842\n",
      "Epoch 30/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.4834Epoch 00029: loss improved from 0.01606 to 0.01605, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0160 - acc: 0.4834 - val_loss: 0.0160 - val_acc: 0.4856\n",
      "Epoch 31/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.4836Epoch 00030: loss improved from 0.01605 to 0.01603, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0160 - acc: 0.4836 - val_loss: 0.0160 - val_acc: 0.4853\n",
      "Epoch 32/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.4837Epoch 00031: loss improved from 0.01603 to 0.01601, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0160 - acc: 0.4837 - val_loss: 0.0160 - val_acc: 0.4834\n",
      "Epoch 33/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.4839Epoch 00032: loss improved from 0.01601 to 0.01600, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0160 - acc: 0.4839 - val_loss: 0.0160 - val_acc: 0.4812\n",
      "Epoch 34/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.4840Epoch 00033: loss improved from 0.01600 to 0.01598, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0160 - acc: 0.4840 - val_loss: 0.0161 - val_acc: 0.4869\n",
      "Epoch 35/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.4841Epoch 00034: loss improved from 0.01598 to 0.01597, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0160 - acc: 0.4841 - val_loss: 0.0159 - val_acc: 0.4841\n",
      "Epoch 36/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.4842Epoch 00035: loss improved from 0.01597 to 0.01596, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0160 - acc: 0.4842 - val_loss: 0.0159 - val_acc: 0.4841\n",
      "Epoch 37/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.4844Epoch 00036: loss improved from 0.01596 to 0.01594, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0159 - acc: 0.4844 - val_loss: 0.0159 - val_acc: 0.4840\n",
      "Epoch 38/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.4844Epoch 00037: loss improved from 0.01594 to 0.01593, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0159 - acc: 0.4844 - val_loss: 0.0159 - val_acc: 0.4855\n",
      "Epoch 39/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.4845Epoch 00038: loss improved from 0.01593 to 0.01591, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0159 - acc: 0.4845 - val_loss: 0.0160 - val_acc: 0.4864\n",
      "Epoch 40/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.4846Epoch 00039: loss improved from 0.01591 to 0.01590, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0159 - acc: 0.4846 - val_loss: 0.0158 - val_acc: 0.4849\n",
      "Epoch 41/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.4847Epoch 00040: loss improved from 0.01590 to 0.01588, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0159 - acc: 0.4847 - val_loss: 0.0159 - val_acc: 0.4838\n",
      "Epoch 42/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.4848Epoch 00041: loss improved from 0.01588 to 0.01587, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0159 - acc: 0.4848 - val_loss: 0.0158 - val_acc: 0.4871\n",
      "Epoch 43/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.4849Epoch 00042: loss improved from 0.01587 to 0.01586, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0159 - acc: 0.4849 - val_loss: 0.0158 - val_acc: 0.4848\n",
      "Epoch 44/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.4850Epoch 00043: loss improved from 0.01586 to 0.01584, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0158 - acc: 0.4850 - val_loss: 0.0159 - val_acc: 0.4884\n",
      "Epoch 45/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.4850Epoch 00044: loss improved from 0.01584 to 0.01583, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0158 - acc: 0.4850 - val_loss: 0.0158 - val_acc: 0.4866\n",
      "Epoch 46/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.4852Epoch 00045: loss improved from 0.01583 to 0.01581, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0158 - acc: 0.4852 - val_loss: 0.0158 - val_acc: 0.4847\n",
      "Epoch 47/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.4852Epoch 00046: loss improved from 0.01581 to 0.01580, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0158 - acc: 0.4852 - val_loss: 0.0157 - val_acc: 0.4871\n",
      "Epoch 48/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.4853Epoch 00047: loss improved from 0.01580 to 0.01579, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0158 - acc: 0.4853 - val_loss: 0.0157 - val_acc: 0.4848\n",
      "Epoch 49/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.4853Epoch 00048: loss improved from 0.01579 to 0.01577, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0158 - acc: 0.4853 - val_loss: 0.0157 - val_acc: 0.4876\n",
      "Epoch 50/50\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.4854Epoch 00049: loss improved from 0.01577 to 0.01576, saving model to ./models/sym_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 468s - loss: 0.0158 - acc: 0.4854 - val_loss: 0.0157 - val_acc: 0.4867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2e80a7fd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=20,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/sym_autoencoder', \n",
    "                                       histogram_freq=0,\n",
    "                                       write_graph=True),model_checkpoint1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 32, 32, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model_as_json(sym_autoencoder,'CNNDSC_CIFAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting images to test\n",
    "def get_testing_images(filePath):\n",
    "    test_images = read_dataset(filePath)\n",
    "    test_images = np.array(test_images)\n",
    "    test_images = test_images.astype('float32')/255.\n",
    "    test_images = np.reshape(test_images, (test_images.shape[0],32,32,3))\n",
    "    noisy_test_images = add_noise(test_images)\n",
    "    print (noisy_test_images.shape)\n",
    "    return (test_images,noisy_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "raw_test_images = readcifar('data/cifar-10-batches-py/test_batch')\n",
    "test_images = preprocess(test_images)\n",
    "print(test_images.shape)\n",
    "noisy_test_images = add_noise(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 34s    \n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#Denoising using CNN symmetric Autoencoders\n",
    "out_sym_autoencoder = sym_autoencoder.predict(noisy_test_images,verbose=1)\n",
    "print (out_sym_autoencoder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s     \n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#Denoising using Autoencoders\n",
    "out_autoencoder = autoencoder.predict(noisy_test_images,verbose=1)\n",
    "print (out_autoencoder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndisplay_images(test_images,10)\\ndisplay_images(noisy_test_images,10)\\ndisplay_images(out,10)\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "display_images(test_images,10)\n",
    "display_images(noisy_test_images,10)\n",
    "display_images(out,10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def get_psnr(imageA,imageB):\n",
    "    maxI = 1.0\n",
    "    try:\n",
    "        return 20*math.log10(maxI) - 10*math.log10(mean_squared_error(imageA.flatten(),imageB.flatten()))\n",
    "    except:\n",
    "        return 20*math.log10(maxI)\n",
    "\n",
    "def get_psnr_result(x_test, out):\n",
    "    psnr_sum = 0\n",
    "    for i in range(out.shape[0]):\n",
    "        psnr_sum += get_psnr(x_test[i].reshape(32,32,3),out[i].reshape(32,32,3))\n",
    "        \n",
    "    return 1.0*psnr_sum/out.shape[0];\n",
    "\n",
    "def get_ssim_result(originalSet,noisySet):\n",
    "    ssim_sum = 0\n",
    "    originalSet = originalSet.reshape(originalSet.shape[0],32,32,3)\n",
    "    noisySet = noisySet.reshape(noisySet.shape[0],32,32,3)\n",
    "    for i in range(originalSet.shape[0]):\n",
    "        ssim_sum += ssim(originalSet[i], noisySet[i],data_range=originalSet[i].max() - noisySet[i].min(), multichannel=True)\n",
    "    return 1.0*ssim_sum/originalSet.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pybm3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bm3d_denoise(noisy_image):\n",
    "    noisy_image = noisy_image.reshape(noisy_image.shape[0],32,32,3)\n",
    "    noisy_image = noisy_image*255.0\n",
    "    denoised = []\n",
    "    count = 1\n",
    "    for i in range(noisy_image.shape[0]):\n",
    "        den_img = pybm3d.bm3d.bm3d(noisy_image[i])\n",
    "        denoised.append(den_img)\n",
    "        if (count%10 == 0):\n",
    "            print (str(count)+ \"images denoised\")\n",
    "        count+=1\n",
    "        \n",
    "    return np.array(denoised)\n",
    "\n",
    "def nlm_denoise(noisy_image):\n",
    "    noisy_image = noisy_image.reshape(noisy_image.shape[0],32,32,3)\n",
    "    noisy_image = noisy_image*255.0\n",
    "    denoised = []\n",
    "    count = 1\n",
    "    \n",
    "    for image in noisy_image:\n",
    "        denoised_image = denoise_nl_means(image, 7, 11, 0.5,multichannel = True)\n",
    "        denoised.append(denoised_image)\n",
    "        if(count%100 == 0) :\n",
    "            print(str(count)+\" images denoised\")\n",
    "        count+=1\n",
    "    return np.array(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10000, 32, 32, 3), (10000, 32, 32, 3))\n",
      "0.017626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.849217702825033"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (test_images.shape,out_autoencoder.shape)\n",
    "print (mean_squared_error(test_images[0].flatten(),out_autoencoder[0].flatten()))\n",
    "get_psnr_result(out_autoencoder,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10000, 32, 32, 3), (10000, 32, 32, 3))\n",
      "0.0088522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.591258702624295"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (test_images.shape,out_sym_autoencoder.shape)\n",
    "print (mean_squared_error(test_images[0].flatten(),out_sym_autoencoder[0].flatten()))\n",
    "get_psnr_result(out_sym_autoencoder,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bm3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_bm3d_wrap() takes at least 2 positional arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-14100dc74e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbm3d_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm3d_denoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-161-c2372be678c4>\u001b[0m in \u001b[0;36mbm3d_denoise\u001b[0;34m(noisy_image)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mden_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpybm3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mdenoised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mden_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpybm3d/bm3d.pyx\u001b[0m in \u001b[0;36mpybm3d.bm3d.bm3d\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpybm3d/bm3d.pyx\u001b[0m in \u001b[0;36mpybm3d.bm3d.run_bm3d_wrap\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: run_bm3d_wrap() takes at least 2 positional arguments (1 given)"
     ]
    }
   ],
   "source": [
    "noisy_test_images.shape\n",
    "bm3d_out = bm3d_denoise(noisy_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm3d_out_norm = bm3d_out.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_psnr_result(bm3d_out_norm,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "100 images denoised\n",
      "200 images denoised\n",
      "300 images denoised\n",
      "400 images denoised\n",
      "500 images denoised\n",
      "600 images denoised\n",
      "700 images denoised\n",
      "800 images denoised\n",
      "900 images denoised\n",
      "1000 images denoised\n",
      "1100 images denoised\n",
      "1200 images denoised\n",
      "1300 images denoised\n",
      "1400 images denoised\n",
      "1500 images denoised\n",
      "1600 images denoised\n",
      "1700 images denoised\n",
      "1800 images denoised\n",
      "1900 images denoised\n",
      "2000 images denoised\n",
      "2100 images denoised\n",
      "2200 images denoised\n",
      "2300 images denoised\n",
      "2400 images denoised\n",
      "2500 images denoised\n",
      "2600 images denoised\n",
      "2700 images denoised\n",
      "2800 images denoised\n",
      "2900 images denoised\n",
      "3000 images denoised\n",
      "3100 images denoised\n",
      "3200 images denoised\n",
      "3300 images denoised\n",
      "3400 images denoised\n",
      "3500 images denoised\n",
      "3600 images denoised\n",
      "3700 images denoised\n",
      "3800 images denoised\n",
      "3900 images denoised\n",
      "4000 images denoised\n",
      "4100 images denoised\n",
      "4200 images denoised\n",
      "4300 images denoised\n",
      "4400 images denoised\n",
      "4500 images denoised\n",
      "4600 images denoised\n",
      "4700 images denoised\n",
      "4800 images denoised\n",
      "4900 images denoised\n",
      "5000 images denoised\n",
      "5100 images denoised\n",
      "5200 images denoised\n",
      "5300 images denoised\n",
      "5400 images denoised\n",
      "5500 images denoised\n",
      "5600 images denoised\n",
      "5700 images denoised\n",
      "5800 images denoised\n",
      "5900 images denoised\n",
      "6000 images denoised\n",
      "6100 images denoised\n",
      "6200 images denoised\n",
      "6300 images denoised\n",
      "6400 images denoised\n",
      "6500 images denoised\n",
      "6600 images denoised\n",
      "6700 images denoised\n",
      "6800 images denoised\n",
      "6900 images denoised\n",
      "7000 images denoised\n",
      "7100 images denoised\n",
      "7200 images denoised\n",
      "7300 images denoised\n",
      "7400 images denoised\n",
      "7500 images denoised\n",
      "7600 images denoised\n",
      "7700 images denoised\n",
      "7800 images denoised\n",
      "7900 images denoised\n",
      "8000 images denoised\n",
      "8100 images denoised\n",
      "8200 images denoised\n",
      "8300 images denoised\n",
      "8400 images denoised\n",
      "8500 images denoised\n",
      "8600 images denoised\n",
      "8700 images denoised\n",
      "8800 images denoised\n",
      "8900 images denoised\n",
      "9000 images denoised\n",
      "9100 images denoised\n",
      "9200 images denoised\n",
      "9300 images denoised\n",
      "9400 images denoised\n",
      "9500 images denoised\n",
      "9600 images denoised\n",
      "9700 images denoised\n",
      "9800 images denoised\n",
      "9900 images denoised\n",
      "10000 images denoised\n"
     ]
    }
   ],
   "source": [
    "print(noisy_test_images.shape)\n",
    "nlm_out = nlm_denoise(noisy_test_images)\n",
    "nlm_out = nlm_out.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.904738896870535"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_psnr_result(nlm_out,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5642729314306093"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,out_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.718734871276698"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,out_sym_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_ssim_result(test_images,bm3d_out_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49438484841716263"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,nlm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test_images = readcifar('data/cifar-10-batches-py/test_batch')\n",
    "raw_test_images = np.array(raw_test_images)\n",
    "raw_test_images_re = raw_test_images.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "scipy.misc.toimage(raw_test_images_re[1], cmin=0.0, cmax=255).save('groundTruth.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_test_images = add_noise(raw_test_images_re)\n",
    "noisy_test_images_re = noisy_test_images_re.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "scipy.misc.imsave('out_noisy.jpg', noisy_test_images_re[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('out_raw_image.png',raw_test_images_re[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "test = raw_test_images_re[0] + np.random.normal(0,10,raw_test_images_re[0].shape)\n",
    "print test.shape\n",
    "scipy.misc.toimage(test, cmin=0.0, cmax=255).save('noisyImage.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filePath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-ba13bb56b988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filePath' is not defined"
     ]
    }
   ],
   "source": [
    "test_images = read_dataset(filePath)\n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(0,10,raw_test_images_re[0].shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.misc.toimage(noisy_test_images[0]*255, cmin=0.0, cmax=255).save('noisyImage.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.24449301,  0.05683702,  0.03648469],\n",
       "        [ 0.0772326 ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.0930394 ,  0.02182998],\n",
       "        [ 0.        ,  0.09627139,  0.14737143],\n",
       "        [ 0.1256676 ,  0.        ,  0.0246383 ]],\n",
       "\n",
       "       [[ 0.07830135,  0.09261384,  0.02461535],\n",
       "        [ 0.08843171,  0.        ,  0.        ],\n",
       "        [ 0.02886679,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.10082165,  0.        ],\n",
       "        [ 0.09477774,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.20705065]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.03018796],\n",
       "        [ 0.        ,  0.        ,  0.10510143],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.00492154,  0.05645058,  0.        ],\n",
       "        [ 0.11785186,  0.21180976,  0.01847803],\n",
       "        [ 0.        ,  0.09241974,  0.        ]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.        ,  0.        ,  0.12735681],\n",
       "        [ 0.0232089 ,  0.        ,  0.22179742],\n",
       "        [ 0.        ,  0.        ,  0.03599915],\n",
       "        ..., \n",
       "        [ 0.08882141,  0.23151231,  0.10505085],\n",
       "        [ 0.10363641,  0.05326724,  0.07019619],\n",
       "        [ 0.        ,  0.04445791,  0.02458405]],\n",
       "\n",
       "       [[ 0.        ,  0.01944573,  0.1001136 ],\n",
       "        [ 0.        ,  0.        ,  0.05210318],\n",
       "        [ 0.01484499,  0.        ,  0.        ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.05703454],\n",
       "        [ 0.09488056,  0.        ,  0.        ],\n",
       "        [ 0.09517968,  0.08397136,  0.        ]],\n",
       "\n",
       "       [[ 0.01992845,  0.00445124,  0.        ],\n",
       "        [ 0.09513754,  0.07808891,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.11095184],\n",
       "        ..., \n",
       "        [ 0.05252762,  0.13024043,  0.01270036],\n",
       "        [ 0.01759394,  0.        ,  0.12532319],\n",
       "        [ 0.01467156,  0.0108349 ,  0.14285792]]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_test_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      " 29024256/170498071 [====>.........................] - ETA: 486s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-472f0acaa056>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcifar10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/datasets/cifar10.pyc\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cifar-10-batches-py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muntar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnum_train_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0mfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/utils/data_utils.pyc\u001b[0m in \u001b[0;36mchunk_read\u001b[0;34m(response, chunk_size, reporthook)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;31m# fragmentation issues on many platforms.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;31m# fragmentation issues on many platforms.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cifar10 = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
