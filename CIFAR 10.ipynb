{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import skimage\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage.measure import compare_psnr,compare_mse\n",
    "from skimage import data, img_as_float\n",
    "from skimage.restoration import denoise_nl_means\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from random import shuffle\n",
    "import math\n",
    "from keras.models import model_from_json, load_model\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ReduceLROnPlateau, CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.core import Lambda\n",
    "import pickle\n",
    "\n",
    "from utilities import *\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readcifar(path) : \n",
    "    with open(path, 'rb') as f:\n",
    "        train_set= pickle.load(f)\n",
    "    return train_set[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train_set1 = readcifar('data/cifar-10-batches-py/data_batch_1')\n",
    "raw_train_set2 = readcifar('data/cifar-10-batches-py/data_batch_2')\n",
    "raw_train_set3 = readcifar('data/cifar-10-batches-py/data_batch_3')\n",
    "raw_train_set4 = readcifar('data/cifar-10-batches-py/data_batch_4')\n",
    "raw_train_set5 = readcifar('data/cifar-10-batches-py/data_batch_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_train_set = np.concatenate((raw_train_set1,raw_train_set2,raw_train_set3,raw_train_set4,raw_train_set5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3072)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(images) :\n",
    "    images = images.reshape(images.shape[0], 3, 32, 32).transpose(0,2,3,1).astype(\"uint8\")\n",
    "    #images = rgb2gray(images)\n",
    "    images = np.reshape(images, (images.shape[0],32,32,3))\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = preprocess(raw_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    cv2.imwrite(\"./data/cifar-bw/image\"+str(i)+\".png\",train_set[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding noise to images\n",
    "def add_noise(images):\n",
    "    #x_train = np.reshape(x_train, (len(x_train), 64*64))  # adapt this if using `channels_first` image data format\n",
    "    #x_test = np.reshape(x_test, (len(x_test), 64*64))  # adapt this if using `channels_first` image data format\n",
    "    batch = images.shape[0]//4;\n",
    "    noise1 = gaussian_noise(images[0:batch],0,20,1)\n",
    "    noise2 = gaussian_noise(images[batch:2*batch],0,25,1)\n",
    "    noise3 = gaussian_noise(images[2*batch:3*batch],0,30,1)\n",
    "    noise4 = gaussian_noise(images[3*batch:],0,35,1)\n",
    "    \n",
    "    noisy_set = []\n",
    "    for data in [noise1,noise2,noise3,noise4]:\n",
    "        for image in data:\n",
    "            noisy_set.append(image)\n",
    "    \n",
    "    return np.array(noisy_set)\n",
    "   \n",
    "#Shuffle the noisy image ground truth pair to randomize the noise distribution in the dataset\n",
    "def pair_shuffle(images,noisy_set):\n",
    "    image_pair = []\n",
    "    for i in range(images.shape[0]):\n",
    "        image_pair.append((images[i],noisy_set[i]))\n",
    "    shuffle(image_pair)\n",
    "    \n",
    "    ground_truth=[]\n",
    "    noisy_images = []\n",
    "    for i in range(images.shape[0]):\n",
    "        ground_truth.append(image_pair[i][0])\n",
    "        noisy_images.append(image_pair[i][1])\n",
    "    return np.array(ground_truth), np.array(noisy_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noisy_set = add_noise(train_set)\n",
    "for i in range(100):\n",
    "    cv2.imwrite(\"./data/noisy-cifar-bw/image\"+str(i)+\".png\",noisy_set[-i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling and adding noise to the dataset\n",
    "ground_truth,noisy_images = pair_shuffle(train_set,noisy_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#Split into training and cross validation and normalizing\n",
    "train_size = int(ground_truth.shape[0]*0.8)\n",
    "x_train = ground_truth[0:train_size]/255.\n",
    "x_train_noisy = noisy_images[0:train_size]/255.\n",
    "x_test = ground_truth[train_size:]/255.\n",
    "x_test_noisy = noisy_images[train_size:]/255.\n",
    "print (x_train_noisy.shape)\n",
    "print (x_test_noisy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor = np.sqrt(0.1), cooldown=0, patience=2, min_lr=0.5e-6)\n",
    "csv_logger = CSVLogger('./models/simple_cnn_autoencoder.csv')\n",
    "early_stopper = EarlyStopping(min_delta=0.001,patience=30)\n",
    "model_checkpoint = ModelCheckpoint('./models/simple_cnn_autoencoder.hdf5',monitor = 'loss', verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_noisy[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the model\n",
    "\n",
    "def get_simple_cnn_autoencoder_model(model_path=None):\n",
    "    \n",
    "    if(model_path is None):\n",
    "        autoencoder = None\n",
    "    else:\n",
    "        autoencoder = read_model_json(model_path) \n",
    "    \n",
    "    if(autoencoder is None):\n",
    "        input_img = Input(shape=(None,None,3))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "        autoencoder = Model(input_img, decoded)\n",
    "        autoencoder.compile(optimizer='sgd', loss='mean_squared_error',metrics = ['accuracy','mean_squared_error'])\n",
    "\n",
    "    print (autoencoder.summary())\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, None, None, 3)     1731      \n",
      "=================================================================\n",
      "Total params: 114,307\n",
      "Trainable params: 114,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "autoencoder = get_simple_cnn_autoencoder_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.4729 - mean_squared_error: 0.0556Epoch 00000: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0556 - acc: 0.4729 - mean_squared_error: 0.0556 - val_loss: 0.0330 - val_acc: 0.4734 - val_mean_squared_error: 0.0330\n",
      "Epoch 2/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.4804 - mean_squared_error: 0.0222Epoch 00001: loss did not improve\n",
      "40000/40000 [==============================] - 108s - loss: 0.0222 - acc: 0.4804 - mean_squared_error: 0.0222 - val_loss: 0.0186 - val_acc: 0.5056 - val_mean_squared_error: 0.0186\n",
      "Epoch 3/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.5420 - mean_squared_error: 0.0170Epoch 00002: loss did not improve\n",
      "40000/40000 [==============================] - 108s - loss: 0.0170 - acc: 0.5420 - mean_squared_error: 0.0170 - val_loss: 0.0154 - val_acc: 0.5823 - val_mean_squared_error: 0.0154\n",
      "Epoch 4/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.5969 - mean_squared_error: 0.0147Epoch 00003: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0147 - acc: 0.5970 - mean_squared_error: 0.0147 - val_loss: 0.0140 - val_acc: 0.6091 - val_mean_squared_error: 0.0140\n",
      "Epoch 5/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.6121 - mean_squared_error: 0.0136Epoch 00004: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0136 - acc: 0.6122 - mean_squared_error: 0.0136 - val_loss: 0.0131 - val_acc: 0.6206 - val_mean_squared_error: 0.0131\n",
      "Epoch 6/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.6173 - mean_squared_error: 0.0129Epoch 00005: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0129 - acc: 0.6173 - mean_squared_error: 0.0129 - val_loss: 0.0125 - val_acc: 0.6237 - val_mean_squared_error: 0.0125\n",
      "Epoch 7/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.6214 - mean_squared_error: 0.0123Epoch 00006: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0123 - acc: 0.6215 - mean_squared_error: 0.0123 - val_loss: 0.0120 - val_acc: 0.6211 - val_mean_squared_error: 0.0120\n",
      "Epoch 8/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.6253 - mean_squared_error: 0.0118Epoch 00007: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0118 - acc: 0.6253 - mean_squared_error: 0.0118 - val_loss: 0.0116 - val_acc: 0.6289 - val_mean_squared_error: 0.0116\n",
      "Epoch 9/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.6291 - mean_squared_error: 0.0114Epoch 00008: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0114 - acc: 0.6291 - mean_squared_error: 0.0114 - val_loss: 0.0112 - val_acc: 0.6369 - val_mean_squared_error: 0.0112\n",
      "Epoch 10/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.6324 - mean_squared_error: 0.0111Epoch 00009: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0111 - acc: 0.6324 - mean_squared_error: 0.0111 - val_loss: 0.0109 - val_acc: 0.6239 - val_mean_squared_error: 0.0109\n",
      "Epoch 11/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.6348 - mean_squared_error: 0.0108Epoch 00010: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0108 - acc: 0.6348 - mean_squared_error: 0.0108 - val_loss: 0.0106 - val_acc: 0.6407 - val_mean_squared_error: 0.0106\n",
      "Epoch 12/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.6378 - mean_squared_error: 0.0106Epoch 00011: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0106 - acc: 0.6378 - mean_squared_error: 0.0106 - val_loss: 0.0104 - val_acc: 0.6379 - val_mean_squared_error: 0.0104\n",
      "Epoch 13/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.6404 - mean_squared_error: 0.0104Epoch 00012: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0104 - acc: 0.6404 - mean_squared_error: 0.0104 - val_loss: 0.0102 - val_acc: 0.6405 - val_mean_squared_error: 0.0102\n",
      "Epoch 14/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.6433 - mean_squared_error: 0.0102Epoch 00013: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0102 - acc: 0.6434 - mean_squared_error: 0.0102 - val_loss: 0.0101 - val_acc: 0.6522 - val_mean_squared_error: 0.0101\n",
      "Epoch 15/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.6468 - mean_squared_error: 0.0100Epoch 00014: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0100 - acc: 0.6468 - mean_squared_error: 0.0100 - val_loss: 0.0099 - val_acc: 0.6508 - val_mean_squared_error: 0.0099\n",
      "Epoch 16/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.6506 - mean_squared_error: 0.0098Epoch 00015: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0098 - acc: 0.6506 - mean_squared_error: 0.0098 - val_loss: 0.0097 - val_acc: 0.6511 - val_mean_squared_error: 0.0097\n",
      "Epoch 17/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.6546 - mean_squared_error: 0.0097Epoch 00016: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0097 - acc: 0.6545 - mean_squared_error: 0.0097 - val_loss: 0.0096 - val_acc: 0.6528 - val_mean_squared_error: 0.0096\n",
      "Epoch 18/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.6589 - mean_squared_error: 0.0095Epoch 00017: loss did not improve\n",
      "40000/40000 [==============================] - 107s - loss: 0.0095 - acc: 0.6589 - mean_squared_error: 0.0095 - val_loss: 0.0094 - val_acc: 0.6600 - val_mean_squared_error: 0.0094\n",
      "Epoch 19/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.6635 - mean_squared_error: 0.0094Epoch 00018: loss did not improve\n",
      "40000/40000 [==============================] - 106s - loss: 0.0094 - acc: 0.6635 - mean_squared_error: 0.0094 - val_loss: 0.0093 - val_acc: 0.6709 - val_mean_squared_error: 0.0093\n",
      "Epoch 20/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.6692 - mean_squared_error: 0.0092Epoch 00019: loss did not improve\n",
      "40000/40000 [==============================] - 106s - loss: 0.0092 - acc: 0.6691 - mean_squared_error: 0.0092 - val_loss: 0.0092 - val_acc: 0.6712 - val_mean_squared_error: 0.0092\n",
      "Epoch 21/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.6754 - mean_squared_error: 0.0091Epoch 00020: loss did not improve\n",
      "40000/40000 [==============================] - 106s - loss: 0.0091 - acc: 0.6754 - mean_squared_error: 0.0091 - val_loss: 0.0089 - val_acc: 0.6829 - val_mean_squared_error: 0.0089\n",
      "Epoch 22/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.6827 - mean_squared_error: 0.0089Epoch 00021: loss did not improve\n",
      "40000/40000 [==============================] - 104s - loss: 0.0089 - acc: 0.6827 - mean_squared_error: 0.0089 - val_loss: 0.0088 - val_acc: 0.6826 - val_mean_squared_error: 0.0088\n",
      "Epoch 23/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.6905 - mean_squared_error: 0.0088Epoch 00022: loss did not improve\n",
      "40000/40000 [==============================] - 104s - loss: 0.0088 - acc: 0.6906 - mean_squared_error: 0.0088 - val_loss: 0.0087 - val_acc: 0.6929 - val_mean_squared_error: 0.0087\n",
      "Epoch 24/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.6988 - mean_squared_error: 0.0086Epoch 00023: loss did not improve\n",
      "40000/40000 [==============================] - 103s - loss: 0.0086 - acc: 0.6988 - mean_squared_error: 0.0086 - val_loss: 0.0085 - val_acc: 0.6977 - val_mean_squared_error: 0.0085\n",
      "Epoch 25/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.7066 - mean_squared_error: 0.0085Epoch 00024: loss did not improve\n",
      "40000/40000 [==============================] - 103s - loss: 0.0085 - acc: 0.7066 - mean_squared_error: 0.0085 - val_loss: 0.0084 - val_acc: 0.7110 - val_mean_squared_error: 0.0084\n",
      "Epoch 26/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.7135 - mean_squared_error: 0.0084Epoch 00025: loss did not improve\n",
      "40000/40000 [==============================] - 103s - loss: 0.0084 - acc: 0.7135 - mean_squared_error: 0.0084 - val_loss: 0.0083 - val_acc: 0.7167 - val_mean_squared_error: 0.0083\n",
      "Epoch 27/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.7190 - mean_squared_error: 0.0083Epoch 00026: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0083 - acc: 0.7190 - mean_squared_error: 0.0083 - val_loss: 0.0082 - val_acc: 0.7186 - val_mean_squared_error: 0.0082\n",
      "Epoch 28/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.7229 - mean_squared_error: 0.0082Epoch 00027: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0082 - acc: 0.7229 - mean_squared_error: 0.0082 - val_loss: 0.0081 - val_acc: 0.7247 - val_mean_squared_error: 0.0081\n",
      "Epoch 29/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.7260 - mean_squared_error: 0.0081Epoch 00028: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0081 - acc: 0.7260 - mean_squared_error: 0.0081 - val_loss: 0.0080 - val_acc: 0.7282 - val_mean_squared_error: 0.0080\n",
      "Epoch 30/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.7283 - mean_squared_error: 0.0080Epoch 00029: loss did not improve\n",
      "40000/40000 [==============================] - 103s - loss: 0.0080 - acc: 0.7283 - mean_squared_error: 0.0080 - val_loss: 0.0080 - val_acc: 0.7285 - val_mean_squared_error: 0.0080\n",
      "Epoch 31/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.7301 - mean_squared_error: 0.0080Epoch 00030: loss did not improve\n",
      "40000/40000 [==============================] - 103s - loss: 0.0080 - acc: 0.7301 - mean_squared_error: 0.0080 - val_loss: 0.0079 - val_acc: 0.7290 - val_mean_squared_error: 0.0079\n",
      "Epoch 32/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.7314 - mean_squared_error: 0.0079Epoch 00031: loss did not improve\n",
      "40000/40000 [==============================] - 103s - loss: 0.0079 - acc: 0.7314 - mean_squared_error: 0.0079 - val_loss: 0.0078 - val_acc: 0.7324 - val_mean_squared_error: 0.0078\n",
      "Epoch 33/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.7326 - mean_squared_error: 0.0078Epoch 00032: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0078 - acc: 0.7326 - mean_squared_error: 0.0078 - val_loss: 0.0078 - val_acc: 0.7356 - val_mean_squared_error: 0.0078\n",
      "Epoch 34/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.7335 - mean_squared_error: 0.0078Epoch 00033: loss did not improve\n",
      "40000/40000 [==============================] - 103s - loss: 0.0078 - acc: 0.7335 - mean_squared_error: 0.0078 - val_loss: 0.0077 - val_acc: 0.7350 - val_mean_squared_error: 0.0077\n",
      "Epoch 35/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.7343 - mean_squared_error: 0.0077Epoch 00034: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0077 - acc: 0.7344 - mean_squared_error: 0.0077 - val_loss: 0.0077 - val_acc: 0.7363 - val_mean_squared_error: 0.0077\n",
      "Epoch 36/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.7351 - mean_squared_error: 0.0077Epoch 00035: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0077 - acc: 0.7351 - mean_squared_error: 0.0077 - val_loss: 0.0077 - val_acc: 0.7371 - val_mean_squared_error: 0.0077\n",
      "Epoch 37/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.7358 - mean_squared_error: 0.0076Epoch 00036: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0076 - acc: 0.7357 - mean_squared_error: 0.0076 - val_loss: 0.0076 - val_acc: 0.7389 - val_mean_squared_error: 0.0076\n",
      "Epoch 38/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.7364 - mean_squared_error: 0.0076Epoch 00037: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0076 - acc: 0.7364 - mean_squared_error: 0.0076 - val_loss: 0.0075 - val_acc: 0.7366 - val_mean_squared_error: 0.0075\n",
      "Epoch 39/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.7371 - mean_squared_error: 0.0075Epoch 00038: loss did not improve\n",
      "40000/40000 [==============================] - 104s - loss: 0.0075 - acc: 0.7371 - mean_squared_error: 0.0075 - val_loss: 0.0075 - val_acc: 0.7383 - val_mean_squared_error: 0.0075\n",
      "Epoch 40/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.7376 - mean_squared_error: 0.0075Epoch 00039: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0075 - acc: 0.7376 - mean_squared_error: 0.0075 - val_loss: 0.0075 - val_acc: 0.7374 - val_mean_squared_error: 0.0075\n",
      "Epoch 41/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.7381 - mean_squared_error: 0.0075Epoch 00040: loss did not improve\n",
      "40000/40000 [==============================] - 103s - loss: 0.0075 - acc: 0.7381 - mean_squared_error: 0.0075 - val_loss: 0.0074 - val_acc: 0.7387 - val_mean_squared_error: 0.0074\n",
      "Epoch 42/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.7387 - mean_squared_error: 0.0074Epoch 00041: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0074 - acc: 0.7387 - mean_squared_error: 0.0074 - val_loss: 0.0074 - val_acc: 0.7378 - val_mean_squared_error: 0.0074\n",
      "Epoch 43/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.7392 - mean_squared_error: 0.0074Epoch 00042: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0074 - acc: 0.7392 - mean_squared_error: 0.0074 - val_loss: 0.0073 - val_acc: 0.7416 - val_mean_squared_error: 0.0073\n",
      "Epoch 44/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.7397 - mean_squared_error: 0.0073Epoch 00043: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0073 - acc: 0.7397 - mean_squared_error: 0.0073 - val_loss: 0.0073 - val_acc: 0.7400 - val_mean_squared_error: 0.0073\n",
      "Epoch 45/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.7402 - mean_squared_error: 0.0073Epoch 00044: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0073 - acc: 0.7402 - mean_squared_error: 0.0073 - val_loss: 0.0073 - val_acc: 0.7408 - val_mean_squared_error: 0.0073\n",
      "Epoch 46/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.7406 - mean_squared_error: 0.0073Epoch 00045: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0073 - acc: 0.7406 - mean_squared_error: 0.0073 - val_loss: 0.0072 - val_acc: 0.7399 - val_mean_squared_error: 0.0072\n",
      "Epoch 47/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.7410 - mean_squared_error: 0.0072Epoch 00046: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0072 - acc: 0.7410 - mean_squared_error: 0.0072 - val_loss: 0.0072 - val_acc: 0.7406 - val_mean_squared_error: 0.0072\n",
      "Epoch 48/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.7414 - mean_squared_error: 0.0072Epoch 00047: loss did not improve\n",
      "40000/40000 [==============================] - 101s - loss: 0.0072 - acc: 0.7414 - mean_squared_error: 0.0072 - val_loss: 0.0072 - val_acc: 0.7428 - val_mean_squared_error: 0.0072\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.7417 - mean_squared_error: 0.0072Epoch 00048: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0072 - acc: 0.7417 - mean_squared_error: 0.0072 - val_loss: 0.0071 - val_acc: 0.7422 - val_mean_squared_error: 0.0071\n",
      "Epoch 50/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.7420 - mean_squared_error: 0.0071Epoch 00049: loss did not improve\n",
      "40000/40000 [==============================] - 104s - loss: 0.0071 - acc: 0.7421 - mean_squared_error: 0.0071 - val_loss: 0.0071 - val_acc: 0.7401 - val_mean_squared_error: 0.0071\n",
      "Epoch 51/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.7424 - mean_squared_error: 0.0071Epoch 00050: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0071 - acc: 0.7424 - mean_squared_error: 0.0071 - val_loss: 0.0071 - val_acc: 0.7418 - val_mean_squared_error: 0.0071\n",
      "Epoch 52/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.7427 - mean_squared_error: 0.0071Epoch 00051: loss did not improve\n",
      "40000/40000 [==============================] - 103s - loss: 0.0071 - acc: 0.7427 - mean_squared_error: 0.0071 - val_loss: 0.0071 - val_acc: 0.7437 - val_mean_squared_error: 0.0071\n",
      "Epoch 53/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.7430 - mean_squared_error: 0.0071Epoch 00052: loss did not improve\n",
      "40000/40000 [==============================] - 102s - loss: 0.0071 - acc: 0.7430 - mean_squared_error: 0.0071 - val_loss: 0.0070 - val_acc: 0.7414 - val_mean_squared_error: 0.0070\n",
      "Epoch 54/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.7433 - mean_squared_error: 0.0070Epoch 00053: loss improved from 0.00703 to 0.00703, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0070 - acc: 0.7432 - mean_squared_error: 0.0070 - val_loss: 0.0070 - val_acc: 0.7421 - val_mean_squared_error: 0.0070\n",
      "Epoch 55/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.7435 - mean_squared_error: 0.0070Epoch 00054: loss improved from 0.00703 to 0.00700, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0070 - acc: 0.7434 - mean_squared_error: 0.0070 - val_loss: 0.0070 - val_acc: 0.7445 - val_mean_squared_error: 0.0070\n",
      "Epoch 56/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.7438 - mean_squared_error: 0.0070Epoch 00055: loss improved from 0.00700 to 0.00697, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0070 - acc: 0.7438 - mean_squared_error: 0.0070 - val_loss: 0.0070 - val_acc: 0.7432 - val_mean_squared_error: 0.0070\n",
      "Epoch 57/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.7440 - mean_squared_error: 0.0069Epoch 00056: loss improved from 0.00697 to 0.00695, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0069 - acc: 0.7440 - mean_squared_error: 0.0069 - val_loss: 0.0069 - val_acc: 0.7444 - val_mean_squared_error: 0.0069\n",
      "Epoch 58/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.7442 - mean_squared_error: 0.0069Epoch 00057: loss improved from 0.00695 to 0.00693, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0069 - acc: 0.7443 - mean_squared_error: 0.0069 - val_loss: 0.0069 - val_acc: 0.7471 - val_mean_squared_error: 0.0069\n",
      "Epoch 59/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.7445 - mean_squared_error: 0.0069Epoch 00058: loss improved from 0.00693 to 0.00690, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0069 - acc: 0.7445 - mean_squared_error: 0.0069 - val_loss: 0.0069 - val_acc: 0.7458 - val_mean_squared_error: 0.0069\n",
      "Epoch 60/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.7449 - mean_squared_error: 0.0069Epoch 00059: loss improved from 0.00690 to 0.00687, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0069 - acc: 0.7449 - mean_squared_error: 0.0069 - val_loss: 0.0069 - val_acc: 0.7468 - val_mean_squared_error: 0.0069\n",
      "Epoch 61/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.7452 - mean_squared_error: 0.0069Epoch 00060: loss improved from 0.00687 to 0.00685, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0069 - acc: 0.7452 - mean_squared_error: 0.0069 - val_loss: 0.0068 - val_acc: 0.7427 - val_mean_squared_error: 0.0068\n",
      "Epoch 62/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.7454 - mean_squared_error: 0.0068Epoch 00061: loss improved from 0.00685 to 0.00683, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0068 - acc: 0.7454 - mean_squared_error: 0.0068 - val_loss: 0.0068 - val_acc: 0.7450 - val_mean_squared_error: 0.0068\n",
      "Epoch 63/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.7457 - mean_squared_error: 0.0068Epoch 00062: loss improved from 0.00683 to 0.00681, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0068 - acc: 0.7456 - mean_squared_error: 0.0068 - val_loss: 0.0068 - val_acc: 0.7461 - val_mean_squared_error: 0.0068\n",
      "Epoch 64/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.7459 - mean_squared_error: 0.0068Epoch 00063: loss improved from 0.00681 to 0.00679, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0068 - acc: 0.7459 - mean_squared_error: 0.0068 - val_loss: 0.0068 - val_acc: 0.7441 - val_mean_squared_error: 0.0068\n",
      "Epoch 65/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.7461 - mean_squared_error: 0.0068Epoch 00064: loss improved from 0.00679 to 0.00677, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0068 - acc: 0.7461 - mean_squared_error: 0.0068 - val_loss: 0.0068 - val_acc: 0.7470 - val_mean_squared_error: 0.0068\n",
      "Epoch 66/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.7463 - mean_squared_error: 0.0067Epoch 00065: loss improved from 0.00677 to 0.00675, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0067 - acc: 0.7464 - mean_squared_error: 0.0067 - val_loss: 0.0067 - val_acc: 0.7461 - val_mean_squared_error: 0.0067\n",
      "Epoch 67/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.7466 - mean_squared_error: 0.0067Epoch 00066: loss improved from 0.00675 to 0.00672, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0067 - acc: 0.7466 - mean_squared_error: 0.0067 - val_loss: 0.0067 - val_acc: 0.7468 - val_mean_squared_error: 0.0067\n",
      "Epoch 68/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.7468 - mean_squared_error: 0.0067Epoch 00067: loss improved from 0.00672 to 0.00670, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0067 - acc: 0.7468 - mean_squared_error: 0.0067 - val_loss: 0.0067 - val_acc: 0.7468 - val_mean_squared_error: 0.0067\n",
      "Epoch 69/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.7470 - mean_squared_error: 0.0067Epoch 00068: loss improved from 0.00670 to 0.00668, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0067 - acc: 0.7470 - mean_squared_error: 0.0067 - val_loss: 0.0067 - val_acc: 0.7459 - val_mean_squared_error: 0.0067\n",
      "Epoch 70/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.7471 - mean_squared_error: 0.0067Epoch 00069: loss improved from 0.00668 to 0.00667, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0067 - acc: 0.7472 - mean_squared_error: 0.0067 - val_loss: 0.0067 - val_acc: 0.7458 - val_mean_squared_error: 0.0067\n",
      "Epoch 71/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.7474 - mean_squared_error: 0.0066Epoch 00070: loss improved from 0.00667 to 0.00665, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0066 - acc: 0.7474 - mean_squared_error: 0.0066 - val_loss: 0.0067 - val_acc: 0.7476 - val_mean_squared_error: 0.0067\n",
      "Epoch 72/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.7476 - mean_squared_error: 0.0066Epoch 00071: loss improved from 0.00665 to 0.00663, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0066 - acc: 0.7476 - mean_squared_error: 0.0066 - val_loss: 0.0066 - val_acc: 0.7464 - val_mean_squared_error: 0.0066\n",
      "Epoch 73/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.7477 - mean_squared_error: 0.0066Epoch 00072: loss improved from 0.00663 to 0.00661, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0066 - acc: 0.7477 - mean_squared_error: 0.0066 - val_loss: 0.0066 - val_acc: 0.7477 - val_mean_squared_error: 0.0066\n",
      "Epoch 74/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.7479 - mean_squared_error: 0.0066Epoch 00073: loss improved from 0.00661 to 0.00659, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0066 - acc: 0.7479 - mean_squared_error: 0.0066 - val_loss: 0.0066 - val_acc: 0.7490 - val_mean_squared_error: 0.0066\n",
      "Epoch 75/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.7480 - mean_squared_error: 0.0066Epoch 00074: loss improved from 0.00659 to 0.00657, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0066 - acc: 0.7480 - mean_squared_error: 0.0066 - val_loss: 0.0066 - val_acc: 0.7478 - val_mean_squared_error: 0.0066\n",
      "Epoch 76/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.7482 - mean_squared_error: 0.0066Epoch 00075: loss improved from 0.00657 to 0.00656, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0066 - acc: 0.7482 - mean_squared_error: 0.0066 - val_loss: 0.0065 - val_acc: 0.7486 - val_mean_squared_error: 0.0065\n",
      "Epoch 77/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.7484 - mean_squared_error: 0.0065Epoch 00076: loss improved from 0.00656 to 0.00654, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0065 - acc: 0.7484 - mean_squared_error: 0.0065 - val_loss: 0.0065 - val_acc: 0.7508 - val_mean_squared_error: 0.0065\n",
      "Epoch 78/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.7486 - mean_squared_error: 0.0065Epoch 00077: loss improved from 0.00654 to 0.00652, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0065 - acc: 0.7486 - mean_squared_error: 0.0065 - val_loss: 0.0065 - val_acc: 0.7492 - val_mean_squared_error: 0.0065\n",
      "Epoch 79/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.7488 - mean_squared_error: 0.0065Epoch 00078: loss improved from 0.00652 to 0.00651, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0065 - acc: 0.7488 - mean_squared_error: 0.0065 - val_loss: 0.0065 - val_acc: 0.7468 - val_mean_squared_error: 0.0065\n",
      "Epoch 80/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.7490 - mean_squared_error: 0.0065Epoch 00079: loss improved from 0.00651 to 0.00649, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0065 - acc: 0.7490 - mean_squared_error: 0.0065 - val_loss: 0.0065 - val_acc: 0.7490 - val_mean_squared_error: 0.0065\n",
      "Epoch 81/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.7492 - mean_squared_error: 0.0065Epoch 00080: loss improved from 0.00649 to 0.00648, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0065 - acc: 0.7491 - mean_squared_error: 0.0065 - val_loss: 0.0065 - val_acc: 0.7501 - val_mean_squared_error: 0.0065\n",
      "Epoch 82/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.7493 - mean_squared_error: 0.0065Epoch 00081: loss improved from 0.00648 to 0.00646, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0065 - acc: 0.7493 - mean_squared_error: 0.0065 - val_loss: 0.0065 - val_acc: 0.7501 - val_mean_squared_error: 0.0065\n",
      "Epoch 83/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.7495 - mean_squared_error: 0.0064Epoch 00082: loss improved from 0.00646 to 0.00644, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0064 - acc: 0.7495 - mean_squared_error: 0.0064 - val_loss: 0.0065 - val_acc: 0.7520 - val_mean_squared_error: 0.0065\n",
      "Epoch 84/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.7498 - mean_squared_error: 0.0064Epoch 00083: loss improved from 0.00644 to 0.00643, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0064 - acc: 0.7498 - mean_squared_error: 0.0064 - val_loss: 0.0064 - val_acc: 0.7501 - val_mean_squared_error: 0.0064\n",
      "Epoch 85/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.7499 - mean_squared_error: 0.0064Epoch 00084: loss improved from 0.00643 to 0.00641, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0064 - acc: 0.7499 - mean_squared_error: 0.0064 - val_loss: 0.0064 - val_acc: 0.7520 - val_mean_squared_error: 0.0064\n",
      "Epoch 86/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.7501 - mean_squared_error: 0.0064Epoch 00085: loss improved from 0.00641 to 0.00640, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0064 - acc: 0.7501 - mean_squared_error: 0.0064 - val_loss: 0.0064 - val_acc: 0.7502 - val_mean_squared_error: 0.0064\n",
      "Epoch 87/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.7504 - mean_squared_error: 0.0064Epoch 00086: loss improved from 0.00640 to 0.00639, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0064 - acc: 0.7503 - mean_squared_error: 0.0064 - val_loss: 0.0064 - val_acc: 0.7510 - val_mean_squared_error: 0.0064\n",
      "Epoch 88/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.7504 - mean_squared_error: 0.0064Epoch 00087: loss improved from 0.00639 to 0.00637, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0064 - acc: 0.7504 - mean_squared_error: 0.0064 - val_loss: 0.0064 - val_acc: 0.7511 - val_mean_squared_error: 0.0064\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.7506 - mean_squared_error: 0.0064Epoch 00088: loss improved from 0.00637 to 0.00636, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0064 - acc: 0.7506 - mean_squared_error: 0.0064 - val_loss: 0.0063 - val_acc: 0.7494 - val_mean_squared_error: 0.0063\n",
      "Epoch 90/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.7508 - mean_squared_error: 0.0063Epoch 00089: loss improved from 0.00636 to 0.00634, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0063 - acc: 0.7509 - mean_squared_error: 0.0063 - val_loss: 0.0063 - val_acc: 0.7511 - val_mean_squared_error: 0.0063\n",
      "Epoch 91/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.7510 - mean_squared_error: 0.0063Epoch 00090: loss improved from 0.00634 to 0.00633, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0063 - acc: 0.7510 - mean_squared_error: 0.0063 - val_loss: 0.0063 - val_acc: 0.7522 - val_mean_squared_error: 0.0063\n",
      "Epoch 92/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.7513 - mean_squared_error: 0.0063Epoch 00091: loss improved from 0.00633 to 0.00631, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0063 - acc: 0.7512 - mean_squared_error: 0.0063 - val_loss: 0.0063 - val_acc: 0.7480 - val_mean_squared_error: 0.0063\n",
      "Epoch 93/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.7514 - mean_squared_error: 0.0063Epoch 00092: loss improved from 0.00631 to 0.00630, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0063 - acc: 0.7514 - mean_squared_error: 0.0063 - val_loss: 0.0063 - val_acc: 0.7534 - val_mean_squared_error: 0.0063\n",
      "Epoch 94/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.7516 - mean_squared_error: 0.0063Epoch 00093: loss improved from 0.00630 to 0.00629, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0063 - acc: 0.7515 - mean_squared_error: 0.0063 - val_loss: 0.0063 - val_acc: 0.7535 - val_mean_squared_error: 0.0063\n",
      "Epoch 95/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.7517 - mean_squared_error: 0.0063Epoch 00094: loss improved from 0.00629 to 0.00627, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0063 - acc: 0.7517 - mean_squared_error: 0.0063 - val_loss: 0.0063 - val_acc: 0.7507 - val_mean_squared_error: 0.0063\n",
      "Epoch 96/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.7519 - mean_squared_error: 0.0063Epoch 00095: loss improved from 0.00627 to 0.00626, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0063 - acc: 0.7519 - mean_squared_error: 0.0063 - val_loss: 0.0063 - val_acc: 0.7530 - val_mean_squared_error: 0.0063\n",
      "Epoch 97/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.7521 - mean_squared_error: 0.0062Epoch 00096: loss improved from 0.00626 to 0.00625, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0062 - acc: 0.7521 - mean_squared_error: 0.0062 - val_loss: 0.0063 - val_acc: 0.7516 - val_mean_squared_error: 0.0063\n",
      "Epoch 98/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.7523 - mean_squared_error: 0.0062Epoch 00097: loss improved from 0.00625 to 0.00624, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0062 - acc: 0.7523 - mean_squared_error: 0.0062 - val_loss: 0.0062 - val_acc: 0.7533 - val_mean_squared_error: 0.0062\n",
      "Epoch 99/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.7525 - mean_squared_error: 0.0062Epoch 00098: loss improved from 0.00624 to 0.00622, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0062 - acc: 0.7524 - mean_squared_error: 0.0062 - val_loss: 0.0062 - val_acc: 0.7533 - val_mean_squared_error: 0.0062\n",
      "Epoch 100/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.7526 - mean_squared_error: 0.0062Epoch 00099: loss improved from 0.00622 to 0.00621, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0062 - acc: 0.7526 - mean_squared_error: 0.0062 - val_loss: 0.0062 - val_acc: 0.7537 - val_mean_squared_error: 0.0062\n",
      "Epoch 101/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.7528 - mean_squared_error: 0.0062Epoch 00100: loss improved from 0.00621 to 0.00620, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0062 - acc: 0.7528 - mean_squared_error: 0.0062 - val_loss: 0.0062 - val_acc: 0.7536 - val_mean_squared_error: 0.0062\n",
      "Epoch 102/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.7529 - mean_squared_error: 0.0062Epoch 00101: loss improved from 0.00620 to 0.00619, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0062 - acc: 0.7529 - mean_squared_error: 0.0062 - val_loss: 0.0062 - val_acc: 0.7527 - val_mean_squared_error: 0.0062\n",
      "Epoch 103/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.7531 - mean_squared_error: 0.0062Epoch 00102: loss improved from 0.00619 to 0.00618, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0062 - acc: 0.7531 - mean_squared_error: 0.0062 - val_loss: 0.0062 - val_acc: 0.7546 - val_mean_squared_error: 0.0062\n",
      "Epoch 104/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.7533 - mean_squared_error: 0.0062Epoch 00103: loss improved from 0.00618 to 0.00617, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0062 - acc: 0.7533 - mean_squared_error: 0.0062 - val_loss: 0.0062 - val_acc: 0.7527 - val_mean_squared_error: 0.0062\n",
      "Epoch 105/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.7534 - mean_squared_error: 0.0062Epoch 00104: loss improved from 0.00617 to 0.00615, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0062 - acc: 0.7534 - mean_squared_error: 0.0062 - val_loss: 0.0062 - val_acc: 0.7538 - val_mean_squared_error: 0.0062\n",
      "Epoch 106/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.7535 - mean_squared_error: 0.0061Epoch 00105: loss improved from 0.00615 to 0.00614, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0061 - acc: 0.7535 - mean_squared_error: 0.0061 - val_loss: 0.0061 - val_acc: 0.7546 - val_mean_squared_error: 0.0061\n",
      "Epoch 107/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.7537 - mean_squared_error: 0.0061Epoch 00106: loss improved from 0.00614 to 0.00613, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0061 - acc: 0.7537 - mean_squared_error: 0.0061 - val_loss: 0.0061 - val_acc: 0.7556 - val_mean_squared_error: 0.0061\n",
      "Epoch 108/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.7538 - mean_squared_error: 0.0061Epoch 00107: loss improved from 0.00613 to 0.00612, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0061 - acc: 0.7538 - mean_squared_error: 0.0061 - val_loss: 0.0061 - val_acc: 0.7549 - val_mean_squared_error: 0.0061\n",
      "Epoch 109/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.7541 - mean_squared_error: 0.0061Epoch 00108: loss improved from 0.00612 to 0.00611, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0061 - acc: 0.7541 - mean_squared_error: 0.0061 - val_loss: 0.0061 - val_acc: 0.7538 - val_mean_squared_error: 0.0061\n",
      "Epoch 110/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.7542 - mean_squared_error: 0.0061Epoch 00109: loss improved from 0.00611 to 0.00610, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0061 - acc: 0.7542 - mean_squared_error: 0.0061 - val_loss: 0.0061 - val_acc: 0.7526 - val_mean_squared_error: 0.0061\n",
      "Epoch 111/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.7544 - mean_squared_error: 0.0061Epoch 00110: loss improved from 0.00610 to 0.00609, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0061 - acc: 0.7544 - mean_squared_error: 0.0061 - val_loss: 0.0061 - val_acc: 0.7542 - val_mean_squared_error: 0.0061\n",
      "Epoch 112/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.7544 - mean_squared_error: 0.0061Epoch 00111: loss improved from 0.00609 to 0.00607, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0061 - acc: 0.7545 - mean_squared_error: 0.0061 - val_loss: 0.0061 - val_acc: 0.7549 - val_mean_squared_error: 0.0061\n",
      "Epoch 113/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.7545 - mean_squared_error: 0.0061Epoch 00112: loss improved from 0.00607 to 0.00606, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0061 - acc: 0.7546 - mean_squared_error: 0.0061 - val_loss: 0.0061 - val_acc: 0.7548 - val_mean_squared_error: 0.0061\n",
      "Epoch 114/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.7547 - mean_squared_error: 0.0061Epoch 00113: loss improved from 0.00606 to 0.00605, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0061 - acc: 0.7548 - mean_squared_error: 0.0061 - val_loss: 0.0061 - val_acc: 0.7548 - val_mean_squared_error: 0.0061\n",
      "Epoch 115/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.7550 - mean_squared_error: 0.0060Epoch 00114: loss improved from 0.00605 to 0.00604, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0060 - acc: 0.7549 - mean_squared_error: 0.0060 - val_loss: 0.0061 - val_acc: 0.7578 - val_mean_squared_error: 0.0061\n",
      "Epoch 116/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.7550 - mean_squared_error: 0.0060Epoch 00115: loss improved from 0.00604 to 0.00603, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0060 - acc: 0.7550 - mean_squared_error: 0.0060 - val_loss: 0.0060 - val_acc: 0.7566 - val_mean_squared_error: 0.0060\n",
      "Epoch 117/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.7552 - mean_squared_error: 0.0060Epoch 00116: loss improved from 0.00603 to 0.00602, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0060 - acc: 0.7552 - mean_squared_error: 0.0060 - val_loss: 0.0060 - val_acc: 0.7554 - val_mean_squared_error: 0.0060\n",
      "Epoch 118/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.7553 - mean_squared_error: 0.0060Epoch 00117: loss improved from 0.00602 to 0.00601, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0060 - acc: 0.7553 - mean_squared_error: 0.0060 - val_loss: 0.0060 - val_acc: 0.7563 - val_mean_squared_error: 0.0060\n",
      "Epoch 119/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.7554 - mean_squared_error: 0.0060Epoch 00118: loss improved from 0.00601 to 0.00600, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0060 - acc: 0.7554 - mean_squared_error: 0.0060 - val_loss: 0.0060 - val_acc: 0.7545 - val_mean_squared_error: 0.0060\n",
      "Epoch 120/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.7556 - mean_squared_error: 0.0060Epoch 00119: loss improved from 0.00600 to 0.00599, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0060 - acc: 0.7556 - mean_squared_error: 0.0060 - val_loss: 0.0060 - val_acc: 0.7556 - val_mean_squared_error: 0.0060\n",
      "Epoch 121/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.7557 - mean_squared_error: 0.0060Epoch 00120: loss improved from 0.00599 to 0.00598, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0060 - acc: 0.7557 - mean_squared_error: 0.0060 - val_loss: 0.0060 - val_acc: 0.7553 - val_mean_squared_error: 0.0060\n",
      "Epoch 122/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.7559 - mean_squared_error: 0.0060Epoch 00121: loss improved from 0.00598 to 0.00597, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0060 - acc: 0.7559 - mean_squared_error: 0.0060 - val_loss: 0.0060 - val_acc: 0.7568 - val_mean_squared_error: 0.0060\n",
      "Epoch 123/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.7560 - mean_squared_error: 0.0060Epoch 00122: loss improved from 0.00597 to 0.00596, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0060 - acc: 0.7560 - mean_squared_error: 0.0060 - val_loss: 0.0060 - val_acc: 0.7565 - val_mean_squared_error: 0.0060\n",
      "Epoch 124/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.7561 - mean_squared_error: 0.0060Epoch 00123: loss improved from 0.00596 to 0.00595, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0060 - acc: 0.7561 - mean_squared_error: 0.0060 - val_loss: 0.0060 - val_acc: 0.7581 - val_mean_squared_error: 0.0060\n",
      "Epoch 125/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.7562 - mean_squared_error: 0.0059Epoch 00124: loss improved from 0.00595 to 0.00594, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0059 - acc: 0.7562 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_acc: 0.7556 - val_mean_squared_error: 0.0059\n",
      "Epoch 126/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.7564 - mean_squared_error: 0.0059Epoch 00125: loss improved from 0.00594 to 0.00593, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0059 - acc: 0.7564 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_acc: 0.7567 - val_mean_squared_error: 0.0059\n",
      "Epoch 127/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.7565 - mean_squared_error: 0.0059Epoch 00126: loss improved from 0.00593 to 0.00592, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0059 - acc: 0.7565 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_acc: 0.7558 - val_mean_squared_error: 0.0059\n",
      "Epoch 128/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.7566 - mean_squared_error: 0.0059Epoch 00127: loss improved from 0.00592 to 0.00592, saving model to ./models/simple_cnn_autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 101s - loss: 0.0059 - acc: 0.7566 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_acc: 0.7558 - val_mean_squared_error: 0.0059\n",
      "Epoch 129/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.7567 - mean_squared_error: 0.0059Epoch 00128: loss improved from 0.00592 to 0.00591, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0059 - acc: 0.7567 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_acc: 0.7562 - val_mean_squared_error: 0.0059\n",
      "Epoch 130/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.7568 - mean_squared_error: 0.0059Epoch 00129: loss improved from 0.00591 to 0.00590, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0059 - acc: 0.7568 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_acc: 0.7549 - val_mean_squared_error: 0.0059\n",
      "Epoch 131/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.7570 - mean_squared_error: 0.0059Epoch 00130: loss improved from 0.00590 to 0.00589, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0059 - acc: 0.7570 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_acc: 0.7554 - val_mean_squared_error: 0.0059\n",
      "Epoch 132/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.7570 - mean_squared_error: 0.0059Epoch 00131: loss improved from 0.00589 to 0.00588, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0059 - acc: 0.7570 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_acc: 0.7576 - val_mean_squared_error: 0.0059\n",
      "Epoch 133/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.7571 - mean_squared_error: 0.0059Epoch 00132: loss improved from 0.00588 to 0.00587, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0059 - acc: 0.7572 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_acc: 0.7574 - val_mean_squared_error: 0.0059\n",
      "Epoch 134/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.7573 - mean_squared_error: 0.0059Epoch 00133: loss improved from 0.00587 to 0.00586, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0059 - acc: 0.7572 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_acc: 0.7574 - val_mean_squared_error: 0.0059\n",
      "Epoch 135/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.7574 - mean_squared_error: 0.0059Epoch 00134: loss improved from 0.00586 to 0.00585, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0059 - acc: 0.7574 - mean_squared_error: 0.0059 - val_loss: 0.0059 - val_acc: 0.7575 - val_mean_squared_error: 0.0059\n",
      "Epoch 136/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.7574 - mean_squared_error: 0.0058Epoch 00135: loss improved from 0.00585 to 0.00584, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0058 - acc: 0.7575 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_acc: 0.7599 - val_mean_squared_error: 0.0058\n",
      "Epoch 137/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.7576 - mean_squared_error: 0.0058Epoch 00136: loss improved from 0.00584 to 0.00584, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0058 - acc: 0.7576 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_acc: 0.7597 - val_mean_squared_error: 0.0058\n",
      "Epoch 138/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.7578 - mean_squared_error: 0.0058Epoch 00137: loss improved from 0.00584 to 0.00583, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0058 - acc: 0.7577 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_acc: 0.7579 - val_mean_squared_error: 0.0058\n",
      "Epoch 139/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.7578 - mean_squared_error: 0.0058Epoch 00138: loss improved from 0.00583 to 0.00582, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0058 - acc: 0.7578 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_acc: 0.7575 - val_mean_squared_error: 0.0058\n",
      "Epoch 140/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.7580 - mean_squared_error: 0.0058Epoch 00139: loss improved from 0.00582 to 0.00581, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0058 - acc: 0.7580 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_acc: 0.7588 - val_mean_squared_error: 0.0058\n",
      "Epoch 141/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.7581 - mean_squared_error: 0.0058Epoch 00140: loss improved from 0.00581 to 0.00580, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0058 - acc: 0.7581 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_acc: 0.7596 - val_mean_squared_error: 0.0058\n",
      "Epoch 142/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.7582 - mean_squared_error: 0.0058Epoch 00141: loss improved from 0.00580 to 0.00579, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0058 - acc: 0.7582 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_acc: 0.7598 - val_mean_squared_error: 0.0058\n",
      "Epoch 143/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.7583 - mean_squared_error: 0.0058Epoch 00142: loss improved from 0.00579 to 0.00579, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0058 - acc: 0.7583 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_acc: 0.7580 - val_mean_squared_error: 0.0058\n",
      "Epoch 144/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.7584 - mean_squared_error: 0.0058Epoch 00143: loss improved from 0.00579 to 0.00578, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0058 - acc: 0.7584 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_acc: 0.7592 - val_mean_squared_error: 0.0058\n",
      "Epoch 145/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.7585 - mean_squared_error: 0.0058Epoch 00144: loss improved from 0.00578 to 0.00577, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0058 - acc: 0.7585 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_acc: 0.7588 - val_mean_squared_error: 0.0058\n",
      "Epoch 146/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.7586 - mean_squared_error: 0.0058Epoch 00145: loss improved from 0.00577 to 0.00576, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0058 - acc: 0.7586 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_acc: 0.7610 - val_mean_squared_error: 0.0058\n",
      "Epoch 147/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.7587 - mean_squared_error: 0.0058Epoch 00146: loss improved from 0.00576 to 0.00575, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0058 - acc: 0.7587 - mean_squared_error: 0.0058 - val_loss: 0.0058 - val_acc: 0.7604 - val_mean_squared_error: 0.0058\n",
      "Epoch 148/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7588 - mean_squared_error: 0.0057Epoch 00147: loss improved from 0.00575 to 0.00575, saving model to ./models/simple_cnn_autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 101s - loss: 0.0057 - acc: 0.7588 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_acc: 0.7590 - val_mean_squared_error: 0.0058\n",
      "Epoch 149/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7589 - mean_squared_error: 0.0057Epoch 00148: loss improved from 0.00575 to 0.00574, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0057 - acc: 0.7590 - mean_squared_error: 0.0057 - val_loss: 0.0058 - val_acc: 0.7611 - val_mean_squared_error: 0.0058\n",
      "Epoch 150/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7590 - mean_squared_error: 0.0057Epoch 00149: loss improved from 0.00574 to 0.00573, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0057 - acc: 0.7590 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_acc: 0.7601 - val_mean_squared_error: 0.0057\n",
      "Epoch 151/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7591 - mean_squared_error: 0.0057Epoch 00150: loss improved from 0.00573 to 0.00572, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0057 - acc: 0.7591 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_acc: 0.7583 - val_mean_squared_error: 0.0057\n",
      "Epoch 152/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7592 - mean_squared_error: 0.0057Epoch 00151: loss improved from 0.00572 to 0.00571, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0057 - acc: 0.7592 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_acc: 0.7571 - val_mean_squared_error: 0.0057\n",
      "Epoch 153/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7593 - mean_squared_error: 0.0057Epoch 00152: loss improved from 0.00571 to 0.00571, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0057 - acc: 0.7593 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_acc: 0.7575 - val_mean_squared_error: 0.0057\n",
      "Epoch 154/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7594 - mean_squared_error: 0.0057Epoch 00153: loss improved from 0.00571 to 0.00570, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0057 - acc: 0.7594 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_acc: 0.7602 - val_mean_squared_error: 0.0057\n",
      "Epoch 155/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7594 - mean_squared_error: 0.0057Epoch 00154: loss improved from 0.00570 to 0.00569, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0057 - acc: 0.7594 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_acc: 0.7595 - val_mean_squared_error: 0.0057\n",
      "Epoch 156/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7596 - mean_squared_error: 0.0057Epoch 00155: loss improved from 0.00569 to 0.00568, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0057 - acc: 0.7596 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_acc: 0.7601 - val_mean_squared_error: 0.0057\n",
      "Epoch 157/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7596 - mean_squared_error: 0.0057Epoch 00156: loss improved from 0.00568 to 0.00568, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0057 - acc: 0.7596 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_acc: 0.7598 - val_mean_squared_error: 0.0057\n",
      "Epoch 158/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7597 - mean_squared_error: 0.0057Epoch 00157: loss improved from 0.00568 to 0.00567, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0057 - acc: 0.7597 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_acc: 0.7599 - val_mean_squared_error: 0.0057\n",
      "Epoch 159/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7598 - mean_squared_error: 0.0057Epoch 00158: loss improved from 0.00567 to 0.00566, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0057 - acc: 0.7598 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_acc: 0.7596 - val_mean_squared_error: 0.0057\n",
      "Epoch 160/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.7599 - mean_squared_error: 0.0057Epoch 00159: loss improved from 0.00566 to 0.00566, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0057 - acc: 0.7599 - mean_squared_error: 0.0057 - val_loss: 0.0057 - val_acc: 0.7615 - val_mean_squared_error: 0.0057\n",
      "Epoch 161/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7599 - mean_squared_error: 0.0056Epoch 00160: loss improved from 0.00566 to 0.00565, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0056 - acc: 0.7599 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_acc: 0.7610 - val_mean_squared_error: 0.0057\n",
      "Epoch 162/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7600 - mean_squared_error: 0.0056Epoch 00161: loss improved from 0.00565 to 0.00564, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0056 - acc: 0.7600 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7621 - val_mean_squared_error: 0.0056\n",
      "Epoch 163/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7601 - mean_squared_error: 0.0056Epoch 00162: loss improved from 0.00564 to 0.00563, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0056 - acc: 0.7601 - mean_squared_error: 0.0056 - val_loss: 0.0057 - val_acc: 0.7586 - val_mean_squared_error: 0.0057\n",
      "Epoch 164/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7602 - mean_squared_error: 0.0056Epoch 00163: loss improved from 0.00563 to 0.00563, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0056 - acc: 0.7602 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7623 - val_mean_squared_error: 0.0056\n",
      "Epoch 165/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7603 - mean_squared_error: 0.0056Epoch 00164: loss improved from 0.00563 to 0.00562, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0056 - acc: 0.7603 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7613 - val_mean_squared_error: 0.0056\n",
      "Epoch 166/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7604 - mean_squared_error: 0.0056Epoch 00165: loss improved from 0.00562 to 0.00561, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0056 - acc: 0.7604 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7602 - val_mean_squared_error: 0.0056\n",
      "Epoch 167/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7605 - mean_squared_error: 0.0056Epoch 00166: loss improved from 0.00561 to 0.00561, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0056 - acc: 0.7605 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7591 - val_mean_squared_error: 0.0056\n",
      "Epoch 168/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7605 - mean_squared_error: 0.0056Epoch 00167: loss improved from 0.00561 to 0.00560, saving model to ./models/simple_cnn_autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 101s - loss: 0.0056 - acc: 0.7605 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7622 - val_mean_squared_error: 0.0056\n",
      "Epoch 169/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7606 - mean_squared_error: 0.0056Epoch 00168: loss improved from 0.00560 to 0.00559, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0056 - acc: 0.7606 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7599 - val_mean_squared_error: 0.0056\n",
      "Epoch 170/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7606 - mean_squared_error: 0.0056Epoch 00169: loss improved from 0.00559 to 0.00559, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0056 - acc: 0.7606 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7616 - val_mean_squared_error: 0.0056\n",
      "Epoch 171/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7607 - mean_squared_error: 0.0056Epoch 00170: loss improved from 0.00559 to 0.00558, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0056 - acc: 0.7607 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7608 - val_mean_squared_error: 0.0056\n",
      "Epoch 172/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7608 - mean_squared_error: 0.0056Epoch 00171: loss improved from 0.00558 to 0.00557, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0056 - acc: 0.7608 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7617 - val_mean_squared_error: 0.0056\n",
      "Epoch 173/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7609 - mean_squared_error: 0.0056Epoch 00172: loss improved from 0.00557 to 0.00557, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0056 - acc: 0.7609 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7602 - val_mean_squared_error: 0.0056\n",
      "Epoch 174/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7610 - mean_squared_error: 0.0056Epoch 00173: loss improved from 0.00557 to 0.00556, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0056 - acc: 0.7610 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7605 - val_mean_squared_error: 0.0056\n",
      "Epoch 175/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.7611 - mean_squared_error: 0.0056Epoch 00174: loss improved from 0.00556 to 0.00555, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0056 - acc: 0.7610 - mean_squared_error: 0.0056 - val_loss: 0.0056 - val_acc: 0.7615 - val_mean_squared_error: 0.0056\n",
      "Epoch 176/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7611 - mean_squared_error: 0.0055Epoch 00175: loss improved from 0.00555 to 0.00555, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0055 - acc: 0.7611 - mean_squared_error: 0.0055 - val_loss: 0.0056 - val_acc: 0.7623 - val_mean_squared_error: 0.0056\n",
      "Epoch 177/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7612 - mean_squared_error: 0.0055Epoch 00176: loss improved from 0.00555 to 0.00554, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0055 - acc: 0.7612 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7610 - val_mean_squared_error: 0.0055\n",
      "Epoch 178/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7613 - mean_squared_error: 0.0055Epoch 00177: loss improved from 0.00554 to 0.00554, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0055 - acc: 0.7613 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7615 - val_mean_squared_error: 0.0055\n",
      "Epoch 179/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7613 - mean_squared_error: 0.0055Epoch 00178: loss improved from 0.00554 to 0.00553, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0055 - acc: 0.7613 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7610 - val_mean_squared_error: 0.0055\n",
      "Epoch 180/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7614 - mean_squared_error: 0.0055Epoch 00179: loss improved from 0.00553 to 0.00552, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0055 - acc: 0.7614 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7623 - val_mean_squared_error: 0.0055\n",
      "Epoch 181/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7615 - mean_squared_error: 0.0055Epoch 00180: loss improved from 0.00552 to 0.00552, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0055 - acc: 0.7615 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7634 - val_mean_squared_error: 0.0055\n",
      "Epoch 182/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7616 - mean_squared_error: 0.0055Epoch 00181: loss improved from 0.00552 to 0.00551, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0055 - acc: 0.7616 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7611 - val_mean_squared_error: 0.0055\n",
      "Epoch 183/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7616 - mean_squared_error: 0.0055Epoch 00182: loss improved from 0.00551 to 0.00551, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0055 - acc: 0.7616 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7637 - val_mean_squared_error: 0.0055\n",
      "Epoch 184/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7617 - mean_squared_error: 0.0055Epoch 00183: loss improved from 0.00551 to 0.00550, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0055 - acc: 0.7618 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7607 - val_mean_squared_error: 0.0055\n",
      "Epoch 185/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7618 - mean_squared_error: 0.0055Epoch 00184: loss improved from 0.00550 to 0.00549, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0055 - acc: 0.7618 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7635 - val_mean_squared_error: 0.0055\n",
      "Epoch 186/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7619 - mean_squared_error: 0.0055Epoch 00185: loss improved from 0.00549 to 0.00549, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0055 - acc: 0.7619 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7623 - val_mean_squared_error: 0.0055\n",
      "Epoch 187/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7620 - mean_squared_error: 0.0055Epoch 00186: loss improved from 0.00549 to 0.00548, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0055 - acc: 0.7620 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7623 - val_mean_squared_error: 0.0055\n",
      "Epoch 188/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7620 - mean_squared_error: 0.0055Epoch 00187: loss improved from 0.00548 to 0.00548, saving model to ./models/simple_cnn_autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 102s - loss: 0.0055 - acc: 0.7620 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7622 - val_mean_squared_error: 0.0055\n",
      "Epoch 189/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7622 - mean_squared_error: 0.0055Epoch 00188: loss improved from 0.00548 to 0.00547, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 103s - loss: 0.0055 - acc: 0.7622 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7619 - val_mean_squared_error: 0.0055\n",
      "Epoch 190/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7622 - mean_squared_error: 0.0055Epoch 00189: loss improved from 0.00547 to 0.00546, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0055 - acc: 0.7622 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7625 - val_mean_squared_error: 0.0055\n",
      "Epoch 191/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7623 - mean_squared_error: 0.0055Epoch 00190: loss improved from 0.00546 to 0.00546, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0055 - acc: 0.7623 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7639 - val_mean_squared_error: 0.0055\n",
      "Epoch 192/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.7623 - mean_squared_error: 0.0055Epoch 00191: loss improved from 0.00546 to 0.00545, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0055 - acc: 0.7623 - mean_squared_error: 0.0055 - val_loss: 0.0055 - val_acc: 0.7636 - val_mean_squared_error: 0.0055\n",
      "Epoch 193/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.7625 - mean_squared_error: 0.0054Epoch 00192: loss improved from 0.00545 to 0.00545, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0054 - acc: 0.7625 - mean_squared_error: 0.0054 - val_loss: 0.0055 - val_acc: 0.7629 - val_mean_squared_error: 0.0055\n",
      "Epoch 194/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.7625 - mean_squared_error: 0.0054Epoch 00193: loss improved from 0.00545 to 0.00544, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0054 - acc: 0.7625 - mean_squared_error: 0.0054 - val_loss: 0.0055 - val_acc: 0.7645 - val_mean_squared_error: 0.0055\n",
      "Epoch 195/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.7626 - mean_squared_error: 0.0054Epoch 00194: loss improved from 0.00544 to 0.00544, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0054 - acc: 0.7626 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_acc: 0.7630 - val_mean_squared_error: 0.0054\n",
      "Epoch 196/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.7626 - mean_squared_error: 0.0054Epoch 00195: loss improved from 0.00544 to 0.00543, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0054 - acc: 0.7627 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_acc: 0.7646 - val_mean_squared_error: 0.0054\n",
      "Epoch 197/200\n",
      "39960/40000 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.7627 - mean_squared_error: 0.0054Epoch 00196: loss improved from 0.00543 to 0.00542, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0054 - acc: 0.7627 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_acc: 0.7642 - val_mean_squared_error: 0.0054\n",
      "Epoch 198/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.7628 - mean_squared_error: 0.0054Epoch 00197: loss improved from 0.00542 to 0.00542, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 101s - loss: 0.0054 - acc: 0.7628 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_acc: 0.7643 - val_mean_squared_error: 0.0054\n",
      "Epoch 199/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.7628 - mean_squared_error: 0.0054Epoch 00198: loss improved from 0.00542 to 0.00541, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0054 - acc: 0.7629 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_acc: 0.7633 - val_mean_squared_error: 0.0054\n",
      "Epoch 200/200\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.7629 - mean_squared_error: 0.0054Epoch 00199: loss improved from 0.00541 to 0.00541, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 102s - loss: 0.0054 - acc: 0.7630 - mean_squared_error: 0.0054 - val_loss: 0.0054 - val_acc: 0.7628 - val_mean_squared_error: 0.0054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe570aec90>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=200,\n",
    "                batch_size=20,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder', histogram_freq=0, write_graph=True), model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to get saved keras model\n",
    "def read_model_json(jsonfilePath,h5filePath):\n",
    "    try:\n",
    "        json_file = open(jsonfilePath, 'r')\n",
    "        print json_file\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        print \"hello\"\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "         \n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(h5filePath)\n",
    "\n",
    "        return loaded_model\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gated_connections(gatePercentageFactor,inputLayer):\n",
    "    gateFactor = Input(tensor = K.variable([gatePercentageFactor]))\n",
    "    fractionG = Lambda(lambda x: x[0]*x[1])([inputLayer,gateFactor])\n",
    "    complement = Lambda(lambda x: x[0] - x[1])([inputLayer,fractionG])\n",
    "    \n",
    "    return gateFactor,fractionG,complement\n",
    "\n",
    "#x is conv layer\n",
    "#y is de-conv layer\n",
    "#gf is gating factor\n",
    "#fg is fractional input from gate\n",
    "#c is complement ie remaining fraction from the gate\n",
    "#jt joining tensor of convolution layer and previous de-conv layer \n",
    "\n",
    "def get_cnn_dsc_architecture(model_path=None):\n",
    "    \n",
    "    if(model_path is None):\n",
    "        sym_autoencoder = None\n",
    "    else:\n",
    "        sym_autoencoder = read_model_json(model_path[0],model_path[1])\n",
    "        print model_path[0],model_path[1]\n",
    "    if(sym_autoencoder is None):\n",
    "        input_img = Input(shape=(None,None,3))  # adapt this if using `channels_first` image data format\n",
    "        x1 = Conv2D(64, (4, 4), activation='relu', padding='same')(input_img)\n",
    "        gf1,fg1,c1 = get_gated_connections(0.1,x1)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(fg1)\n",
    "        x2 = Conv2D(64, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf2,fg2,c2 = get_gated_connections(0.2,x2)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(fg2)\n",
    "        x3 = Conv2D(128, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf3,fg3,c3 = get_gated_connections(0.3,x3)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x3)\n",
    "        x4 = Conv2D(256, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf4,fg4,c4 = get_gated_connections(0.4,x4)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x4)\n",
    "        x5 = Conv2D(512, (4, 4), activation='relu', padding='same')(x) \n",
    "\n",
    "        x = UpSampling2D((2, 2))(x5)\n",
    "        y1 = Conv2DTranspose(256, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt4 = Add()([y1,c4])\n",
    "        x = UpSampling2D((2, 2))(jt4)\n",
    "\n",
    "        y2 = Conv2DTranspose(128, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt3 = Add()([y2,c3])\n",
    "        x = UpSampling2D((2, 2))(jt3)\n",
    "\n",
    "        y3 = Conv2DTranspose(64, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt2 = Add()([y3,c2])\n",
    "        x = UpSampling2D((2, 2))(jt2)\n",
    "\n",
    "        jt1 = Add()([x,c1])\n",
    "        y4 = Conv2DTranspose(64, (4, 4), activation='relu', padding='same')(jt1)\n",
    "        y5 = Conv2DTranspose(3, (4, 4), activation='relu', padding='same')(y4) \n",
    "\n",
    "        layers = y5\n",
    "\n",
    "        sym_autoencoder = Model([input_img,gf1,gf2,gf3,gf4],layers)\n",
    "        sym_autoencoder.compile(optimizer='sgd', loss = 'mean_squared_error', metrics = ['accuracy','mean_squared_error'])\n",
    "        print \"Model created\"\n",
    "    else:\n",
    "        print \"Saved model loaded\"\n",
    "    print sym_autoencoder.summary()\n",
    "    return sym_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, None, None, 64 3136        input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_9 (InputLayer)             (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)                (None, None, None, 64 0           conv2d_11[0][0]                  \n",
      "                                                                   input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)   (None, None, None, 64 0           lambda_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, None, None, 64 65600       max_pooling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "input_10 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)               (None, None, None, 64 0           conv2d_12[0][0]                  \n",
      "                                                                   input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)   (None, None, None, 64 0           lambda_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, None, None, 12 131200      max_pooling2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)   (None, None, None, 12 0           conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, None, None, 25 524544      max_pooling2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D)  (None, None, None, 25 0           conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, None, None, 51 2097664     max_pooling2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "input_12 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)   (None, None, None, 51 0           conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)               (None, None, None, 25 0           conv2d_14[0][0]                  \n",
      "                                                                   input_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTransp (None, None, None, 25 2097408     up_sampling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)               (None, None, None, 25 0           conv2d_14[0][0]                  \n",
      "                                                                   lambda_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, None, None, 25 0           conv2d_transpose_6[0][0]         \n",
      "                                                                   lambda_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_11 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)   (None, None, None, 25 0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)               (None, None, None, 12 0           conv2d_13[0][0]                  \n",
      "                                                                   input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTransp (None, None, None, 12 524416      up_sampling2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)               (None, None, None, 12 0           conv2d_13[0][0]                  \n",
      "                                                                   lambda_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, None, None, 12 0           conv2d_transpose_7[0][0]         \n",
      "                                                                   lambda_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)   (None, None, None, 12 0           add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTransp (None, None, None, 64 131136      up_sampling2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)               (None, None, None, 64 0           conv2d_12[0][0]                  \n",
      "                                                                   lambda_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, None, None, 64 0           conv2d_transpose_8[0][0]         \n",
      "                                                                   lambda_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling2D)  (None, None, None, 64 0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)               (None, None, None, 64 0           conv2d_11[0][0]                  \n",
      "                                                                   lambda_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, None, None, 64 0           up_sampling2d_10[0][0]           \n",
      "                                                                   lambda_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTransp (None, None, None, 64 65600       add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTrans (None, None, None, 3) 3075        conv2d_transpose_9[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 5,643,779\n",
      "Trainable params: 5,643,779\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sym_autoencoder = get_cnn_dsc_architecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint1 = ModelCheckpoint('./models/gated_cnn_autoencoder.hdf5',monitor = 'loss', verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.6165 - mean_squared_error: 0.0117Epoch 00000: loss improved from inf to 0.01172, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0117 - acc: 0.6166 - mean_squared_error: 0.0117 - val_loss: 0.0051 - val_acc: 0.6753 - val_mean_squared_error: 0.0051\n",
      "Epoch 2/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.6962 - mean_squared_error: 0.0044Epoch 00001: loss improved from 0.01172 to 0.00437, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 480s - loss: 0.0044 - acc: 0.6963 - mean_squared_error: 0.0044 - val_loss: 0.0040 - val_acc: 0.7088 - val_mean_squared_error: 0.0040\n",
      "Epoch 3/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.7172 - mean_squared_error: 0.0037Epoch 00002: loss improved from 0.00437 to 0.00375, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 480s - loss: 0.0037 - acc: 0.7172 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_acc: 0.7213 - val_mean_squared_error: 0.0036\n",
      "Epoch 4/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.7267 - mean_squared_error: 0.0035Epoch 00003: loss improved from 0.00375 to 0.00346, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 480s - loss: 0.0035 - acc: 0.7267 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_acc: 0.7293 - val_mean_squared_error: 0.0034\n",
      "Epoch 5/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.7329 - mean_squared_error: 0.0033Epoch 00004: loss improved from 0.00346 to 0.00329, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 480s - loss: 0.0033 - acc: 0.7329 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_acc: 0.7341 - val_mean_squared_error: 0.0032\n",
      "Epoch 6/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.7375 - mean_squared_error: 0.0032Epoch 00005: loss improved from 0.00329 to 0.00317, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 480s - loss: 0.0032 - acc: 0.7375 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_acc: 0.7386 - val_mean_squared_error: 0.0031\n",
      "Epoch 7/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.7411 - mean_squared_error: 0.0031Epoch 00006: loss improved from 0.00317 to 0.00308, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 480s - loss: 0.0031 - acc: 0.7411 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_acc: 0.7437 - val_mean_squared_error: 0.0031\n",
      "Epoch 8/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.7441 - mean_squared_error: 0.0030Epoch 00007: loss improved from 0.00308 to 0.00301, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 480s - loss: 0.0030 - acc: 0.7441 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_acc: 0.7447 - val_mean_squared_error: 0.0030\n",
      "Epoch 9/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.7465 - mean_squared_error: 0.0030Epoch 00008: loss improved from 0.00301 to 0.00296, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 480s - loss: 0.0030 - acc: 0.7465 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_acc: 0.7483 - val_mean_squared_error: 0.0029\n",
      "Epoch 10/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.7486 - mean_squared_error: 0.0029Epoch 00009: loss improved from 0.00296 to 0.00291, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 480s - loss: 0.0029 - acc: 0.7486 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_acc: 0.7499 - val_mean_squared_error: 0.0029\n",
      "Epoch 11/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.7503 - mean_squared_error: 0.0029Epoch 00010: loss improved from 0.00291 to 0.00287, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 483s - loss: 0.0029 - acc: 0.7504 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_acc: 0.7498 - val_mean_squared_error: 0.0029\n",
      "Epoch 12/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.7520 - mean_squared_error: 0.0028Epoch 00011: loss improved from 0.00287 to 0.00284, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 483s - loss: 0.0028 - acc: 0.7520 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_acc: 0.7527 - val_mean_squared_error: 0.0028\n",
      "Epoch 13/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.7533 - mean_squared_error: 0.0028Epoch 00012: loss improved from 0.00284 to 0.00281, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 483s - loss: 0.0028 - acc: 0.7533 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_acc: 0.7551 - val_mean_squared_error: 0.0028\n",
      "Epoch 14/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.7546 - mean_squared_error: 0.0028Epoch 00013: loss improved from 0.00281 to 0.00278, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 483s - loss: 0.0028 - acc: 0.7546 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_acc: 0.7547 - val_mean_squared_error: 0.0028\n",
      "Epoch 15/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.7557 - mean_squared_error: 0.0028Epoch 00014: loss improved from 0.00278 to 0.00276, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 483s - loss: 0.0028 - acc: 0.7557 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_acc: 0.7539 - val_mean_squared_error: 0.0028\n",
      "Epoch 16/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.7566 - mean_squared_error: 0.0027Epoch 00015: loss improved from 0.00276 to 0.00274, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 483s - loss: 0.0027 - acc: 0.7566 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_acc: 0.7549 - val_mean_squared_error: 0.0027\n",
      "Epoch 17/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.7575 - mean_squared_error: 0.0027Epoch 00016: loss improved from 0.00274 to 0.00272, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 483s - loss: 0.0027 - acc: 0.7575 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_acc: 0.7585 - val_mean_squared_error: 0.0027\n",
      "Epoch 18/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.7584 - mean_squared_error: 0.0027Epoch 00017: loss improved from 0.00272 to 0.00270, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 483s - loss: 0.0027 - acc: 0.7583 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_acc: 0.7570 - val_mean_squared_error: 0.0027\n",
      "Epoch 19/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.7591 - mean_squared_error: 0.0027Epoch 00018: loss improved from 0.00270 to 0.00268, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 483s - loss: 0.0027 - acc: 0.7591 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_acc: 0.7576 - val_mean_squared_error: 0.0027\n",
      "Epoch 20/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.7597 - mean_squared_error: 0.0027Epoch 00019: loss improved from 0.00268 to 0.00267, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0027 - acc: 0.7598 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_acc: 0.7584 - val_mean_squared_error: 0.0027\n",
      "Epoch 21/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.7604 - mean_squared_error: 0.0027Epoch 00020: loss improved from 0.00267 to 0.00265, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0027 - acc: 0.7604 - mean_squared_error: 0.0027 - val_loss: 0.0026 - val_acc: 0.7596 - val_mean_squared_error: 0.0026\n",
      "Epoch 22/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.7609 - mean_squared_error: 0.0026Epoch 00021: loss improved from 0.00265 to 0.00264, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0026 - acc: 0.7609 - mean_squared_error: 0.0026 - val_loss: 0.0026 - val_acc: 0.7580 - val_mean_squared_error: 0.0026\n",
      "Epoch 23/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.7615 - mean_squared_error: 0.0026Epoch 00022: loss improved from 0.00264 to 0.00262, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0026 - acc: 0.7615 - mean_squared_error: 0.0026 - val_loss: 0.0026 - val_acc: 0.7595 - val_mean_squared_error: 0.0026\n",
      "Epoch 24/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.7620 - mean_squared_error: 0.0026Epoch 00023: loss improved from 0.00262 to 0.00261, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0026 - acc: 0.7620 - mean_squared_error: 0.0026 - val_loss: 0.0026 - val_acc: 0.7626 - val_mean_squared_error: 0.0026\n",
      "Epoch 25/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.7625 - mean_squared_error: 0.0026Epoch 00024: loss improved from 0.00261 to 0.00260, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0026 - acc: 0.7625 - mean_squared_error: 0.0026 - val_loss: 0.0026 - val_acc: 0.7620 - val_mean_squared_error: 0.0026\n",
      "Epoch 26/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.7629 - mean_squared_error: 0.0026Epoch 00025: loss improved from 0.00260 to 0.00259, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0026 - acc: 0.7629 - mean_squared_error: 0.0026 - val_loss: 0.0026 - val_acc: 0.7625 - val_mean_squared_error: 0.0026\n",
      "Epoch 27/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.7633 - mean_squared_error: 0.0026Epoch 00026: loss improved from 0.00259 to 0.00258, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0026 - acc: 0.7633 - mean_squared_error: 0.0026 - val_loss: 0.0026 - val_acc: 0.7636 - val_mean_squared_error: 0.0026\n",
      "Epoch 28/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.7636 - mean_squared_error: 0.0026Epoch 00027: loss improved from 0.00258 to 0.00257, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0026 - acc: 0.7636 - mean_squared_error: 0.0026 - val_loss: 0.0026 - val_acc: 0.7621 - val_mean_squared_error: 0.0026\n",
      "Epoch 29/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.7640 - mean_squared_error: 0.0026Epoch 00028: loss improved from 0.00257 to 0.00256, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0026 - acc: 0.7640 - mean_squared_error: 0.0026 - val_loss: 0.0026 - val_acc: 0.7645 - val_mean_squared_error: 0.0026\n",
      "Epoch 30/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.7643 - mean_squared_error: 0.0026Epoch 00029: loss improved from 0.00256 to 0.00255, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0026 - acc: 0.7643 - mean_squared_error: 0.0026 - val_loss: 0.0026 - val_acc: 0.7672 - val_mean_squared_error: 0.0026\n",
      "Epoch 31/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7647 - mean_squared_error: 0.0025Epoch 00030: loss improved from 0.00255 to 0.00255, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7647 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7633 - val_mean_squared_error: 0.0025\n",
      "Epoch 32/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7650 - mean_squared_error: 0.0025Epoch 00031: loss improved from 0.00255 to 0.00254, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7650 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7629 - val_mean_squared_error: 0.0025\n",
      "Epoch 33/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7653 - mean_squared_error: 0.0025Epoch 00032: loss improved from 0.00254 to 0.00253, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7653 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7647 - val_mean_squared_error: 0.0025\n",
      "Epoch 34/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7655 - mean_squared_error: 0.0025Epoch 00033: loss improved from 0.00253 to 0.00252, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7655 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7635 - val_mean_squared_error: 0.0025\n",
      "Epoch 35/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7658 - mean_squared_error: 0.0025Epoch 00034: loss improved from 0.00252 to 0.00252, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7658 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7636 - val_mean_squared_error: 0.0025\n",
      "Epoch 36/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7661 - mean_squared_error: 0.0025Epoch 00035: loss improved from 0.00252 to 0.00251, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7661 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7649 - val_mean_squared_error: 0.0025\n",
      "Epoch 37/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7663 - mean_squared_error: 0.0025Epoch 00036: loss improved from 0.00251 to 0.00251, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7663 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7651 - val_mean_squared_error: 0.0025\n",
      "Epoch 38/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7665 - mean_squared_error: 0.0025Epoch 00037: loss improved from 0.00251 to 0.00250, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7665 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7673 - val_mean_squared_error: 0.0025\n",
      "Epoch 39/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7667 - mean_squared_error: 0.0025Epoch 00038: loss improved from 0.00250 to 0.00249, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7667 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7646 - val_mean_squared_error: 0.0025\n",
      "Epoch 40/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7669 - mean_squared_error: 0.0025Epoch 00039: loss improved from 0.00249 to 0.00249, saving model to ./models/gated_cnn_autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7669 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7661 - val_mean_squared_error: 0.0025\n",
      "Epoch 41/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7671 - mean_squared_error: 0.0025Epoch 00040: loss improved from 0.00249 to 0.00248, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7671 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7654 - val_mean_squared_error: 0.0025\n",
      "Epoch 42/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7673 - mean_squared_error: 0.0025Epoch 00041: loss improved from 0.00248 to 0.00248, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7673 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7655 - val_mean_squared_error: 0.0025\n",
      "Epoch 43/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7675 - mean_squared_error: 0.0025Epoch 00042: loss improved from 0.00248 to 0.00247, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7675 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7632 - val_mean_squared_error: 0.0025\n",
      "Epoch 44/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7676 - mean_squared_error: 0.0025Epoch 00043: loss improved from 0.00247 to 0.00247, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7676 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7684 - val_mean_squared_error: 0.0025\n",
      "Epoch 45/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7678 - mean_squared_error: 0.0025Epoch 00044: loss improved from 0.00247 to 0.00247, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7678 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7663 - val_mean_squared_error: 0.0025\n",
      "Epoch 46/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7680 - mean_squared_error: 0.0025Epoch 00045: loss improved from 0.00247 to 0.00246, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7680 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7677 - val_mean_squared_error: 0.0025\n",
      "Epoch 47/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7682 - mean_squared_error: 0.0025Epoch 00046: loss improved from 0.00246 to 0.00246, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7682 - mean_squared_error: 0.0025 - val_loss: 0.0025 - val_acc: 0.7669 - val_mean_squared_error: 0.0025\n",
      "Epoch 48/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.7683 - mean_squared_error: 0.0025Epoch 00047: loss improved from 0.00246 to 0.00245, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0025 - acc: 0.7683 - mean_squared_error: 0.0025 - val_loss: 0.0024 - val_acc: 0.7669 - val_mean_squared_error: 0.0024\n",
      "Epoch 49/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7684 - mean_squared_error: 0.0024Epoch 00048: loss improved from 0.00245 to 0.00245, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7684 - mean_squared_error: 0.0024 - val_loss: 0.0025 - val_acc: 0.7657 - val_mean_squared_error: 0.0025\n",
      "Epoch 50/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7686 - mean_squared_error: 0.0024Epoch 00049: loss improved from 0.00245 to 0.00245, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7685 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7648 - val_mean_squared_error: 0.0024\n",
      "Epoch 51/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7687 - mean_squared_error: 0.0024Epoch 00050: loss improved from 0.00245 to 0.00244, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7687 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7670 - val_mean_squared_error: 0.0024\n",
      "Epoch 52/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7688 - mean_squared_error: 0.0024Epoch 00051: loss improved from 0.00244 to 0.00244, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7688 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7684 - val_mean_squared_error: 0.0024\n",
      "Epoch 53/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7689 - mean_squared_error: 0.0024Epoch 00052: loss improved from 0.00244 to 0.00244, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7689 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7700 - val_mean_squared_error: 0.0024\n",
      "Epoch 54/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7691 - mean_squared_error: 0.0024Epoch 00053: loss improved from 0.00244 to 0.00243, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7691 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7711 - val_mean_squared_error: 0.0024\n",
      "Epoch 55/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7692 - mean_squared_error: 0.0024Epoch 00054: loss improved from 0.00243 to 0.00243, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7692 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7663 - val_mean_squared_error: 0.0024\n",
      "Epoch 56/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7694 - mean_squared_error: 0.0024Epoch 00055: loss improved from 0.00243 to 0.00243, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7694 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7706 - val_mean_squared_error: 0.0024\n",
      "Epoch 57/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7694 - mean_squared_error: 0.0024Epoch 00056: loss improved from 0.00243 to 0.00242, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7695 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7669 - val_mean_squared_error: 0.0024\n",
      "Epoch 58/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7696 - mean_squared_error: 0.0024Epoch 00057: loss improved from 0.00242 to 0.00242, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7696 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7702 - val_mean_squared_error: 0.0024\n",
      "Epoch 59/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7696 - mean_squared_error: 0.0024Epoch 00058: loss improved from 0.00242 to 0.00242, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7697 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7682 - val_mean_squared_error: 0.0024\n",
      "Epoch 60/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7698 - mean_squared_error: 0.0024Epoch 00059: loss improved from 0.00242 to 0.00241, saving model to ./models/gated_cnn_autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7698 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7673 - val_mean_squared_error: 0.0024\n",
      "Epoch 61/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7699 - mean_squared_error: 0.0024Epoch 00060: loss improved from 0.00241 to 0.00241, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7699 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7667 - val_mean_squared_error: 0.0024\n",
      "Epoch 62/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7700 - mean_squared_error: 0.0024Epoch 00061: loss improved from 0.00241 to 0.00241, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7700 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7703 - val_mean_squared_error: 0.0024\n",
      "Epoch 63/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7700 - mean_squared_error: 0.0024Epoch 00062: loss improved from 0.00241 to 0.00241, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7701 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7697 - val_mean_squared_error: 0.0024\n",
      "Epoch 64/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7702 - mean_squared_error: 0.0024Epoch 00063: loss improved from 0.00241 to 0.00240, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7702 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7682 - val_mean_squared_error: 0.0024\n",
      "Epoch 65/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7704 - mean_squared_error: 0.0024Epoch 00064: loss improved from 0.00240 to 0.00240, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7703 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7673 - val_mean_squared_error: 0.0024\n",
      "Epoch 66/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7704 - mean_squared_error: 0.0024Epoch 00065: loss improved from 0.00240 to 0.00240, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7704 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7732 - val_mean_squared_error: 0.0024\n",
      "Epoch 67/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7705 - mean_squared_error: 0.0024Epoch 00066: loss improved from 0.00240 to 0.00240, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7705 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7708 - val_mean_squared_error: 0.0024\n",
      "Epoch 68/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7705 - mean_squared_error: 0.0024Epoch 00067: loss improved from 0.00240 to 0.00239, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7706 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7682 - val_mean_squared_error: 0.0024\n",
      "Epoch 69/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7706 - mean_squared_error: 0.0024Epoch 00068: loss improved from 0.00239 to 0.00239, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7706 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7614 - val_mean_squared_error: 0.0024\n",
      "Epoch 70/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7707 - mean_squared_error: 0.0024Epoch 00069: loss improved from 0.00239 to 0.00239, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7707 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7695 - val_mean_squared_error: 0.0024\n",
      "Epoch 71/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7708 - mean_squared_error: 0.0024Epoch 00070: loss improved from 0.00239 to 0.00238, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7708 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7666 - val_mean_squared_error: 0.0024\n",
      "Epoch 72/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7709 - mean_squared_error: 0.0024Epoch 00071: loss improved from 0.00238 to 0.00238, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7709 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7681 - val_mean_squared_error: 0.0024\n",
      "Epoch 73/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7710 - mean_squared_error: 0.0024Epoch 00072: loss improved from 0.00238 to 0.00238, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7710 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7669 - val_mean_squared_error: 0.0024\n",
      "Epoch 74/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7711 - mean_squared_error: 0.0024Epoch 00073: loss improved from 0.00238 to 0.00238, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7710 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7721 - val_mean_squared_error: 0.0024\n",
      "Epoch 75/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7712 - mean_squared_error: 0.0024Epoch 00074: loss improved from 0.00238 to 0.00238, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7711 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7717 - val_mean_squared_error: 0.0024\n",
      "Epoch 76/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7712 - mean_squared_error: 0.0024Epoch 00075: loss improved from 0.00238 to 0.00237, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 481s - loss: 0.0024 - acc: 0.7712 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7728 - val_mean_squared_error: 0.0024\n",
      "Epoch 77/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7713 - mean_squared_error: 0.0024Epoch 00076: loss improved from 0.00237 to 0.00237, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7712 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7690 - val_mean_squared_error: 0.0024\n",
      "Epoch 78/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7713 - mean_squared_error: 0.0024Epoch 00077: loss improved from 0.00237 to 0.00237, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7713 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7717 - val_mean_squared_error: 0.0024\n",
      "Epoch 79/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7714 - mean_squared_error: 0.0024Epoch 00078: loss improved from 0.00237 to 0.00237, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7714 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7724 - val_mean_squared_error: 0.0024\n",
      "Epoch 80/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7715 - mean_squared_error: 0.0024Epoch 00079: loss improved from 0.00237 to 0.00237, saving model to ./models/gated_cnn_autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7715 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7711 - val_mean_squared_error: 0.0024\n",
      "Epoch 81/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7716 - mean_squared_error: 0.0024Epoch 00080: loss improved from 0.00237 to 0.00237, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7716 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7702 - val_mean_squared_error: 0.0024\n",
      "Epoch 82/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7717 - mean_squared_error: 0.0024Epoch 00081: loss improved from 0.00237 to 0.00236, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7717 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7709 - val_mean_squared_error: 0.0024\n",
      "Epoch 83/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7717 - mean_squared_error: 0.0024Epoch 00082: loss improved from 0.00236 to 0.00236, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7717 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7700 - val_mean_squared_error: 0.0024\n",
      "Epoch 84/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7718 - mean_squared_error: 0.0024Epoch 00083: loss improved from 0.00236 to 0.00236, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7718 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7733 - val_mean_squared_error: 0.0024\n",
      "Epoch 85/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7718 - mean_squared_error: 0.0024Epoch 00084: loss improved from 0.00236 to 0.00236, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7718 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7689 - val_mean_squared_error: 0.0024\n",
      "Epoch 86/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7718 - mean_squared_error: 0.0024Epoch 00085: loss improved from 0.00236 to 0.00236, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7718 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7738 - val_mean_squared_error: 0.0024\n",
      "Epoch 87/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7719 - mean_squared_error: 0.0024Epoch 00086: loss improved from 0.00236 to 0.00235, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7719 - mean_squared_error: 0.0024 - val_loss: 0.0023 - val_acc: 0.7727 - val_mean_squared_error: 0.0023\n",
      "Epoch 88/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7720 - mean_squared_error: 0.0024Epoch 00087: loss improved from 0.00235 to 0.00235, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7720 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_acc: 0.7703 - val_mean_squared_error: 0.0024\n",
      "Epoch 89/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.7720 - mean_squared_error: 0.0024Epoch 00088: loss improved from 0.00235 to 0.00235, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0024 - acc: 0.7720 - mean_squared_error: 0.0024 - val_loss: 0.0023 - val_acc: 0.7706 - val_mean_squared_error: 0.0023\n",
      "Epoch 90/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7721 - mean_squared_error: 0.0023Epoch 00089: loss improved from 0.00235 to 0.00235, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7721 - mean_squared_error: 0.0023 - val_loss: 0.0024 - val_acc: 0.7666 - val_mean_squared_error: 0.0024\n",
      "Epoch 91/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7721 - mean_squared_error: 0.0023Epoch 00090: loss improved from 0.00235 to 0.00235, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7722 - mean_squared_error: 0.0023 - val_loss: 0.0024 - val_acc: 0.7708 - val_mean_squared_error: 0.0024\n",
      "Epoch 92/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7723 - mean_squared_error: 0.0023Epoch 00091: loss improved from 0.00235 to 0.00235, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7723 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7708 - val_mean_squared_error: 0.0023\n",
      "Epoch 93/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7723 - mean_squared_error: 0.0023Epoch 00092: loss improved from 0.00235 to 0.00234, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7723 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7696 - val_mean_squared_error: 0.0023\n",
      "Epoch 94/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7723 - mean_squared_error: 0.0023Epoch 00093: loss improved from 0.00234 to 0.00234, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7724 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7697 - val_mean_squared_error: 0.0023\n",
      "Epoch 95/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7724 - mean_squared_error: 0.0023Epoch 00094: loss improved from 0.00234 to 0.00234, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7724 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7702 - val_mean_squared_error: 0.0023\n",
      "Epoch 96/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7725 - mean_squared_error: 0.0023Epoch 00095: loss improved from 0.00234 to 0.00234, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7725 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7688 - val_mean_squared_error: 0.0023\n",
      "Epoch 97/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7725 - mean_squared_error: 0.0023Epoch 00096: loss improved from 0.00234 to 0.00234, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7725 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7731 - val_mean_squared_error: 0.0023\n",
      "Epoch 98/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7726 - mean_squared_error: 0.0023Epoch 00097: loss improved from 0.00234 to 0.00233, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7726 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7756 - val_mean_squared_error: 0.0023\n",
      "Epoch 99/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7727 - mean_squared_error: 0.0023Epoch 00098: loss improved from 0.00233 to 0.00233, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7726 - mean_squared_error: 0.0023 - val_loss: 0.0024 - val_acc: 0.7729 - val_mean_squared_error: 0.0024\n",
      "Epoch 100/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7727 - mean_squared_error: 0.0023Epoch 00099: loss improved from 0.00233 to 0.00233, saving model to ./models/gated_cnn_autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7727 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7702 - val_mean_squared_error: 0.0023\n",
      "Epoch 101/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7728 - mean_squared_error: 0.0023Epoch 00100: loss improved from 0.00233 to 0.00233, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7728 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7737 - val_mean_squared_error: 0.0023\n",
      "Epoch 102/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7728 - mean_squared_error: 0.0023Epoch 00101: loss improved from 0.00233 to 0.00233, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7728 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7711 - val_mean_squared_error: 0.0023\n",
      "Epoch 103/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7729 - mean_squared_error: 0.0023Epoch 00102: loss improved from 0.00233 to 0.00233, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7729 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7706 - val_mean_squared_error: 0.0023\n",
      "Epoch 104/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7729 - mean_squared_error: 0.0023Epoch 00103: loss improved from 0.00233 to 0.00232, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7729 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7753 - val_mean_squared_error: 0.0023\n",
      "Epoch 105/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7730 - mean_squared_error: 0.0023Epoch 00104: loss improved from 0.00232 to 0.00232, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7730 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7715 - val_mean_squared_error: 0.0023\n",
      "Epoch 106/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7730 - mean_squared_error: 0.0023Epoch 00105: loss improved from 0.00232 to 0.00232, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7730 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7715 - val_mean_squared_error: 0.0023\n",
      "Epoch 107/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7730 - mean_squared_error: 0.0023Epoch 00106: loss improved from 0.00232 to 0.00232, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7730 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7692 - val_mean_squared_error: 0.0023\n",
      "Epoch 108/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7731 - mean_squared_error: 0.0023Epoch 00107: loss improved from 0.00232 to 0.00232, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7731 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7718 - val_mean_squared_error: 0.0023\n",
      "Epoch 109/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7731 - mean_squared_error: 0.0023Epoch 00108: loss improved from 0.00232 to 0.00232, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7731 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7747 - val_mean_squared_error: 0.0023\n",
      "Epoch 110/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7732 - mean_squared_error: 0.0023Epoch 00109: loss improved from 0.00232 to 0.00232, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7732 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7695 - val_mean_squared_error: 0.0023\n",
      "Epoch 111/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7733 - mean_squared_error: 0.0023Epoch 00110: loss improved from 0.00232 to 0.00231, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7733 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7760 - val_mean_squared_error: 0.0023\n",
      "Epoch 112/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7732 - mean_squared_error: 0.0023Epoch 00111: loss improved from 0.00231 to 0.00231, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7733 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7716 - val_mean_squared_error: 0.0023\n",
      "Epoch 113/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7734 - mean_squared_error: 0.0023Epoch 00112: loss did not improve\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7734 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7693 - val_mean_squared_error: 0.0023\n",
      "Epoch 114/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7733 - mean_squared_error: 0.0023Epoch 00113: loss improved from 0.00231 to 0.00231, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7734 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7736 - val_mean_squared_error: 0.0023\n",
      "Epoch 115/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7735 - mean_squared_error: 0.0023Epoch 00114: loss improved from 0.00231 to 0.00231, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7734 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7709 - val_mean_squared_error: 0.0023\n",
      "Epoch 116/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7734 - mean_squared_error: 0.0023Epoch 00115: loss improved from 0.00231 to 0.00231, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7735 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7753 - val_mean_squared_error: 0.0023\n",
      "Epoch 117/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7735 - mean_squared_error: 0.0023Epoch 00116: loss improved from 0.00231 to 0.00230, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7735 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7720 - val_mean_squared_error: 0.0023\n",
      "Epoch 118/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7735 - mean_squared_error: 0.0023Epoch 00117: loss did not improve\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7735 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7746 - val_mean_squared_error: 0.0023\n",
      "Epoch 119/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7735 - mean_squared_error: 0.0023Epoch 00118: loss improved from 0.00230 to 0.00230, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7735 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7704 - val_mean_squared_error: 0.0023\n",
      "Epoch 120/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7737 - mean_squared_error: 0.0023Epoch 00119: loss improved from 0.00230 to 0.00230, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 486s - loss: 0.0023 - acc: 0.7736 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7691 - val_mean_squared_error: 0.0023\n",
      "Epoch 121/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7737 - mean_squared_error: 0.0023Epoch 00120: loss improved from 0.00230 to 0.00230, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7737 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7754 - val_mean_squared_error: 0.0023\n",
      "Epoch 122/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7738 - mean_squared_error: 0.0023Epoch 00121: loss improved from 0.00230 to 0.00230, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7738 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7683 - val_mean_squared_error: 0.0023\n",
      "Epoch 123/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7738 - mean_squared_error: 0.0023Epoch 00122: loss improved from 0.00230 to 0.00230, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7737 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7727 - val_mean_squared_error: 0.0023\n",
      "Epoch 124/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7737 - mean_squared_error: 0.0023Epoch 00123: loss improved from 0.00230 to 0.00230, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7737 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7680 - val_mean_squared_error: 0.0023\n",
      "Epoch 125/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7739 - mean_squared_error: 0.0023Epoch 00124: loss improved from 0.00230 to 0.00229, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7738 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7791 - val_mean_squared_error: 0.0023\n",
      "Epoch 126/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7739 - mean_squared_error: 0.0023Epoch 00125: loss improved from 0.00229 to 0.00229, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7739 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7733 - val_mean_squared_error: 0.0023\n",
      "Epoch 127/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7739 - mean_squared_error: 0.0023Epoch 00126: loss improved from 0.00229 to 0.00229, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7739 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7713 - val_mean_squared_error: 0.0023\n",
      "Epoch 128/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7739 - mean_squared_error: 0.0023Epoch 00127: loss did not improve\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7739 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7728 - val_mean_squared_error: 0.0023\n",
      "Epoch 129/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7740 - mean_squared_error: 0.0023Epoch 00128: loss improved from 0.00229 to 0.00229, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7740 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7684 - val_mean_squared_error: 0.0023\n",
      "Epoch 130/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7741 - mean_squared_error: 0.0023Epoch 00129: loss improved from 0.00229 to 0.00229, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7741 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7717 - val_mean_squared_error: 0.0023\n",
      "Epoch 131/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7741 - mean_squared_error: 0.0023Epoch 00130: loss improved from 0.00229 to 0.00229, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7741 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7685 - val_mean_squared_error: 0.0023\n",
      "Epoch 132/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7741 - mean_squared_error: 0.0023Epoch 00131: loss improved from 0.00229 to 0.00228, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7741 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7698 - val_mean_squared_error: 0.0023\n",
      "Epoch 133/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7742 - mean_squared_error: 0.0023Epoch 00132: loss improved from 0.00228 to 0.00228, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7742 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7730 - val_mean_squared_error: 0.0023\n",
      "Epoch 134/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7742 - mean_squared_error: 0.0023Epoch 00133: loss improved from 0.00228 to 0.00228, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7742 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7734 - val_mean_squared_error: 0.0023\n",
      "Epoch 135/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7742 - mean_squared_error: 0.0023Epoch 00134: loss improved from 0.00228 to 0.00228, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7742 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7721 - val_mean_squared_error: 0.0023\n",
      "Epoch 136/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7743 - mean_squared_error: 0.0023Epoch 00135: loss improved from 0.00228 to 0.00228, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7743 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7718 - val_mean_squared_error: 0.0023\n",
      "Epoch 137/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7743 - mean_squared_error: 0.0023Epoch 00136: loss improved from 0.00228 to 0.00228, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7743 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7717 - val_mean_squared_error: 0.0023\n",
      "Epoch 138/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7744 - mean_squared_error: 0.0023Epoch 00137: loss improved from 0.00228 to 0.00228, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7744 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7762 - val_mean_squared_error: 0.0023\n",
      "Epoch 139/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7744 - mean_squared_error: 0.0023Epoch 00138: loss improved from 0.00228 to 0.00227, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7744 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7755 - val_mean_squared_error: 0.0023\n",
      "Epoch 140/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7746 - mean_squared_error: 0.0023Epoch 00139: loss improved from 0.00227 to 0.00227, saving model to ./models/gated_cnn_autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7746 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7708 - val_mean_squared_error: 0.0023\n",
      "Epoch 141/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7745 - mean_squared_error: 0.0023Epoch 00140: loss improved from 0.00227 to 0.00227, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7745 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7717 - val_mean_squared_error: 0.0023\n",
      "Epoch 142/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7746 - mean_squared_error: 0.0023Epoch 00141: loss improved from 0.00227 to 0.00227, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7745 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7738 - val_mean_squared_error: 0.0023\n",
      "Epoch 143/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7745 - mean_squared_error: 0.0023Epoch 00142: loss improved from 0.00227 to 0.00227, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7745 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7752 - val_mean_squared_error: 0.0023\n",
      "Epoch 144/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7746 - mean_squared_error: 0.0023Epoch 00143: loss improved from 0.00227 to 0.00227, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7746 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7745 - val_mean_squared_error: 0.0023\n",
      "Epoch 145/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7747 - mean_squared_error: 0.0023Epoch 00144: loss improved from 0.00227 to 0.00227, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7747 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7738 - val_mean_squared_error: 0.0023\n",
      "Epoch 146/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7747 - mean_squared_error: 0.0023Epoch 00145: loss improved from 0.00227 to 0.00227, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7747 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7720 - val_mean_squared_error: 0.0023\n",
      "Epoch 147/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7747 - mean_squared_error: 0.0023Epoch 00146: loss improved from 0.00227 to 0.00226, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7747 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7699 - val_mean_squared_error: 0.0023\n",
      "Epoch 148/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7748 - mean_squared_error: 0.0023Epoch 00147: loss improved from 0.00226 to 0.00226, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7748 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7713 - val_mean_squared_error: 0.0023\n",
      "Epoch 149/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7748 - mean_squared_error: 0.0023Epoch 00148: loss improved from 0.00226 to 0.00226, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7748 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7773 - val_mean_squared_error: 0.0023\n",
      "Epoch 150/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7749 - mean_squared_error: 0.0023Epoch 00149: loss improved from 0.00226 to 0.00226, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7749 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7795 - val_mean_squared_error: 0.0023\n",
      "Epoch 151/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7749 - mean_squared_error: 0.0023Epoch 00150: loss improved from 0.00226 to 0.00226, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7749 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7681 - val_mean_squared_error: 0.0023\n",
      "Epoch 152/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7749 - mean_squared_error: 0.0023Epoch 00151: loss improved from 0.00226 to 0.00226, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7749 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7757 - val_mean_squared_error: 0.0023\n",
      "Epoch 153/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7750 - mean_squared_error: 0.0023Epoch 00152: loss improved from 0.00226 to 0.00226, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7750 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7761 - val_mean_squared_error: 0.0023\n",
      "Epoch 154/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7750 - mean_squared_error: 0.0023Epoch 00153: loss improved from 0.00226 to 0.00225, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7750 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7790 - val_mean_squared_error: 0.0023\n",
      "Epoch 155/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7750 - mean_squared_error: 0.0023Epoch 00154: loss improved from 0.00225 to 0.00225, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7750 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_acc: 0.7727 - val_mean_squared_error: 0.0023\n",
      "Epoch 156/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.7751 - mean_squared_error: 0.0023Epoch 00155: loss improved from 0.00225 to 0.00225, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0023 - acc: 0.7751 - mean_squared_error: 0.0023 - val_loss: 0.0022 - val_acc: 0.7739 - val_mean_squared_error: 0.0022\n",
      "Epoch 157/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.7752 - mean_squared_error: 0.0022Epoch 00156: loss improved from 0.00225 to 0.00225, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0022 - acc: 0.7751 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_acc: 0.7734 - val_mean_squared_error: 0.0022\n",
      "Epoch 158/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.7751 - mean_squared_error: 0.0022Epoch 00157: loss improved from 0.00225 to 0.00225, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0022 - acc: 0.7751 - mean_squared_error: 0.0022 - val_loss: 0.0023 - val_acc: 0.7698 - val_mean_squared_error: 0.0023\n",
      "Epoch 159/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.7752 - mean_squared_error: 0.0022Epoch 00158: loss improved from 0.00225 to 0.00225, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0022 - acc: 0.7752 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_acc: 0.7718 - val_mean_squared_error: 0.0022\n",
      "Epoch 160/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.7752 - mean_squared_error: 0.0022Epoch 00159: loss improved from 0.00225 to 0.00225, saving model to ./models/gated_cnn_autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 482s - loss: 0.0022 - acc: 0.7752 - mean_squared_error: 0.0022 - val_loss: 0.0023 - val_acc: 0.7801 - val_mean_squared_error: 0.0023\n",
      "Epoch 161/4000\n",
      "39980/40000 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.7753 - mean_squared_error: 0.0022Epoch 00160: loss improved from 0.00225 to 0.00224, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "40000/40000 [==============================] - 482s - loss: 0.0022 - acc: 0.7753 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_acc: 0.7717 - val_mean_squared_error: 0.0022\n",
      "Epoch 162/4000\n",
      " 9740/40000 [======>.......................] - ETA: 338s - loss: 0.0022 - acc: 0.7766 - mean_squared_error: 0.0022"
     ]
    }
   ],
   "source": [
    "sym_autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=4000,\n",
    "                batch_size=20,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/gated_cnn_autoencoder', \n",
    "                                       histogram_freq=0,\n",
    "                                       write_graph=True),model_checkpoint1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 32, 32, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sym_autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-dec5870d8faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_model_as_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msym_autoencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CNNDSC_CIFAR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sym_autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "save_model_as_json(sym_autoencoder,'CNNDSC_CIFAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting images to test\n",
    "def get_testing_images(filePath):\n",
    "    test_images = read_dataset(filePath)\n",
    "    test_images = np.array(test_images)\n",
    "    test_images = test_images.astype('float32')/255.\n",
    "    test_images = np.reshape(test_images, (test_images.shape[0],32,32,1))\n",
    "    noisy_test_images = add_noise(test_images)\n",
    "    print (noisy_test_images.shape)\n",
    "    return (test_images,noisy_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "test_images = readcifar('data/cifar-10-batches-py/test_batch')\n",
    "test_images = preprocess(test_images)\n",
    "print(test_images.shape)\n",
    "noisy_test_images = add_noise(test_images)\n",
    "noisy_test_images = noisy_test_images/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sym_autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ed28be106bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Denoising using CNN symmetric Autoencoders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout_sym_autoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msym_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_sym_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sym_autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "#Denoising using CNN symmetric Autoencoders\n",
    "out_sym_autoencoder = sym_autoencoder.predict(noisy_test_images,verbose=1)\n",
    "print (out_sym_autoencoder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s(10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "#Denoising using Autoencoders\n",
    "out_autoencoder = autoencoder.predict(noisy_test_images,verbose=1).astype('float64')\n",
    "print (out_autoencoder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    cv2.imwrite(\"./data/denoise-cifar-bw/\"+str(i)+\".png\",out_autoencoder[i]*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndisplay_images(test_images,10)\\ndisplay_images(noisy_test_images,10)\\ndisplay_images(out,10)\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "display_images(test_images,10)\n",
    "display_images(noisy_test_images,10)\n",
    "display_images(out,10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_psnr(imageA,imageB):\n",
    "    maxI = 255.\n",
    "    try:\n",
    "        return 20*math.log10(maxI) - 10*math.log10(compare_mse(imageA.flatten(),imageB.flatten()))\n",
    "    except:\n",
    "        return 20*math.log10(maxI)\n",
    "\n",
    "def get_psnr_result(x_test, out):\n",
    "    psnr_sum = 0\n",
    "    for i in range(out.shape[0]):\n",
    "        psnr_sum += compare_psnr(x_test[i].reshape(32,32,1),out[i].reshape(32,32,1),data_range=255)\n",
    "        \n",
    "    return 1.0*psnr_sum/out.shape[0];\n",
    "\n",
    "def get_ssim_result(originalSet,noisySet):\n",
    "    ssim_sum = 0\n",
    "    originalSet = originalSet.reshape(originalSet.shape[0],32,32,1)\n",
    "    noisySet = noisySet.reshape(noisySet.shape[0],32,32,1)\n",
    "    for i in range(originalSet.shape[0]):\n",
    "        ssim_sum += ssim(originalSet[i], noisySet[i],data_range=originalSet[i].max() - noisySet[i].min(), multichannel=True)\n",
    "    return 1.0*ssim_sum/originalSet.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bm3d_denoise(noisy_image):\n",
    "    noisy_image = noisy_image.reshape(noisy_image.shape[0],32,32)\n",
    "    denoised = []\n",
    "    count = 1\n",
    "    for i in range(noisy_image.shape[0]):\n",
    "        Basic_img = bm3d.BM3D_1st_step(noisy_image[i])\n",
    "        Final_img = bm3d.BM3D_2nd_step(Basic_img, noisy_image[i])\n",
    "        denoised.append(Final_img)\n",
    "        if (count%10 == 0):\n",
    "            print (str(count)+ \"images denoised\")\n",
    "        count+=1\n",
    "        \n",
    "    return np.array(denoised)\n",
    "\n",
    "def nlm_denoise(noisy_image):\n",
    "    noisy_image = noisy_image.reshape(noisy_image.shape[0],32,32,1)\n",
    "    denoised = []\n",
    "    count = 1\n",
    "    \n",
    "    for image in noisy_image:\n",
    "        denoised_image = denoise_nl_means(image, 7, 11, 0.5,multichannel = False)\n",
    "        denoised.append(denoised_image)\n",
    "        if(count%100 == 0) :\n",
    "            print(str(count)+\" images denoised\")\n",
    "        count+=1\n",
    "    return np.array(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10000, 32, 32, 1), (10000, 32, 32, 1))\n",
      "458.092258419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.066576979897317"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (test_images.shape,out_autoencoder.shape)\n",
    "print (compare_mse(test_images[0].flatten(),(out_autoencoder[0]*255.).flatten()))\n",
    "get_psnr_result(out_autoencoder*255.,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_sym_autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-c6ec004857a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_sym_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_sym_autoencoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_psnr_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_sym_autoencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_sym_autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "print (test_images.shape,out_sym_autoencoder.shape)\n",
    "print (mean_squared_error(test_images[0].flatten(),out_sym_autoencoder[0].flatten()))\n",
    "get_psnr_result(out_sym_autoencoder,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bm3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "/home/travis/miniconda/conda-bld/work/opencv-2.4.11/modules/core/src/dxt.cpp:2330: error: (-213) Odd-size DCT's are not implemented in function dct\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-14100dc74e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbm3d_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm3d_denoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-5e994559fb52>\u001b[0m in \u001b[0;36mbm3d_denoise\u001b[0;34m(noisy_image)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mBasic_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBM3D_1st_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mFinal_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbm3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBM3D_2nd_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasic_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisy_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdenoised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFinal_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/Image-Denoising-with-Convolutional-Denoising-Autoencoders/bm3d.pyc\u001b[0m in \u001b[0;36mBM3D_1st_step\u001b[0;34m(_noisyImg)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHeight_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mm_blockPoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocate_blk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblk_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_Size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mSimilar_Blks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStep1_fast_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_noisyImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_blockPoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mSimilar_Blks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatis_nonzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStep1_3DFiltering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimilar_Blks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mAggregation_hardthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSimilar_Blks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPositions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBasic_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_Wight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatis_nonzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_Kaiser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/Image-Denoising-with-Convolutional-Denoising-Autoencoders/bm3d.pyc\u001b[0m in \u001b[0;36mStep1_fast_match\u001b[0;34m(_noisyImg, _BlockPoint)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mtem_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_noisyImg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpresent_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpresent_x\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBlk_Size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresent_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpresent_y\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBlk_Size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdct_Tem_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtem_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mm_Distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdct_img\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdct_Tem_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBlk_Size\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /home/travis/miniconda/conda-bld/work/opencv-2.4.11/modules/core/src/dxt.cpp:2330: error: (-213) Odd-size DCT's are not implemented in function dct\n"
     ]
    }
   ],
   "source": [
    "noisy_test_images.shape\n",
    "bm3d_out = bm3d_denoise(noisy_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm3d_out_norm = bm3d_out.astype('float64')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_psnr_result(bm3d_out_norm,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-c8bb56579059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlm_denoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_test_images\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnlm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-165-85427f2402e9>\u001b[0m in \u001b[0;36mnlm_denoise\u001b[0;34m(noisy_image)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnoisy_image\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mdenoised_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenoise_nl_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmultichannel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mdenoised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenoised_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/skimage/restoration/non_local_means.pyc\u001b[0m in \u001b[0;36mdenoise_nl_means\u001b[0;34m(image, patch_size, patch_distance, h, multichannel, fast_mode)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfast_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             return np.array(_fast_nl_means_denoising_3d(image, s=patch_size,\n\u001b[0;32m--> 127\u001b[0;31m                                                         d=patch_distance, h=h))\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             return np.array(_nl_means_denoising_3d(image, patch_size,\n",
      "\u001b[0;32mskimage/restoration/_nl_means_denoising.pyx\u001b[0m in \u001b[0;36mskimage.restoration._nl_means_denoising._fast_nl_means_denoising_3d (skimage/restoration/_nl_means_denoising.c:8689)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36mzeros_like\u001b[0;34m(a, dtype, order, subok)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \"\"\"\n\u001b[1;32m     89\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mzeros\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(noisy_test_images.shape)\n",
    "nlm_out = nlm_denoise(noisy_test_images*255.)\n",
    "nlm_out = nlm_out.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32) (10000, 32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.414818545893922"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print nlm_out.shape,test_images.shape\n",
    "get_psnr_result(nlm_out,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69608629344603479"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,out_autoencoder*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.718734871276698"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,out_sym_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_ssim_result(test_images,bm3d_out_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49438484841716263"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,nlm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"./models/simple_cnn_autoencoder.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s     \n"
     ]
    }
   ],
   "source": [
    "bwmodel= model.predict(noisy_test_images,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10000, 32, 32, 1), (10000, 32, 32, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.773690910050014"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (test_images.shape,bwmodel.shape)\n",
    "get_psnr_result(bwmodel,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path,filename),0)\n",
    "        if img is not None:\n",
    "            images.append((img,filename))\n",
    "    return np.array(images)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standard_test_images = read_images_from_folder('./data/standard_test_images/gd/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ array([[156, 157, 160, ..., 152, 152, 152],\n",
       "       [156, 157, 159, ..., 152, 152, 152],\n",
       "       [158, 157, 156, ..., 152, 152, 152],\n",
       "       ..., \n",
       "       [121, 123, 126, ..., 121, 113, 111],\n",
       "       [121, 123, 126, ..., 121, 113, 111],\n",
       "       [121, 123, 126, ..., 121, 113, 111]], dtype=uint8),\n",
       "       'cameraman.tif'], dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_test_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std_test_images = []\n",
    "image_names = []\n",
    "for img in standard_test_images:\n",
    "    std_test_images.append(img[0])\n",
    "    image_names.append(img[1])\n",
    "std_test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noisy_std_test_images = add_noise(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in range(noisy_std_test_images.shape[0]):\n",
    "    cv2.imwrite('./data/standard_test_images/noise/'+image_names[index],noisy_std_test_images[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denoise_by_patches(noisy_image,model,stride):\n",
    "    denoise_image = [[0 for col in range(512)] for row in range(512)]\n",
    "    overlap_mat = [[0 for col in range(512)] for row in range(512)]\n",
    "    denoise_image = np.array(denoise_image)\n",
    "    overlap_mat = np.array(overlap_mat)\n",
    "    norm_image = noisy_image/255.\n",
    "    cnt = 1\n",
    "    for row in xrange(0,512 - 31,stride):\n",
    "        for col in xrange(0,512 - 31,stride):\n",
    "            #print cnt\n",
    "            cnt+=1\n",
    "            patch = norm_image[row:row+32,col:col+32]\n",
    "            #print patch.shape\n",
    "            de_patch = [patch]\n",
    "            de_patch = np.array(de_patch)\n",
    "            #print row,col,de_patch.shape\n",
    "            de_patch = np.reshape(de_patch, (1,32,32,1))\n",
    "            #print de_patch.shape\n",
    "            de_patch = model.predict(de_patch)\n",
    "            de_patch = de_patch[0]*255.\n",
    "            denoise_image[row:row+32 ,col:col+32] += np.reshape(de_patch, (32,32)).astype('int64')\n",
    "            overlap_mat[row:row+32 ,col:col+32] += 1\n",
    "    \n",
    "    for row in xrange(0,512):\n",
    "        for col in xrange(0,512):\n",
    "            denoise_image[row][col]/=(overlap_mat[row][col]*1.0)\n",
    "    \n",
    "    return denoise_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denoise_std_test_images(images,model,stride):\n",
    "    denoised_images = []\n",
    "    for index in range(images.shape[0]):\n",
    "        d_image = denoise_by_patches(images[index],model,stride)\n",
    "        denoised_images.append(d_image)\n",
    "        print compare_psnr(d_image.astype('int64'),std_test_images[index].astype('int64'),data_range=255)\n",
    "        cv2.imwrite('./data/standard_test_images/denoise/'+image_names[index],d_image)\n",
    "        print \"image \" + str(index)+ \" denoised\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-fa9687567ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdenoise_std_test_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_std_test_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-229-5dd213b9b68e>\u001b[0m in \u001b[0;36mdenoise_std_test_images\u001b[0;34m(images, model, stride)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdenoised_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0md_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenoise_by_patches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdenoised_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mcompare_psnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd_test_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-222-a5ba357f2f42>\u001b[0m in \u001b[0;36mdenoise_by_patches\u001b[0;34m(noisy_image, model, stride)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mde_patch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_patch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m#print de_patch.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mde_patch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mde_patch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mde_patch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mdenoise_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m32\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_patch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1517\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "denoise_std_test_images(noisy_std_test_images,model,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.1276904426\n"
     ]
    }
   ],
   "source": [
    "nlm_camera = cv2.fastNlMeansDenoising(noisy_std_test_images[0].astype('uint8'),None,25,7 ,21)\n",
    "cv2.imwrite(\"nlm.png\",nlm_camera)\n",
    "print compare_psnr(nlm_camera,std_test_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = load_model('./models/simple_cnn_autoencoder.hdf5')\n",
    "#sym_autoencoder = load_model('./models/gated_cnn_autoencoder.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ssim(originalSet,noisySet):\n",
    "    return ssim(originalSet, noisySet,data_range=originalSet.max() - noisySet.min(), multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_image(img,vmin,vmax):\n",
    "    umin = img.min()\n",
    "    umax = img.max()\n",
    "    \n",
    "    sf = 1.0*(vmax - vmin)/(umax - umin)\n",
    "    scaled_image = vmin + 1.0*(img - umin)*sf\n",
    "    return scaled_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_multichannel_gaussian(test_img,noise_std):\n",
    "    noise = np.random.normal(0,noise_std, (test_img.shape[0],test_img.shape[1])).astype('uint8')\n",
    "    noisy_test = np.ones((test_img.shape[0],test_img.shape[1],3),dtype=np.uint8)\n",
    "    noisy_test[:,:,0] = test_img[:,:,0] + noise\n",
    "    noisy_test[:,:,1] = test_img[:,:,1] + noise\n",
    "    noisy_test[:,:,2] = test_img[:,:,2] +noise\n",
    "    noisy_test = np.clip(noisy_test,0.,255.)\n",
    "    \n",
    "    return noisy_test\n",
    "\n",
    "def add_greyscale_noise(test_img,noise_std):\n",
    "    noise = np.random.normal(0,noise_std, (test_img.shape[0],test_img.shape[1])).astype('float64')\n",
    "    print test_img.min(),test_img.max()\n",
    "    test_img = test_img + noise\n",
    "    print test_img.min(),test_img.max(),noise.min(),noise.max()\n",
    "     \n",
    "    grey_test = scale_image(test_img,0,255)\n",
    "    print grey_test.min(),grey_test.max()\n",
    "    \n",
    "    grey_noisy = np.zeros((test_img.shape[0],test_img.shape[1],3),dtype=np.uint8)\n",
    "    grey_noisy[:,:,0] = grey_test\n",
    "    grey_noisy[:,:,1] = grey_test\n",
    "    grey_noisy[:,:,2] = grey_test\n",
    "    \n",
    "    \n",
    "    \n",
    "    return grey_noisy,grey_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.imshow(out_autoencoder[0])\n",
    "\n",
    "def predict_save(model,image_path):\n",
    "    \n",
    "    noise_std = 30\n",
    "    test_img = cv2.imread(image_path,0)\n",
    "    cv2.imwrite(\"gt.png\",test_img)\n",
    "    test_img = np.array(test_img)\n",
    "    \n",
    "    #Adding noise\n",
    "    noisy_test,noisy_test_SC = add_greyscale_noise(test_img,noise_std)\n",
    "    cv2.imwrite(\"noisy.png\",noisy_test_SC)\n",
    "    print compare_psnr(test_img.astype('uint8'),noisy_test_SC.astype('uint8')), get_ssim(test_img.astype('uint8'),noisy_test_SC.astype('uint8'))\n",
    "    \n",
    "    \n",
    "    #NLM Denoise\n",
    "    nlm_out = cv2.fastNlMeansDenoising(noisy_test.astype('uint8'),noise_std,7,21)\n",
    "    print compare_psnr(nlm_out.astype('uint8'),test_img.astype('uint8')), get_ssim(nlm_out.astype('uint8'),test_img.astype('uint8'))\n",
    "    cv2.imwrite(\"nlm_denoise.png\",nlm_out)\n",
    "\n",
    "    \n",
    "    noisy_test = noisy_test.reshape(1,noisy_test.shape[0],noisy_test.shape[1],noisy_test.shape[2])\n",
    "    noisy_test = noisy_test/255.0\n",
    "    \n",
    "    out = model.predict(noisy_test,verbose=1)\n",
    "    \n",
    "    output_img = (out[0][:,:,0]*255.).astype('uint8');\n",
    "    print compare_psnr(output_img,test_img.astype('uint8')), get_ssim(output_img,test_img.astype('uint8'))\n",
    "    cv2.imwrite(\"denoised.png\",output_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 253\n",
      "-109.043346539 306.869268315 -139.052527416 121.748786369\n",
      "0.0 255.0\n",
      "16.8528460998 0.290518422267\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "17.6329043681 0.483915942431\n"
     ]
    }
   ],
   "source": [
    "predict_save(autoencoder,'./data/standard_test_images/gt/cameraman.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function fastNlMeansDenoising in module cv2:\n",
      "\n",
      "fastNlMeansDenoising(...)\n",
      "    fastNlMeansDenoising(src[, dst[, h[, templateWindowSize[, searchWindowSize]]]]) -> dst\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.fastNlMeansDenoising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_9 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, None, None, 64 3136        input_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_10 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)                (None, None, None, 64 0           conv2d_21[0][0]                  \n",
      "                                                                   input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D)  (None, None, None, 64 0           lambda_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, None, None, 64 65600       max_pooling2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "input_11 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)               (None, None, None, 64 0           conv2d_22[0][0]                  \n",
      "                                                                   input_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D)  (None, None, None, 64 0           lambda_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, None, None, 12 131200      max_pooling2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D)  (None, None, None, 12 0           conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, None, None, 25 524544      max_pooling2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D)  (None, None, None, 25 0           conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, None, None, 51 2097664     max_pooling2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "input_13 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling2D)  (None, None, None, 51 0           conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)               (None, None, None, 25 0           conv2d_24[0][0]                  \n",
      "                                                                   input_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTransp (None, None, None, 25 2097408     up_sampling2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)               (None, None, None, 25 0           conv2d_24[0][0]                  \n",
      "                                                                   lambda_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, None, None, 25 0           conv2d_transpose_6[0][0]         \n",
      "                                                                   lambda_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_12 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D)  (None, None, None, 25 0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)               (None, None, None, 12 0           conv2d_23[0][0]                  \n",
      "                                                                   input_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTransp (None, None, None, 12 524416      up_sampling2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)               (None, None, None, 12 0           conv2d_23[0][0]                  \n",
      "                                                                   lambda_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, None, None, 12 0           conv2d_transpose_7[0][0]         \n",
      "                                                                   lambda_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling2D)  (None, None, None, 12 0           add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTransp (None, None, None, 64 131136      up_sampling2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)               (None, None, None, 64 0           conv2d_22[0][0]                  \n",
      "                                                                   lambda_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, None, None, 64 0           conv2d_transpose_8[0][0]         \n",
      "                                                                   lambda_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling2D)  (None, None, None, 64 0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)               (None, None, None, 64 0           conv2d_21[0][0]                  \n",
      "                                                                   lambda_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, None, None, 64 0           up_sampling2d_14[0][0]           \n",
      "                                                                   lambda_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTransp (None, None, None, 64 65600       add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTrans (None, None, None, 3) 3075        conv2d_transpose_9[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 5,643,779\n",
      "Trainable params: 5,643,779\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sym_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not create write struct",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-356-aa3126bc0d6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhistr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcHist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hist.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, **kwargs)\u001b[0m\n\u001b[1;32m   1812\u001b[0m     \u001b[0mnewsize\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewsize\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfigsize_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;31m# Finally, if we have a really funky aspect ratio, break it but respect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m     \u001b[0;31m# the min/max dimensions (we don't want figures 10 feet tall!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m     \u001b[0mnewsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2257\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morigDPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigfacecolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2259\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigedgecolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_canvas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_saving\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not create write struct"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not create write struct",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2206\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_bbox_extra_artists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2208\u001b[0;31m                 \u001b[0mbbox_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2209\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbbox_artists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2210\u001b[0m                     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not create write struct"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb47e9453d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('noisy.png')\n",
    "color = ('b','g','r')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
