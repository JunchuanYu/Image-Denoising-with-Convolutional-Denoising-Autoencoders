{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import skimage\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from skimage import data, img_as_float\n",
    "from skimage.restoration import denoise_nl_means\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "from random import shuffle\n",
    "import math\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from utilities import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.layers.core import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_all_datasets():\n",
    "    rawimages = read_dataset('data/all-mias/')\n",
    "    rawimages.extend(read_dataset('data/dental'))\n",
    "    rawimages.extend(read_dataset('data/RawImage/TrainingData'))\n",
    "    return np.array(rawimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(722, 64, 64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawimages = read_all_datasets()\n",
    "rawimages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "#rawimages = rawimages.astype('float32')/255.\n",
    "images = np.reshape(rawimages, (rawimages.shape[0],64,64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in range(rawimages.shape[0]):\n",
    "    cv2.imwrite('./data/Test/denoise/image'+str(index)+'.png',rawimages[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to add gaussian noise\n",
    "def gaussian_noise(images,mean,sigma,prop):\n",
    "    \n",
    "    noisy_images = []\n",
    "    for img in images:\n",
    "        noisy_images.append(skimage.util.random_noise(img, mode='gaussian', seed=None, clip=True, mean=mean, var=sigma**2))\n",
    "   \n",
    "    return noisy_images\n",
    "\n",
    "#Adding noise to images\n",
    "def add_noise(images):\n",
    "    #x_train = np.reshape(x_train, (len(x_train), 64*64))  # adapt this if using `channels_first` image data format\n",
    "    #x_test = np.reshape(x_test, (len(x_test), 64*64))  # adapt this if using `channels_first` image data format\n",
    "    batch = images.shape[0]//4;\n",
    "    noise1 = gaussian_noise(images[0:batch],0,25,0.1)\n",
    "    noise2 = gaussian_noise(images[batch:2*batch],0,30,0.5)\n",
    "    noise3 = gaussian_noise(images[2*batch:3*batch],0,35,0.21)\n",
    "    noise4 = gaussian_noise(images[3*batch:],0,40,0.2)\n",
    "    \n",
    "    noisy_set = []\n",
    "    for data in [noise1,noise2,noise3,noise4]:\n",
    "        for image in data:\n",
    "            noisy_set.append(image)\n",
    "    \n",
    "    return np.array(noisy_set)\n",
    "#Shuffle the noisy image ground truth pair to randomize the noise distribution in the dataset\n",
    "def pair_shuffle(images,noisy_set):\n",
    "    image_pair = []\n",
    "    for i in range(images.shape[0]):\n",
    "        image_pair.append((images[i],noisy_set[i]))\n",
    "    shuffle(image_pair)\n",
    "    \n",
    "    ground_truth=[]\n",
    "    noisy_images = []\n",
    "    for i in range(images.shape[0]):\n",
    "        ground_truth.append(image_pair[i][0])\n",
    "        noisy_images.append(image_pair[i][1])\n",
    "    return np.array(ground_truth), np.array(noisy_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffling and adding noise to the dataset\n",
    "shuffle(images)\n",
    "#Getting the noisy image set\n",
    "noisy_set = add_noise(images)\n",
    "ground_truth,noisy_images = pair_shuffle(images,noisy_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(577, 64, 64, 1)\n",
      "(145, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "#Split into training and cross validation\n",
    "train_size = int(ground_truth.shape[0]*0.8)\n",
    "x_train = ground_truth[0:train_size]/255.\n",
    "x_train_noisy = noisy_images[0:train_size]/255.\n",
    "x_test = ground_truth[train_size:]/255.\n",
    "x_test_noisy = noisy_images[train_size:]/255.\n",
    "print x_train_noisy.shape\n",
    "print x_test_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in range(x_train_noisy.shape[0]):\n",
    "    cv2.imwrite('./data/Test/denoise/image'+str(index)+'.png',x_train_noisy[index]*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining the model\n",
    "\n",
    "def get_simple_autoencoder_model(model_path=None):\n",
    "    \n",
    "    if(model_path is None):\n",
    "        autoencoder = None\n",
    "    else:\n",
    "        autoencoder = read_model_json(model_path) \n",
    "    \n",
    "    if(autoencoder is None):\n",
    "        input_img = Input(shape=x_train_noisy[0].shape)  # adapt this if using `channels_first` image data format\n",
    "\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "        autoencoder = Model(input_img, decoded)\n",
    "        autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "    print (autoencoder.summary())\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('./models/simple_cnn_autoencoder.hdf5',monitor = 'loss', verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 64, 64, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 64, 64, 1)         577       \n",
      "=================================================================\n",
      "Total params: 112,001\n",
      "Trainable params: 112,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 577 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.4512 - acc: 0.3659Epoch 00000: loss improved from inf to 0.44942, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 6s - loss: 0.4494 - acc: 0.3668 - val_loss: 0.3556 - val_acc: 0.3626\n",
      "Epoch 2/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.3779Epoch 00001: loss improved from 0.44942 to 0.35322, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3532 - acc: 0.3780 - val_loss: 0.3511 - val_acc: 0.3627\n",
      "Epoch 3/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3444 - acc: 0.3802Epoch 00002: loss improved from 0.35322 to 0.34571, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3457 - acc: 0.3782 - val_loss: 0.3648 - val_acc: 0.3623\n",
      "Epoch 4/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3423 - acc: 0.3776Epoch 00003: loss improved from 0.34571 to 0.34136, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3414 - acc: 0.3782 - val_loss: 0.3376 - val_acc: 0.3634\n",
      "Epoch 5/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3358 - acc: 0.3796Epoch 00004: loss improved from 0.34136 to 0.33623, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3362 - acc: 0.3787 - val_loss: 0.3376 - val_acc: 0.3636\n",
      "Epoch 6/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3354 - acc: 0.3777Epoch 00005: loss improved from 0.33623 to 0.33463, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3346 - acc: 0.3789 - val_loss: 0.3329 - val_acc: 0.3640\n",
      "Epoch 7/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3324 - acc: 0.3787Epoch 00006: loss improved from 0.33463 to 0.33199, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3320 - acc: 0.3791 - val_loss: 0.3332 - val_acc: 0.3641\n",
      "Epoch 8/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3305 - acc: 0.3794Epoch 00007: loss improved from 0.33199 to 0.33048, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3305 - acc: 0.3793 - val_loss: 0.3312 - val_acc: 0.3642\n",
      "Epoch 9/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3281 - acc: 0.3807Epoch 00008: loss improved from 0.33048 to 0.32873, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3287 - acc: 0.3796 - val_loss: 0.3318 - val_acc: 0.3642\n",
      "Epoch 10/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3261 - acc: 0.3814Epoch 00009: loss improved from 0.32873 to 0.32706, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3271 - acc: 0.3796 - val_loss: 0.3287 - val_acc: 0.3644\n",
      "Epoch 11/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3273 - acc: 0.3791Epoch 00010: loss improved from 0.32706 to 0.32661, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3266 - acc: 0.3797 - val_loss: 0.3278 - val_acc: 0.3644\n",
      "Epoch 12/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.3795Epoch 00011: loss improved from 0.32661 to 0.32547, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3255 - acc: 0.3798 - val_loss: 0.3267 - val_acc: 0.3645\n",
      "Epoch 13/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3235 - acc: 0.3812Epoch 00012: loss improved from 0.32547 to 0.32450, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3245 - acc: 0.3799 - val_loss: 0.3314 - val_acc: 0.3642\n",
      "Epoch 14/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3243 - acc: 0.3800Epoch 00013: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3247 - acc: 0.3798 - val_loss: 0.3281 - val_acc: 0.3646\n",
      "Epoch 15/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3236 - acc: 0.3799Epoch 00014: loss improved from 0.32450 to 0.32319, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3232 - acc: 0.3799 - val_loss: 0.3277 - val_acc: 0.3645\n",
      "Epoch 16/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3230 - acc: 0.3796Epoch 00015: loss improved from 0.32319 to 0.32301, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3230 - acc: 0.3799 - val_loss: 0.3252 - val_acc: 0.3646\n",
      "Epoch 17/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.3787Epoch 00016: loss improved from 0.32301 to 0.32257, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3226 - acc: 0.3800 - val_loss: 0.3248 - val_acc: 0.3647\n",
      "Epoch 18/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3218 - acc: 0.3796Epoch 00017: loss improved from 0.32257 to 0.32214, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3221 - acc: 0.3800 - val_loss: 0.3268 - val_acc: 0.3646\n",
      "Epoch 19/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3222 - acc: 0.3795Epoch 00018: loss improved from 0.32214 to 0.32190, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3219 - acc: 0.3800 - val_loss: 0.3253 - val_acc: 0.3647\n",
      "Epoch 20/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3220 - acc: 0.3799Epoch 00019: loss improved from 0.32190 to 0.32187, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3219 - acc: 0.3800 - val_loss: 0.3240 - val_acc: 0.3647\n",
      "Epoch 21/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3216 - acc: 0.3787Epoch 00020: loss improved from 0.32187 to 0.32088, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3209 - acc: 0.3800 - val_loss: 0.3292 - val_acc: 0.3647\n",
      "Epoch 22/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3217 - acc: 0.3795Epoch 00021: loss improved from 0.32088 to 0.32085, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3209 - acc: 0.3801 - val_loss: 0.3258 - val_acc: 0.3647\n",
      "Epoch 23/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3205 - acc: 0.3797Epoch 00022: loss improved from 0.32085 to 0.32043, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3204 - acc: 0.3800 - val_loss: 0.3233 - val_acc: 0.3647\n",
      "Epoch 24/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3200 - acc: 0.3807Epoch 00023: loss improved from 0.32043 to 0.32027, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3203 - acc: 0.3801 - val_loss: 0.3239 - val_acc: 0.3647\n",
      "Epoch 25/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3211 - acc: 0.3791Epoch 00024: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3205 - acc: 0.3801 - val_loss: 0.3230 - val_acc: 0.3647\n",
      "Epoch 26/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3189 - acc: 0.3810Epoch 00025: loss improved from 0.32027 to 0.31942, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3194 - acc: 0.3801 - val_loss: 0.3244 - val_acc: 0.3647\n",
      "Epoch 27/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3192 - acc: 0.3810Epoch 00026: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3199 - acc: 0.3801 - val_loss: 0.3236 - val_acc: 0.3647\n",
      "Epoch 28/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3197 - acc: 0.3804Epoch 00027: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3201 - acc: 0.3801 - val_loss: 0.3278 - val_acc: 0.3647\n",
      "Epoch 29/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3191 - acc: 0.3800Epoch 00028: loss improved from 0.31942 to 0.31895, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3189 - acc: 0.3801 - val_loss: 0.3224 - val_acc: 0.3647\n",
      "Epoch 30/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3187 - acc: 0.3815Epoch 00029: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3196 - acc: 0.3801 - val_loss: 0.3242 - val_acc: 0.3647\n",
      "Epoch 31/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3187 - acc: 0.3802Epoch 00030: loss improved from 0.31895 to 0.31870, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3187 - acc: 0.3801 - val_loss: 0.3234 - val_acc: 0.3647\n",
      "Epoch 32/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3196 - acc: 0.3796Epoch 00031: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3192 - acc: 0.3801 - val_loss: 0.3250 - val_acc: 0.3647\n",
      "Epoch 33/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3209 - acc: 0.3777Epoch 00032: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3194 - acc: 0.3801 - val_loss: 0.3229 - val_acc: 0.3647\n",
      "Epoch 34/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3190 - acc: 0.3797Epoch 00033: loss improved from 0.31870 to 0.31853, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 6s - loss: 0.3185 - acc: 0.3801 - val_loss: 0.3220 - val_acc: 0.3647\n",
      "Epoch 35/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3178 - acc: 0.3820Epoch 00034: loss did not improve\n",
      "577/577 [==============================] - 6s - loss: 0.3189 - acc: 0.3801 - val_loss: 0.3250 - val_acc: 0.3647\n",
      "Epoch 36/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3192 - acc: 0.3795Epoch 00035: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3188 - acc: 0.3801 - val_loss: 0.3222 - val_acc: 0.3647\n",
      "Epoch 37/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3190 - acc: 0.3793Epoch 00036: loss improved from 0.31853 to 0.31842, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3184 - acc: 0.3801 - val_loss: 0.3224 - val_acc: 0.3648\n",
      "Epoch 38/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3181 - acc: 0.3806Epoch 00037: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3186 - acc: 0.3801 - val_loss: 0.3250 - val_acc: 0.3647\n",
      "Epoch 39/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.3814Epoch 00038: loss improved from 0.31842 to 0.31817, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3182 - acc: 0.3801 - val_loss: 0.3239 - val_acc: 0.3647\n",
      "Epoch 40/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3188 - acc: 0.3796Epoch 00039: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3186 - acc: 0.3801 - val_loss: 0.3240 - val_acc: 0.3647\n",
      "Epoch 41/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3181 - acc: 0.3792Epoch 00040: loss improved from 0.31817 to 0.31781, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3178 - acc: 0.3801 - val_loss: 0.3219 - val_acc: 0.3648\n",
      "Epoch 42/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3180 - acc: 0.3803Epoch 00041: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3179 - acc: 0.3801 - val_loss: 0.3232 - val_acc: 0.3647\n",
      "Epoch 43/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3183 - acc: 0.3797Epoch 00042: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3178 - acc: 0.3801 - val_loss: 0.3220 - val_acc: 0.3648\n",
      "Epoch 44/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3177 - acc: 0.3809Epoch 00043: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3181 - acc: 0.3801 - val_loss: 0.3214 - val_acc: 0.3648\n",
      "Epoch 45/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3172 - acc: 0.3806Epoch 00044: loss improved from 0.31781 to 0.31717, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3172 - acc: 0.3801 - val_loss: 0.3215 - val_acc: 0.3648\n",
      "Epoch 46/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3183 - acc: 0.3803Epoch 00045: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3181 - acc: 0.3801 - val_loss: 0.3275 - val_acc: 0.3648\n",
      "Epoch 47/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3167 - acc: 0.3814Epoch 00046: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3176 - acc: 0.3801 - val_loss: 0.3224 - val_acc: 0.3648\n",
      "Epoch 48/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3183 - acc: 0.3785Epoch 00047: loss improved from 0.31717 to 0.31711, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3171 - acc: 0.3801 - val_loss: 0.3210 - val_acc: 0.3648\n",
      "Epoch 49/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3171 - acc: 0.3808Epoch 00048: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3174 - acc: 0.3801 - val_loss: 0.3230 - val_acc: 0.3648\n",
      "Epoch 50/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3169 - acc: 0.3805Epoch 00049: loss improved from 0.31711 to 0.31708, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3171 - acc: 0.3801 - val_loss: 0.3212 - val_acc: 0.3648\n",
      "Epoch 51/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3169 - acc: 0.3800Epoch 00050: loss improved from 0.31708 to 0.31690, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3169 - acc: 0.3801 - val_loss: 0.3210 - val_acc: 0.3648\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570/577 [============================>.] - ETA: 0s - loss: 0.3163 - acc: 0.3812Epoch 00051: loss improved from 0.31690 to 0.31688, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3169 - acc: 0.3801 - val_loss: 0.3207 - val_acc: 0.3648\n",
      "Epoch 53/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3164 - acc: 0.3811Epoch 00052: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3170 - acc: 0.3801 - val_loss: 0.3215 - val_acc: 0.3648\n",
      "Epoch 54/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.3798Epoch 00053: loss improved from 0.31688 to 0.31651, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3165 - acc: 0.3801 - val_loss: 0.3218 - val_acc: 0.3648\n",
      "Epoch 55/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3153 - acc: 0.3825Epoch 00054: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3169 - acc: 0.3801 - val_loss: 0.3217 - val_acc: 0.3648\n",
      "Epoch 56/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.3808Epoch 00055: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3168 - acc: 0.3801 - val_loss: 0.3205 - val_acc: 0.3648\n",
      "Epoch 57/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3171 - acc: 0.3794Epoch 00056: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3167 - acc: 0.3801 - val_loss: 0.3205 - val_acc: 0.3648\n",
      "Epoch 58/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.3787Epoch 00057: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3166 - acc: 0.3801 - val_loss: 0.3204 - val_acc: 0.3648\n",
      "Epoch 59/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3165 - acc: 0.3797Epoch 00058: loss improved from 0.31651 to 0.31630, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3163 - acc: 0.3801 - val_loss: 0.3222 - val_acc: 0.3648\n",
      "Epoch 60/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3158 - acc: 0.3808Epoch 00059: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3164 - acc: 0.3801 - val_loss: 0.3205 - val_acc: 0.3648\n",
      "Epoch 61/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3155 - acc: 0.3812Epoch 00060: loss improved from 0.31630 to 0.31621, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3162 - acc: 0.3801 - val_loss: 0.3236 - val_acc: 0.3648\n",
      "Epoch 62/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3164 - acc: 0.3804Epoch 00061: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3163 - acc: 0.3801 - val_loss: 0.3212 - val_acc: 0.3648\n",
      "Epoch 63/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3152 - acc: 0.3814Epoch 00062: loss improved from 0.31621 to 0.31598, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3160 - acc: 0.3801 - val_loss: 0.3201 - val_acc: 0.3648\n",
      "Epoch 64/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3161 - acc: 0.3797Epoch 00063: loss improved from 0.31598 to 0.31591, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3159 - acc: 0.3801 - val_loss: 0.3200 - val_acc: 0.3648\n",
      "Epoch 65/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3158 - acc: 0.3805Epoch 00064: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3161 - acc: 0.3801 - val_loss: 0.3223 - val_acc: 0.3648\n",
      "Epoch 66/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3179 - acc: 0.3771Epoch 00065: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3163 - acc: 0.3801 - val_loss: 0.3207 - val_acc: 0.3648\n",
      "Epoch 67/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3156 - acc: 0.3808Epoch 00066: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3159 - acc: 0.3801 - val_loss: 0.3228 - val_acc: 0.3648\n",
      "Epoch 68/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3168 - acc: 0.3792Epoch 00067: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3160 - acc: 0.3801 - val_loss: 0.3214 - val_acc: 0.3648\n",
      "Epoch 69/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.3785Epoch 00068: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3162 - acc: 0.3801 - val_loss: 0.3198 - val_acc: 0.3648\n",
      "Epoch 70/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3154 - acc: 0.3805Epoch 00069: loss improved from 0.31591 to 0.31586, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3159 - acc: 0.3801 - val_loss: 0.3233 - val_acc: 0.3648\n",
      "Epoch 71/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3171 - acc: 0.3781Epoch 00070: loss improved from 0.31586 to 0.31579, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3158 - acc: 0.3801 - val_loss: 0.3200 - val_acc: 0.3648\n",
      "Epoch 72/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3159 - acc: 0.3805Epoch 00071: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3160 - acc: 0.3801 - val_loss: 0.3197 - val_acc: 0.3648\n",
      "Epoch 73/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3151 - acc: 0.3812Epoch 00072: loss improved from 0.31579 to 0.31560, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3156 - acc: 0.3801 - val_loss: 0.3205 - val_acc: 0.3648\n",
      "Epoch 74/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.3794Epoch 00073: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3159 - acc: 0.3801 - val_loss: 0.3199 - val_acc: 0.3648\n",
      "Epoch 75/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3150 - acc: 0.3808Epoch 00074: loss improved from 0.31560 to 0.31541, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3154 - acc: 0.3801 - val_loss: 0.3215 - val_acc: 0.3648\n",
      "Epoch 76/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3144 - acc: 0.3818Epoch 00075: loss did not improve\n",
      "577/577 [==============================] - 14s - loss: 0.3157 - acc: 0.3801 - val_loss: 0.3196 - val_acc: 0.3648\n",
      "Epoch 77/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3155 - acc: 0.3811Epoch 00076: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3159 - acc: 0.3801 - val_loss: 0.3195 - val_acc: 0.3648\n",
      "Epoch 78/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3169 - acc: 0.3781Epoch 00077: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3157 - acc: 0.3801 - val_loss: 0.3197 - val_acc: 0.3648\n",
      "Epoch 79/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3163 - acc: 0.3790Epoch 00078: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3157 - acc: 0.3801 - val_loss: 0.3202 - val_acc: 0.3648\n",
      "Epoch 80/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3158 - acc: 0.3796Epoch 00079: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3156 - acc: 0.3801 - val_loss: 0.3251 - val_acc: 0.3648\n",
      "Epoch 81/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3164 - acc: 0.3782Epoch 00080: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3155 - acc: 0.3801 - val_loss: 0.3196 - val_acc: 0.3648\n",
      "Epoch 82/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.3787Epoch 00081: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3154 - acc: 0.3801 - val_loss: 0.3195 - val_acc: 0.3648\n",
      "Epoch 83/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3150 - acc: 0.3812Epoch 00082: loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 5s - loss: 0.3155 - acc: 0.3801 - val_loss: 0.3194 - val_acc: 0.3648\n",
      "Epoch 84/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3154 - acc: 0.3793Epoch 00083: loss improved from 0.31541 to 0.31520, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3152 - acc: 0.3801 - val_loss: 0.3194 - val_acc: 0.3648\n",
      "Epoch 85/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3149 - acc: 0.3809Epoch 00084: loss improved from 0.31520 to 0.31518, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3152 - acc: 0.3801 - val_loss: 0.3210 - val_acc: 0.3648\n",
      "Epoch 86/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3149 - acc: 0.3806Epoch 00085: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3153 - acc: 0.3801 - val_loss: 0.3196 - val_acc: 0.3648\n",
      "Epoch 87/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3150 - acc: 0.3808Epoch 00086: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3153 - acc: 0.3801 - val_loss: 0.3197 - val_acc: 0.3648\n",
      "Epoch 88/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3146 - acc: 0.3807Epoch 00087: loss improved from 0.31518 to 0.31495, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3149 - acc: 0.3801 - val_loss: 0.3197 - val_acc: 0.3648\n",
      "Epoch 89/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3156 - acc: 0.3788Epoch 00088: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3151 - acc: 0.3801 - val_loss: 0.3194 - val_acc: 0.3648\n",
      "Epoch 90/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.3788Epoch 00089: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3151 - acc: 0.3801 - val_loss: 0.3195 - val_acc: 0.3648\n",
      "Epoch 91/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3152 - acc: 0.3807Epoch 00090: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3156 - acc: 0.3801 - val_loss: 0.3193 - val_acc: 0.3648\n",
      "Epoch 92/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3148 - acc: 0.3804Epoch 00091: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3151 - acc: 0.3801 - val_loss: 0.3205 - val_acc: 0.3648\n",
      "Epoch 93/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3142 - acc: 0.3814Epoch 00092: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3151 - acc: 0.3801 - val_loss: 0.3193 - val_acc: 0.3648\n",
      "Epoch 94/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3149 - acc: 0.3807Epoch 00093: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3150 - acc: 0.3801 - val_loss: 0.3200 - val_acc: 0.3648\n",
      "Epoch 95/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3166 - acc: 0.3782Epoch 00094: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3154 - acc: 0.3801 - val_loss: 0.3192 - val_acc: 0.3648\n",
      "Epoch 96/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3160 - acc: 0.3788Epoch 00095: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3153 - acc: 0.3801 - val_loss: 0.3192 - val_acc: 0.3648\n",
      "Epoch 97/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3147 - acc: 0.3802Epoch 00096: loss improved from 0.31495 to 0.31462, saving model to ./models/simple_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 5s - loss: 0.3146 - acc: 0.3801 - val_loss: 0.3193 - val_acc: 0.3648\n",
      "Epoch 98/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3147 - acc: 0.3806Epoch 00097: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3148 - acc: 0.3801 - val_loss: 0.3196 - val_acc: 0.3648\n",
      "Epoch 99/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3132 - acc: 0.3828Epoch 00098: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3147 - acc: 0.3801 - val_loss: 0.3214 - val_acc: 0.3648\n",
      "Epoch 100/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.3148 - acc: 0.3804Epoch 00099: loss did not improve\n",
      "577/577 [==============================] - 5s - loss: 0.3150 - acc: 0.3801 - val_loss: 0.3191 - val_acc: 0.3648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7396af090>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "autoencoder = get_simple_autoencoder_model()\n",
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder', histogram_freq=0, write_graph=True),model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to get saved keras model\n",
    "def read_model_json(jsonfilePath,h5filePath):\n",
    "    try:\n",
    "        json_file = open(jsonfilePath, 'r')\n",
    "        print json_file\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        print \"hello\"\n",
    "        loaded_model = model_from_json(loaded_model_json)\n",
    "         \n",
    "        # load weights into new model\n",
    "        loaded_model.load_weights(h5filePath)\n",
    "\n",
    "        return loaded_model\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gated_connections(gatePercentageFactor,inputLayer):\n",
    "    gateFactor = Input(tensor = K.variable([gatePercentageFactor]))\n",
    "    fractionG = Lambda(lambda x: x[0]*x[1])([inputLayer,gateFactor])\n",
    "    complement = Lambda(lambda x: x[0] - x[1])([inputLayer,fractionG])\n",
    "    \n",
    "    return gateFactor,fractionG,complement\n",
    "\n",
    "#x is conv layer\n",
    "#y is de-conv layer\n",
    "#gf is gating factor\n",
    "#fg is fractional input from gate\n",
    "#c is complement ie remaining fraction from the gate\n",
    "#jt joining tensor of convolution layer and previous de-conv layer \n",
    "\n",
    "def get_cnn_dsc_architecture(model_path=None):\n",
    "    \n",
    "    if(model_path is None):\n",
    "        sym_autoencoder = None\n",
    "    else:\n",
    "        sym_autoencoder = read_model_json(model_path[0],model_path[1])\n",
    "        print model_path[0],model_path[1]\n",
    "    if(sym_autoencoder is None):\n",
    "        input_img = Input(shape=(64,64,1))  # adapt this if using `channels_first` image data format\n",
    "        x1 = Conv2D(64, (4, 4), activation='relu', padding='same')(input_img)\n",
    "        gf1,fg1,c1 = get_gated_connections(0.1,x1)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(fg1)\n",
    "        x2 = Conv2D(64, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf2,fg2,c2 = get_gated_connections(0.2,x2)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(fg2)\n",
    "        x3 = Conv2D(128, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf3,fg3,c3 = get_gated_connections(0.3,x3)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x3)\n",
    "        x4 = Conv2D(256, (4, 4), activation='relu', padding='same')(x) \n",
    "        gf4,fg4,c4 = get_gated_connections(0.4,x4)\n",
    "\n",
    "        x = MaxPooling2D((2, 2), padding='same')(x4)\n",
    "        x5 = Conv2D(512, (4, 4), activation='relu', padding='same')(x) \n",
    "\n",
    "        x = UpSampling2D((2, 2))(x5)\n",
    "        y1 = Conv2DTranspose(256, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt4 = Add()([y1,c4])\n",
    "        x = UpSampling2D((2, 2))(jt4)\n",
    "\n",
    "        y2 = Conv2DTranspose(128, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt3 = Add()([y2,c3])\n",
    "        x = UpSampling2D((2, 2))(jt3)\n",
    "\n",
    "        y3 = Conv2DTranspose(64, (4, 4), activation='relu', padding='same')(x) \n",
    "        jt2 = Add()([y3,c2])\n",
    "        x = UpSampling2D((2, 2))(jt2)\n",
    "\n",
    "        jt1 = Add()([x,c1])\n",
    "        y4 = Conv2DTranspose(64, (4, 4), activation='relu', padding='same')(jt1)\n",
    "        y5 = Conv2DTranspose(1, (4, 4), activation='relu', padding='same')(y4) \n",
    "\n",
    "        layers = y5\n",
    "\n",
    "        sym_autoencoder = Model([input_img,gf1,gf2,gf3,gf4],layers)\n",
    "        sym_autoencoder.compile(optimizer='sgd', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "        print \"Model created\"\n",
    "    else:\n",
    "        print \"Saved model loaded\"\n",
    "    print sym_autoencoder.summary()\n",
    "    return sym_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_19 (InputLayer)            (None, 64, 64, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 64, 64, 64)    1088        input_19[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "input_20 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)               (None, 64, 64, 64)    0           conv2d_31[0][0]                  \n",
      "                                                                   input_20[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D)  (None, 32, 32, 64)    0           lambda_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 32, 32, 64)    65600       max_pooling2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "input_21 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)               (None, 32, 32, 64)    0           conv2d_32[0][0]                  \n",
      "                                                                   input_21[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D)  (None, 16, 16, 64)    0           lambda_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 16, 16, 128)   131200      max_pooling2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D)  (None, 8, 8, 128)     0           conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 8, 8, 256)     524544      max_pooling2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D)  (None, 4, 4, 256)     0           conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 4, 4, 512)     2097664     max_pooling2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "input_23 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling2D)  (None, 8, 8, 512)     0           conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)               (None, 8, 8, 256)     0           conv2d_34[0][0]                  \n",
      "                                                                   input_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DTrans (None, 8, 8, 256)     2097408     up_sampling2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)               (None, 8, 8, 256)     0           conv2d_34[0][0]                  \n",
      "                                                                   lambda_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_13 (Add)                     (None, 8, 8, 256)     0           conv2d_transpose_16[0][0]        \n",
      "                                                                   lambda_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_22 (InputLayer)            (1,)                  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_20 (UpSampling2D)  (None, 16, 16, 256)   0           add_13[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)               (None, 16, 16, 128)   0           conv2d_33[0][0]                  \n",
      "                                                                   input_22[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DTrans (None, 16, 16, 128)   524416      up_sampling2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)               (None, 16, 16, 128)   0           conv2d_33[0][0]                  \n",
      "                                                                   lambda_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_14 (Add)                     (None, 16, 16, 128)   0           conv2d_transpose_17[0][0]        \n",
      "                                                                   lambda_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_21 (UpSampling2D)  (None, 32, 32, 128)   0           add_14[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_18 (Conv2DTrans (None, 32, 32, 64)    131136      up_sampling2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)               (None, 32, 32, 64)    0           conv2d_32[0][0]                  \n",
      "                                                                   lambda_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_15 (Add)                     (None, 32, 32, 64)    0           conv2d_transpose_18[0][0]        \n",
      "                                                                   lambda_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_22 (UpSampling2D)  (None, 64, 64, 64)    0           add_15[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)               (None, 64, 64, 64)    0           conv2d_31[0][0]                  \n",
      "                                                                   lambda_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "add_16 (Add)                     (None, 64, 64, 64)    0           up_sampling2d_22[0][0]           \n",
      "                                                                   lambda_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_19 (Conv2DTrans (None, 64, 64, 64)    65600       add_16[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_20 (Conv2DTrans (None, 64, 64, 1)     1025        conv2d_transpose_19[0][0]        \n",
      "====================================================================================================\n",
      "Total params: 5,639,681\n",
      "Trainable params: 5,639,681\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sym_autoencoder = get_cnn_dsc_architecture()\n",
    "model_checkpoint = ModelCheckpoint('./models/gated_cnn_autoencoder.hdf5',monitor = 'loss', verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 577 samples, validate on 145 samples\n",
      "Epoch 1/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.3766Epoch 00000: loss improved from inf to 0.02698, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0270 - acc: 0.3774 - val_loss: 0.0111 - val_acc: 0.3625\n",
      "Epoch 2/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.3778Epoch 00001: loss improved from 0.02698 to 0.01065, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0107 - acc: 0.3777 - val_loss: 0.0100 - val_acc: 0.3625\n",
      "Epoch 3/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.3773Epoch 00002: loss improved from 0.01065 to 0.00985, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0098 - acc: 0.3778 - val_loss: 0.0094 - val_acc: 0.3625\n",
      "Epoch 4/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.3796Epoch 00003: loss improved from 0.00985 to 0.00929, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0093 - acc: 0.3778 - val_loss: 0.0089 - val_acc: 0.3625\n",
      "Epoch 5/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.3783Epoch 00004: loss improved from 0.00929 to 0.00881, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0088 - acc: 0.3778 - val_loss: 0.0085 - val_acc: 0.3626\n",
      "Epoch 6/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.3767Epoch 00005: loss improved from 0.00881 to 0.00841, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0084 - acc: 0.3778 - val_loss: 0.0081 - val_acc: 0.3626\n",
      "Epoch 7/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.3779Epoch 00006: loss improved from 0.00841 to 0.00805, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0081 - acc: 0.3778 - val_loss: 0.0078 - val_acc: 0.3626\n",
      "Epoch 8/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.3780Epoch 00007: loss improved from 0.00805 to 0.00773, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0077 - acc: 0.3779 - val_loss: 0.0075 - val_acc: 0.3626\n",
      "Epoch 9/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.3768Epoch 00008: loss improved from 0.00773 to 0.00744, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0074 - acc: 0.3779 - val_loss: 0.0072 - val_acc: 0.3626\n",
      "Epoch 10/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.3768Epoch 00009: loss improved from 0.00744 to 0.00718, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0072 - acc: 0.3779 - val_loss: 0.0069 - val_acc: 0.3626\n",
      "Epoch 11/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.3784Epoch 00010: loss improved from 0.00718 to 0.00694, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0069 - acc: 0.3779 - val_loss: 0.0067 - val_acc: 0.3626\n",
      "Epoch 12/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.3784Epoch 00011: loss improved from 0.00694 to 0.00673, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0067 - acc: 0.3779 - val_loss: 0.0065 - val_acc: 0.3626\n",
      "Epoch 13/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.3782Epoch 00012: loss improved from 0.00673 to 0.00653, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0065 - acc: 0.3780 - val_loss: 0.0063 - val_acc: 0.3626\n",
      "Epoch 14/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.3794Epoch 00013: loss improved from 0.00653 to 0.00635, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0063 - acc: 0.3780 - val_loss: 0.0062 - val_acc: 0.3626\n",
      "Epoch 15/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.3797Epoch 00014: loss improved from 0.00635 to 0.00618, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0062 - acc: 0.3780 - val_loss: 0.0060 - val_acc: 0.3626\n",
      "Epoch 16/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.3792Epoch 00015: loss improved from 0.00618 to 0.00602, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0060 - acc: 0.3780 - val_loss: 0.0059 - val_acc: 0.3626\n",
      "Epoch 17/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.3775Epoch 00016: loss improved from 0.00602 to 0.00587, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0059 - acc: 0.3781 - val_loss: 0.0057 - val_acc: 0.3626\n",
      "Epoch 18/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.3774Epoch 00017: loss improved from 0.00587 to 0.00572, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0057 - acc: 0.3781 - val_loss: 0.0056 - val_acc: 0.3626\n",
      "Epoch 19/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.3769Epoch 00018: loss improved from 0.00572 to 0.00559, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0056 - acc: 0.3781 - val_loss: 0.0054 - val_acc: 0.3627\n",
      "Epoch 20/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.3795Epoch 00019: loss improved from 0.00559 to 0.00545, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0055 - acc: 0.3781 - val_loss: 0.0053 - val_acc: 0.3627\n",
      "Epoch 21/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.3777Epoch 00020: loss improved from 0.00545 to 0.00533, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0053 - acc: 0.3781 - val_loss: 0.0052 - val_acc: 0.3627\n",
      "Epoch 22/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.3792Epoch 00021: loss improved from 0.00533 to 0.00521, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0052 - acc: 0.3781 - val_loss: 0.0051 - val_acc: 0.3627\n",
      "Epoch 23/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.3771Epoch 00022: loss improved from 0.00521 to 0.00510, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0051 - acc: 0.3781 - val_loss: 0.0050 - val_acc: 0.3627\n",
      "Epoch 24/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.3778Epoch 00023: loss improved from 0.00510 to 0.00499, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0050 - acc: 0.3782 - val_loss: 0.0049 - val_acc: 0.3627\n",
      "Epoch 25/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.3792Epoch 00024: loss improved from 0.00499 to 0.00488, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0049 - acc: 0.3782 - val_loss: 0.0047 - val_acc: 0.3627\n",
      "Epoch 26/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.3782Epoch 00025: loss improved from 0.00488 to 0.00478, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0048 - acc: 0.3782 - val_loss: 0.0046 - val_acc: 0.3627\n",
      "Epoch 27/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.3776Epoch 00026: loss improved from 0.00478 to 0.00468, saving model to ./models/gated_cnn_autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 22s - loss: 0.0047 - acc: 0.3782 - val_loss: 0.0046 - val_acc: 0.3627\n",
      "Epoch 28/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.3778Epoch 00027: loss improved from 0.00468 to 0.00459, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0046 - acc: 0.3782 - val_loss: 0.0045 - val_acc: 0.3627\n",
      "Epoch 29/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.3792Epoch 00028: loss improved from 0.00459 to 0.00450, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0045 - acc: 0.3782 - val_loss: 0.0044 - val_acc: 0.3628\n",
      "Epoch 30/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.3767Epoch 00029: loss improved from 0.00450 to 0.00441, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0044 - acc: 0.3782 - val_loss: 0.0043 - val_acc: 0.3628\n",
      "Epoch 31/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.3795Epoch 00030: loss improved from 0.00441 to 0.00432, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0043 - acc: 0.3783 - val_loss: 0.0042 - val_acc: 0.3628\n",
      "Epoch 32/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.3779Epoch 00031: loss improved from 0.00432 to 0.00424, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0042 - acc: 0.3783 - val_loss: 0.0041 - val_acc: 0.3628\n",
      "Epoch 33/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.3778Epoch 00032: loss improved from 0.00424 to 0.00416, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0042 - acc: 0.3783 - val_loss: 0.0040 - val_acc: 0.3628\n",
      "Epoch 34/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.3794Epoch 00033: loss improved from 0.00416 to 0.00408, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0041 - acc: 0.3783 - val_loss: 0.0040 - val_acc: 0.3628\n",
      "Epoch 35/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.3785Epoch 00034: loss improved from 0.00408 to 0.00400, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0040 - acc: 0.3783 - val_loss: 0.0039 - val_acc: 0.3628\n",
      "Epoch 36/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.3808Epoch 00035: loss improved from 0.00400 to 0.00392, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0039 - acc: 0.3783 - val_loss: 0.0038 - val_acc: 0.3628\n",
      "Epoch 37/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.3761Epoch 00036: loss improved from 0.00392 to 0.00385, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0038 - acc: 0.3784 - val_loss: 0.0037 - val_acc: 0.3628\n",
      "Epoch 38/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.3778Epoch 00037: loss improved from 0.00385 to 0.00378, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0038 - acc: 0.3784 - val_loss: 0.0037 - val_acc: 0.3628\n",
      "Epoch 39/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.3790Epoch 00038: loss improved from 0.00378 to 0.00371, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0037 - acc: 0.3784 - val_loss: 0.0036 - val_acc: 0.3628\n",
      "Epoch 40/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.3777Epoch 00039: loss improved from 0.00371 to 0.00364, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0036 - acc: 0.3784 - val_loss: 0.0035 - val_acc: 0.3628\n",
      "Epoch 41/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.3794Epoch 00040: loss improved from 0.00364 to 0.00357, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0036 - acc: 0.3785 - val_loss: 0.0035 - val_acc: 0.3629\n",
      "Epoch 42/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.3782Epoch 00041: loss improved from 0.00357 to 0.00350, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0035 - acc: 0.3785 - val_loss: 0.0034 - val_acc: 0.3629\n",
      "Epoch 43/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.3775Epoch 00042: loss improved from 0.00350 to 0.00344, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0034 - acc: 0.3786 - val_loss: 0.0033 - val_acc: 0.3631\n",
      "Epoch 44/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.3783Epoch 00043: loss improved from 0.00344 to 0.00337, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0034 - acc: 0.3788 - val_loss: 0.0033 - val_acc: 0.3632\n",
      "Epoch 45/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.3785Epoch 00044: loss improved from 0.00337 to 0.00331, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0033 - acc: 0.3789 - val_loss: 0.0032 - val_acc: 0.3635\n",
      "Epoch 46/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.3779Epoch 00045: loss improved from 0.00331 to 0.00325, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0032 - acc: 0.3790 - val_loss: 0.0031 - val_acc: 0.3637\n",
      "Epoch 47/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.3788Epoch 00046: loss improved from 0.00325 to 0.00319, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0032 - acc: 0.3792 - val_loss: 0.0031 - val_acc: 0.3639\n",
      "Epoch 48/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.3799Epoch 00047: loss improved from 0.00319 to 0.00313, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0031 - acc: 0.3793 - val_loss: 0.0030 - val_acc: 0.3640\n",
      "Epoch 49/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.3797Epoch 00048: loss improved from 0.00313 to 0.00307, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0031 - acc: 0.3793 - val_loss: 0.0030 - val_acc: 0.3641\n",
      "Epoch 50/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.3790Epoch 00049: loss improved from 0.00307 to 0.00302, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0030 - acc: 0.3794 - val_loss: 0.0029 - val_acc: 0.3641\n",
      "Epoch 51/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.3804Epoch 00050: loss improved from 0.00302 to 0.00296, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0030 - acc: 0.3794 - val_loss: 0.0029 - val_acc: 0.3642\n",
      "Epoch 52/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.3782Epoch 00051: loss improved from 0.00296 to 0.00291, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0029 - acc: 0.3795 - val_loss: 0.0028 - val_acc: 0.3643\n",
      "Epoch 53/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.3800Epoch 00052: loss improved from 0.00291 to 0.00286, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0029 - acc: 0.3795 - val_loss: 0.0028 - val_acc: 0.3643\n",
      "Epoch 54/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.3802Epoch 00053: loss improved from 0.00286 to 0.00281, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0028 - acc: 0.3796 - val_loss: 0.0027 - val_acc: 0.3644\n",
      "Epoch 55/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.3794Epoch 00054: loss improved from 0.00281 to 0.00276, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0028 - acc: 0.3796 - val_loss: 0.0027 - val_acc: 0.3644\n",
      "Epoch 56/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.3783Epoch 00055: loss improved from 0.00276 to 0.00271, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0027 - acc: 0.3797 - val_loss: 0.0026 - val_acc: 0.3644\n",
      "Epoch 57/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.3789Epoch 00056: loss improved from 0.00271 to 0.00267, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0027 - acc: 0.3797 - val_loss: 0.0026 - val_acc: 0.3645\n",
      "Epoch 58/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.3792Epoch 00057: loss improved from 0.00267 to 0.00263, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0026 - acc: 0.3797 - val_loss: 0.0025 - val_acc: 0.3645\n",
      "Epoch 59/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.3795Epoch 00058: loss improved from 0.00263 to 0.00258, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0026 - acc: 0.3797 - val_loss: 0.0025 - val_acc: 0.3645\n",
      "Epoch 60/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.3786Epoch 00059: loss improved from 0.00258 to 0.00254, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0025 - acc: 0.3797 - val_loss: 0.0025 - val_acc: 0.3645\n",
      "Epoch 61/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.3799Epoch 00060: loss improved from 0.00254 to 0.00250, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0025 - acc: 0.3798 - val_loss: 0.0024 - val_acc: 0.3645\n",
      "Epoch 62/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.3808Epoch 00061: loss improved from 0.00250 to 0.00247, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0025 - acc: 0.3798 - val_loss: 0.0024 - val_acc: 0.3645\n",
      "Epoch 63/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.3800Epoch 00062: loss improved from 0.00247 to 0.00243, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0024 - acc: 0.3798 - val_loss: 0.0023 - val_acc: 0.3645\n",
      "Epoch 64/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.3793Epoch 00063: loss improved from 0.00243 to 0.00239, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0024 - acc: 0.3798 - val_loss: 0.0023 - val_acc: 0.3645\n",
      "Epoch 65/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.3803Epoch 00064: loss improved from 0.00239 to 0.00236, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0024 - acc: 0.3798 - val_loss: 0.0023 - val_acc: 0.3645\n",
      "Epoch 66/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.3791Epoch 00065: loss improved from 0.00236 to 0.00233, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0023 - acc: 0.3798 - val_loss: 0.0022 - val_acc: 0.3645\n",
      "Epoch 67/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.3803Epoch 00066: loss improved from 0.00233 to 0.00229, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0023 - acc: 0.3798 - val_loss: 0.0022 - val_acc: 0.3646\n",
      "Epoch 68/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.3804Epoch 00067: loss improved from 0.00229 to 0.00226, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0023 - acc: 0.3798 - val_loss: 0.0022 - val_acc: 0.3646\n",
      "Epoch 69/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.3802Epoch 00068: loss improved from 0.00226 to 0.00223, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0022 - acc: 0.3798 - val_loss: 0.0021 - val_acc: 0.3646\n",
      "Epoch 70/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.3795Epoch 00069: loss improved from 0.00223 to 0.00220, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0022 - acc: 0.3799 - val_loss: 0.0021 - val_acc: 0.3646\n",
      "Epoch 71/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.3816Epoch 00070: loss improved from 0.00220 to 0.00217, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0022 - acc: 0.3799 - val_loss: 0.0021 - val_acc: 0.3646\n",
      "Epoch 72/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.3794Epoch 00071: loss improved from 0.00217 to 0.00214, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0021 - acc: 0.3799 - val_loss: 0.0021 - val_acc: 0.3646\n",
      "Epoch 73/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.3791Epoch 00072: loss improved from 0.00214 to 0.00211, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0021 - acc: 0.3799 - val_loss: 0.0020 - val_acc: 0.3646\n",
      "Epoch 74/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.3812Epoch 00073: loss improved from 0.00211 to 0.00209, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 29s - loss: 0.0021 - acc: 0.3799 - val_loss: 0.0020 - val_acc: 0.3646\n",
      "Epoch 75/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.3792Epoch 00074: loss improved from 0.00209 to 0.00206, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0021 - acc: 0.3799 - val_loss: 0.0020 - val_acc: 0.3646\n",
      "Epoch 76/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.3788Epoch 00075: loss improved from 0.00206 to 0.00204, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0020 - acc: 0.3799 - val_loss: 0.0020 - val_acc: 0.3646\n",
      "Epoch 77/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.3795Epoch 00076: loss improved from 0.00204 to 0.00201, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0020 - acc: 0.3799 - val_loss: 0.0019 - val_acc: 0.3646\n",
      "Epoch 78/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.3795Epoch 00077: loss improved from 0.00201 to 0.00199, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0020 - acc: 0.3799 - val_loss: 0.0019 - val_acc: 0.3646\n",
      "Epoch 79/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.3793Epoch 00078: loss improved from 0.00199 to 0.00196, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0020 - acc: 0.3799 - val_loss: 0.0019 - val_acc: 0.3646\n",
      "Epoch 80/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.3800Epoch 00079: loss improved from 0.00196 to 0.00194, saving model to ./models/gated_cnn_autoencoder.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577/577 [==============================] - 22s - loss: 0.0019 - acc: 0.3799 - val_loss: 0.0019 - val_acc: 0.3646\n",
      "Epoch 81/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.3801Epoch 00080: loss improved from 0.00194 to 0.00192, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0019 - acc: 0.3799 - val_loss: 0.0018 - val_acc: 0.3646\n",
      "Epoch 82/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.3805Epoch 00081: loss improved from 0.00192 to 0.00189, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0019 - acc: 0.3800 - val_loss: 0.0018 - val_acc: 0.3646\n",
      "Epoch 83/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.3807Epoch 00082: loss improved from 0.00189 to 0.00187, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0019 - acc: 0.3800 - val_loss: 0.0018 - val_acc: 0.3646\n",
      "Epoch 84/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.3818Epoch 00083: loss improved from 0.00187 to 0.00185, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0019 - acc: 0.3800 - val_loss: 0.0018 - val_acc: 0.3646\n",
      "Epoch 85/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.3800Epoch 00084: loss improved from 0.00185 to 0.00183, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0018 - acc: 0.3800 - val_loss: 0.0018 - val_acc: 0.3646\n",
      "Epoch 86/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.3800Epoch 00085: loss improved from 0.00183 to 0.00181, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0018 - acc: 0.3800 - val_loss: 0.0017 - val_acc: 0.3646\n",
      "Epoch 87/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.3817Epoch 00086: loss improved from 0.00181 to 0.00179, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0018 - acc: 0.3800 - val_loss: 0.0017 - val_acc: 0.3646\n",
      "Epoch 88/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.3801Epoch 00087: loss improved from 0.00179 to 0.00177, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0018 - acc: 0.3800 - val_loss: 0.0017 - val_acc: 0.3646\n",
      "Epoch 89/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.3790Epoch 00088: loss improved from 0.00177 to 0.00176, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0018 - acc: 0.3800 - val_loss: 0.0017 - val_acc: 0.3646\n",
      "Epoch 90/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.3804Epoch 00089: loss improved from 0.00176 to 0.00174, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0017 - acc: 0.3800 - val_loss: 0.0017 - val_acc: 0.3647\n",
      "Epoch 91/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.3806Epoch 00090: loss improved from 0.00174 to 0.00172, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0017 - acc: 0.3800 - val_loss: 0.0017 - val_acc: 0.3647\n",
      "Epoch 92/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.3798Epoch 00091: loss improved from 0.00172 to 0.00170, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0017 - acc: 0.3800 - val_loss: 0.0016 - val_acc: 0.3647\n",
      "Epoch 93/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.3793Epoch 00092: loss improved from 0.00170 to 0.00169, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0017 - acc: 0.3800 - val_loss: 0.0016 - val_acc: 0.3647\n",
      "Epoch 94/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.3802Epoch 00093: loss improved from 0.00169 to 0.00167, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0017 - acc: 0.3800 - val_loss: 0.0016 - val_acc: 0.3647\n",
      "Epoch 95/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.3786Epoch 00094: loss improved from 0.00167 to 0.00166, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0017 - acc: 0.3800 - val_loss: 0.0016 - val_acc: 0.3647\n",
      "Epoch 96/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.3796Epoch 00095: loss improved from 0.00166 to 0.00164, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0016 - acc: 0.3800 - val_loss: 0.0016 - val_acc: 0.3647\n",
      "Epoch 97/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.3788Epoch 00096: loss improved from 0.00164 to 0.00163, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0016 - acc: 0.3800 - val_loss: 0.0016 - val_acc: 0.3647\n",
      "Epoch 98/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.3804Epoch 00097: loss improved from 0.00163 to 0.00161, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0016 - acc: 0.3800 - val_loss: 0.0015 - val_acc: 0.3647\n",
      "Epoch 99/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.3795Epoch 00098: loss improved from 0.00161 to 0.00160, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0016 - acc: 0.3800 - val_loss: 0.0015 - val_acc: 0.3647\n",
      "Epoch 100/100\n",
      "570/577 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.3793Epoch 00099: loss improved from 0.00160 to 0.00158, saving model to ./models/gated_cnn_autoencoder.hdf5\n",
      "577/577 [==============================] - 22s - loss: 0.0016 - acc: 0.3800 - val_loss: 0.0015 - val_acc: 0.3647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7fc371dd0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder', \n",
    "                                       histogram_freq=0,\n",
    "                                       write_graph=True),model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(577, 64, 64, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model_as_json(sym_autoencoder,'CNNDSC_MINI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting images to test\n",
    "def get_testing_images(filePath):\n",
    "    test_images = read_dataset(filePath)\n",
    "    test_images = np.array(test_images)\n",
    "    test_images = np.reshape(test_images, (test_images.shape[0],64,64,1))\n",
    "    noisy_test_images = add_noise(test_images)\n",
    "    noisy_test_images = noisy_test_images.astype('float32')/255.\n",
    "    \n",
    "    print (noisy_test_images.shape)\n",
    "    return (test_images,noisy_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 64, 64, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120, 64, 64, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images,noisy_test_images = get_testing_images('data/Test/gd/')\n",
    "noisy_test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in range(noisy_test_images.shape[0]):\n",
    "    cv2.imwrite('./data/Test/noisy/image'+str(index)+'.png',noisy_test_images[index]*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 1s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120, 64, 64, 1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Denoising using CNN symmetric Autoencoders\n",
    "out_sym_autoencoder = sym_autoencoder.predict(noisy_test_images,verbose=1)\n",
    "out_sym_autoencoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in range(out_sym_autoencoder.shape[0]):\n",
    "    cv2.imwrite('./data/Test/denoise/image'+str(index)+'.png',out_sym_autoencoder[index]*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120, 64, 64, 1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Denoising using Autoencoders\n",
    "out_autoencoder = autoencoder.predict(noisy_test_images,verbose=1)\n",
    "out_autoencoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in range(out_autoencoder.shape[0]):\n",
    "    cv2.imwrite('./data/Test/denoise/image'+str(index)+'.png',out_autoencoder[index]*255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def get_psnr(imageA,imageB):\n",
    "    maxI = 1.0\n",
    "    try:\n",
    "        return 20*math.log10(maxI) - 10*math.log10(mean_squared_error(imageA.flatten(),imageB.flatten()))\n",
    "    except:\n",
    "        return 20*math.log10(maxI)\n",
    "\n",
    "def get_psnr_result(x_test, out):\n",
    "    psnr_sum = 0\n",
    "    for i in range(out.shape[0]):\n",
    "        psnr_sum += get_psnr(x_test[i].reshape(64,64),out[i].reshape(64,64))\n",
    "        \n",
    "    return 1.0*psnr_sum/out.shape[0];\n",
    "\n",
    "def get_ssim_result(originalSet,noisySet):\n",
    "    ssim_sum = 0\n",
    "    originalSet = originalSet.reshape(originalSet.shape[0],64, 64, 1)\n",
    "    noisySet = noisySet.reshape(noisySet.shape[0],64, 64, 1)\n",
    "    for i in range(originalSet.shape[0]):\n",
    "        ssim_sum += ssim(originalSet[i], noisySet[i],data_range=originalSet[i].max() - noisySet[i].min(), multichannel=True)\n",
    "    return 1.0*ssim_sum/originalSet.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bm3d_denoise(noisy_image):\n",
    "    noisy_image = noisy_image.reshape(noisy_image.shape[0],64,64)\n",
    "    noisy_image = noisy_image*255.0\n",
    "    denoised = []\n",
    "    for i in range(noisy_image.shape[0]):\n",
    "        Basic_img = bm3d.BM3D_1st_step(noisy_image[i])\n",
    "        Final_img = bm3d.BM3D_2nd_step(Basic_img, noisy_image[i])\n",
    "        denoised.append(Final_img)\n",
    "        print \"Image \" + str(i) + \" denoised\"\n",
    "    return np.array(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nlm_denoise(noisy_image):\n",
    "    noisy_image = noisy_image.reshape(noisy_image.shape[0],64,64)\n",
    "    noisy_image = noisy_image*255.0\n",
    "    denoised = []\n",
    "    \n",
    "    for image in noisy_image:\n",
    "        denoised_image = denoise_nl_means(image, 7, 11, 0.5)\n",
    "        denoised.append(denoised_image)\n",
    "        \n",
    "    return np.array(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.700186873509635"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_psnr_result(out_autoencoder,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.174594201883929"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_psnr_result(out_sym_autoencoder,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bm3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 64, 64, 1)\n",
      "Image 0 denoised\n",
      "Image 1 denoised\n",
      "Image 2 denoised\n",
      "Image 3 denoised\n",
      "Image 4 denoised\n",
      "Image 5 denoised\n",
      "Image 6 denoised\n",
      "Image 7 denoised\n",
      "Image 8 denoised\n",
      "Image 9 denoised\n",
      "Image 10 denoised\n",
      "Image 11 denoised\n",
      "Image 12 denoised\n",
      "Image 13 denoised\n",
      "Image 14 denoised\n",
      "Image 15 denoised\n",
      "Image 16 denoised\n",
      "Image 17 denoised\n",
      "Image 18 denoised\n",
      "Image 19 denoised\n",
      "Image 20 denoised\n",
      "Image 21 denoised\n",
      "Image 22 denoised\n",
      "Image 23 denoised\n",
      "Image 24 denoised\n",
      "Image 25 denoised\n",
      "Image 26 denoised\n",
      "Image 27 denoised\n",
      "Image 28 denoised\n",
      "Image 29 denoised\n",
      "Image 30 denoised\n",
      "Image 31 denoised\n",
      "Image 32 denoised\n",
      "Image 33 denoised\n",
      "Image 34 denoised\n",
      "Image 35 denoised\n",
      "Image 36 denoised\n",
      "Image 37 denoised\n",
      "Image 38 denoised\n",
      "Image 39 denoised\n",
      "Image 40 denoised\n",
      "Image 41 denoised\n",
      "Image 42 denoised\n",
      "Image 43 denoised\n",
      "Image 44 denoised\n",
      "Image 45 denoised\n",
      "Image 46 denoised\n",
      "Image 47 denoised\n",
      "Image 48 denoised\n",
      "Image 49 denoised\n",
      "Image 50 denoised\n",
      "Image 51 denoised\n",
      "Image 52 denoised\n",
      "Image 53 denoised\n",
      "Image 54 denoised\n",
      "Image 55 denoised\n",
      "Image 56 denoised\n",
      "Image 57 denoised\n",
      "Image 58 denoised\n",
      "Image 59 denoised\n",
      "Image 60 denoised\n",
      "Image 61 denoised\n",
      "Image 62 denoised\n",
      "Image 63 denoised\n",
      "Image 64 denoised\n",
      "Image 65 denoised\n",
      "Image 66 denoised\n",
      "Image 67 denoised\n",
      "Image 68 denoised\n",
      "Image 69 denoised\n",
      "Image 70 denoised\n",
      "Image 71 denoised\n",
      "Image 72 denoised\n",
      "Image 73 denoised\n",
      "Image 74 denoised\n",
      "Image 75 denoised\n",
      "Image 76 denoised\n",
      "Image 77 denoised\n",
      "Image 78 denoised\n",
      "Image 79 denoised\n",
      "Image 80 denoised\n",
      "Image 81 denoised\n",
      "Image 82 denoised\n",
      "Image 83 denoised\n",
      "Image 84 denoised\n",
      "Image 85 denoised\n",
      "Image 86 denoised\n",
      "Image 87 denoised\n",
      "Image 88 denoised\n",
      "Image 89 denoised\n",
      "Image 90 denoised\n",
      "Image 91 denoised\n",
      "Image 92 denoised\n",
      "Image 93 denoised\n",
      "Image 94 denoised\n",
      "Image 95 denoised\n",
      "Image 96 denoised\n",
      "Image 97 denoised\n",
      "Image 98 denoised\n",
      "Image 99 denoised\n",
      "Image 100 denoised\n",
      "Image 101 denoised\n",
      "Image 102 denoised\n",
      "Image 103 denoised\n",
      "Image 104 denoised\n",
      "Image 105 denoised\n",
      "Image 106 denoised\n",
      "Image 107 denoised\n",
      "Image 108 denoised\n",
      "Image 109 denoised\n",
      "Image 110 denoised\n",
      "Image 111 denoised\n",
      "Image 112 denoised\n",
      "Image 113 denoised\n",
      "Image 114 denoised\n",
      "Image 115 denoised\n",
      "Image 116 denoised\n",
      "Image 117 denoised\n",
      "Image 118 denoised\n",
      "Image 119 denoised\n"
     ]
    }
   ],
   "source": [
    "print noisy_test_images.shape\n",
    "bm3d_out = bm3d_denoise(noisy_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm3d_out_norm = bm3d_out.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.799269401238046"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_psnr_result(bm3d_out_norm,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeshwanth/anaconda2/lib/python2.7/site-packages/skimage/restoration/non_local_means.py:108: UserWarning: denoise_nl_means will default to multichannel=False in v0.15\n",
      "  warn('denoise_nl_means will default to multichannel=False in v0.15')\n"
     ]
    }
   ],
   "source": [
    "nlm_out = nlm_denoise(noisy_test_images)\n",
    "nlm_out = nlm_out.astype('float32')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.178280774231597"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_psnr_result(nlm_out,test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48315060087070411"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,out_sym_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38761606919347613"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,out_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-e19e4b07874d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ssim_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbm3d_out_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-2067cca5c825>\u001b[0m in \u001b[0;36mget_ssim_result\u001b[0;34m(originalSet, noisySet)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnoisySet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoisySet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisySet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginalSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mssim_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mssim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginalSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoisySet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginalSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnoisySet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultichannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mssim_sum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0moriginalSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "get_ssim_result(test_images,bm3d_out_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28062358379392816"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ssim_result(test_images,nlm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ground Truth\n",
    "display_images(test_images,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Noisy images\n",
    "display_images(noisy_test_images,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Autoencoder denoised images\n",
    "display_images(out,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bm3d denoised images\n",
    "display_images(bm3d_out_norm,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nlm denoised images\n",
    "display_images(nlm_out,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
